{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#TEST CODE\n"
      ],
      "metadata": {
        "id": "HkRpXSNw995y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcAKpSXSBppJ",
        "outputId": "e9420edc-e2c2-4e7f-ab45-e07143644b53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Poker Preflop Bucketing Implementation\n",
            "========================================\n",
            "Total number of unique 2-card hands: 1326\n",
            "Total number of preflop buckets generated: 169\n",
            "Successfully generated all 169 preflop buckets.\n",
            "\n",
            "Bucket 'AA': Contains 6 combinations.\n",
            "   Hands: ['AhAd', 'AhAc', 'AhAs', 'AdAc', 'AdAs', 'AcAs']...\n",
            "Bucket 'AKs': Contains 4 combinations.\n",
            "   Hands: ['KhAh', 'KdAd', 'KcAc', 'KsAs']...\n",
            "Bucket 'AKo': Contains 12 combinations.\n",
            "   Hands: ['KhAd', 'KhAc', 'KhAs', 'KdAh', 'KdAc', 'KdAs']...\n",
            "\n",
            "--- Verifying Hand Counts ---\n",
            "Pocket pairs should have 6 combos. 'AA' has: 6\n",
            "Suited hands should have 4 combos. 'AKs' has: 4\n",
            "Offsuit hands should have 12 combos. 'AKo' has: 12\n"
          ]
        }
      ],
      "source": [
        "from __future__ import annotations\n",
        "import itertools\n",
        "from typing import List, Dict, Tuple, Set\n",
        "\n",
        "SUITS = ['h', 'd', 'c', 's']  # Hearts, Diamonds, Clubs, Spades\n",
        "RANKS = ['2', '3', '4', '5', '6', '7', '8', '9', 'T', 'J', 'Q', 'K', 'A']\n",
        "\n",
        "class Card:\n",
        "    \"\"\"\n",
        "    Represents a single playing card with rank and suit.\n",
        "\n",
        "    Attributes:\n",
        "        rank (str): The rank of the card ('2' through 'A')\n",
        "        suit (str): The suit of the card ('h', 'd', 'c', 's')\n",
        "    \"\"\"\n",
        "    __slots__ = ('rank', 'suit')  # Memory optimization\n",
        "\n",
        "    def __init__(self, rank: str, suit: str) -> None:\n",
        "        if rank not in RANKS:\n",
        "            raise ValueError(f\"Invalid rank: {rank}. Must be one of {RANKS}\")\n",
        "        if suit not in SUITS:\n",
        "            raise ValueError(f\"Invalid suit: {suit}. Must be one of {SUITS}\")\n",
        "        self.rank = rank\n",
        "        self.suit = suit\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return f\"{self.rank}{self.suit}\"\n",
        "\n",
        "    def __eq__(self, other: object) -> bool:\n",
        "        if not isinstance(other, Card):\n",
        "            return NotImplemented\n",
        "        return self.rank == other.rank and self.suit == other.suit\n",
        "\n",
        "    def __hash__(self) -> int:\n",
        "        return hash((self.rank, self.suit))\n",
        "\n",
        "    def get_numeric_rank(self) -> int:\n",
        "        \"\"\"Returns the numeric rank of the card (2-14, where Ace is 14).\"\"\"\n",
        "        return RANKS.index(self.rank) + 2\n",
        "\n",
        "def create_deck() -> List[Card]:\n",
        "    \"\"\"Creates a standard 52-card deck.\"\"\"\n",
        "    return [Card(rank, suit) for rank in RANKS for suit in SUITS]\n",
        "\n",
        "def get_hand_bucket(hand: List[Card]) -> str:\n",
        "    \"\"\"\n",
        "    Determines the preflop bucket for a given two-card hand.\n",
        "\n",
        "    Args:\n",
        "        hand (List[Card]): A list containing exactly two Card objects.\n",
        "\n",
        "    Returns:\n",
        "        str: The name of the preflop bucket (e.g., 'AA', 'AKs', 'KQo').\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If hand doesn't contain exactly two cards.\n",
        "    \"\"\"\n",
        "    if len(hand) != 2:\n",
        "        raise ValueError(\"Hand must consist of exactly two cards.\")\n",
        "\n",
        "    # Sort cards by rank (higher rank first)\n",
        "    sorted_hand = sorted(hand, key=lambda card: RANKS.index(card.rank), reverse=True)\n",
        "    card1, card2 = sorted_hand\n",
        "\n",
        "    if card1.rank == card2.rank:\n",
        "        return f\"{card1.rank}{card2.rank}\"  # Pocket pair\n",
        "    elif card1.suit == card2.suit:\n",
        "        return f\"{card1.rank}{card2.rank}s\"  # Suited\n",
        "    else:\n",
        "        return f\"{card1.rank}{card2.rank}o\"  # Offsuit\n",
        "\n",
        "def main() -> None:\n",
        "    \"\"\"Demonstrates the poker hand bucketing implementation.\"\"\"\n",
        "    print(\"Poker Preflop Bucketing Implementation\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    # Create all possible 2-card combinations\n",
        "    deck = create_deck()\n",
        "    all_possible_hands = list(itertools.combinations(deck, 2))\n",
        "    print(f\"Total number of unique 2-card hands: {len(all_possible_hands)}\")\n",
        "\n",
        "    # Group hands into buckets\n",
        "    preflop_buckets: Dict[str, List[Tuple[Card, Card]]] = {}\n",
        "    for hand in all_possible_hands:\n",
        "        bucket_name = get_hand_bucket(list(hand))\n",
        "        preflop_buckets.setdefault(bucket_name, []).append(hand)\n",
        "\n",
        "    # Verify results\n",
        "    total_buckets = len(preflop_buckets)\n",
        "    print(f\"Total number of preflop buckets generated: {total_buckets}\")\n",
        "\n",
        "    if total_buckets == 169:\n",
        "        print(\"Successfully generated all 169 preflop buckets.\\n\")\n",
        "    else:\n",
        "        print(f\"Error: Expected 169 buckets, but got {total_buckets}.\\n\")\n",
        "\n",
        "    # Display example buckets\n",
        "    example_buckets = ['AA', 'AKs', 'AKo']\n",
        "    for bucket in example_buckets:\n",
        "        hands = preflop_buckets[bucket]\n",
        "        print(f\"Bucket '{bucket}': Contains {len(hands)} combinations.\")\n",
        "        print(f\"   Hands: {[str(c1)+str(c2) for c1, c2 in hands][:6]}...\")\n",
        "\n",
        "    print(\"\\n--- Verifying Hand Counts ---\")\n",
        "    print(f\"Pocket pairs should have 6 combos. 'AA' has: {len(preflop_buckets['AA'])}\")\n",
        "    print(f\"Suited hands should have 4 combos. 'AKs' has: {len(preflop_buckets['AKs'])}\")\n",
        "    print(f\"Offsuit hands should have 12 combos. 'AKo' has: {len(preflop_buckets['AKo'])}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFzTmyPRXzmW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHfa5WDfXwSn"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import time\n",
        "from phevaluator import evaluate_cards # Removed card_to_string and string_to_card\n",
        "\n",
        "# --- Basic Game Definitions ---\n",
        "SUITS = ['h', 'd', 'c', 's']\n",
        "RANKS = ['2', '3', '4', '5', '6', '7', '8', '9', 'T', 'J', 'Q', 'K', 'A']\n",
        "DECK = [r + s for r in RANKS for s in SUITS]\n",
        "RANK_MAP = {rank: i for i, rank in enumerate(RANKS)}\n",
        "\n",
        "class PotentialAwareCalculator:\n",
        "    \"\"\"\n",
        "    Calculates a multi-dimensional feature vector for a poker hand,\n",
        "    including current equity, flush potential, and straight potential.\n",
        "    This is the implementation of the improved \"potential-aware\" methodology.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.cache = {}\n",
        "        print(\"PotentialAwareCalculator initialized. Cache is currently empty.\")\n",
        "\n",
        "    def _calculate_current_equity(self, hand, board, remaining_deck, num_sims=500):\n",
        "        \"\"\"A helper to calculate just the raw winning percentage.\"\"\"\n",
        "        wins = 0\n",
        "        cards_to_draw = 2 + (5 - len(board))\n",
        "        for _ in range(num_sims):\n",
        "            try:\n",
        "                samples = random.sample(remaining_deck, cards_to_draw)\n",
        "                opp_hand, board_runout = samples[:2], samples[2:]\n",
        "                final_board = board + board_runout\n",
        "\n",
        "                player_rank = evaluate_cards(*hand, *final_board)\n",
        "                opp_rank = evaluate_cards(*opp_hand, *final_board)\n",
        "\n",
        "                if player_rank < opp_rank: wins += 1\n",
        "                elif player_rank == opp_rank: wins += 0.5\n",
        "            except ValueError: continue\n",
        "        return wins / num_sims if num_sims > 0 else 0\n",
        "\n",
        "    def _has_straight_in_ranks(self, rank_set):\n",
        "        \"\"\"\n",
        "        Checks if a given SET of numerical ranks contains a 5-card straight.\n",
        "        This is the helper tool for the new _calculate_straight_outs method.\n",
        "        \"\"\"\n",
        "        if len(rank_set) < 5:\n",
        "            return False\n",
        "\n",
        "        # Handle Ace-low straight (A, 2, 3, 4, 5) -> Indices {12, 0, 1, 2, 3}\n",
        "        if all(x in rank_set for x in [12, 0, 1, 2, 3]):\n",
        "            return True\n",
        "\n",
        "        # Check for standard straights by sorting the set\n",
        "        sorted_ranks = sorted(list(rank_set), reverse=True)\n",
        "        for i in range(len(sorted_ranks) - 4):\n",
        "            if sorted_ranks[i] - sorted_ranks[i+4] == 4:\n",
        "                return True\n",
        "\n",
        "        return False\n",
        "\n",
        "\n",
        "    def _calculate_straight_outs(self, hand_and_board):\n",
        "        \"\"\"Enhanced with additional safety checks.\"\"\"\n",
        "        if len(hand_and_board) < 3:\n",
        "            return 0  # Not enough cards for meaningful straight draws\n",
        "\n",
        "        ranks_idx = [RANK_MAP[c[0]] for c in hand_and_board]\n",
        "        rank_set = set(ranks_idx)\n",
        "        straight_out_cards = set()\n",
        "\n",
        "        for missing_rank_idx in range(13):\n",
        "            if missing_rank_idx not in rank_set:\n",
        "                test_ranks = rank_set | {missing_rank_idx}\n",
        "\n",
        "                if self._has_straight_in_ranks(test_ranks):\n",
        "                    completing_rank_str = RANKS[missing_rank_idx]\n",
        "                    for suit in SUITS:\n",
        "                        card = completing_rank_str + suit\n",
        "                        if card not in hand_and_board:\n",
        "                            straight_out_cards.add(card)\n",
        "\n",
        "        return len(straight_out_cards)\n",
        "\n",
        "    def _calculate_potential(self, hand, board, remaining_deck):\n",
        "          \"\"\"\n",
        "          Calculates potential, now using the enhanced straight out calculation.\n",
        "          \"\"\"\n",
        "          if len(board) == 5:  # River - no more potential\n",
        "              return 0.0, 0.0\n",
        "\n",
        "\n",
        "          hand_and_board = hand + board\n",
        "\n",
        "          # --- Flush Potential Calculation (Unchanged) ---\n",
        "          suit_counts = {s: sum(1 for c in hand_and_board if c[1] == s) for s in SUITS}\n",
        "          flush_potential = 0.0\n",
        "          flush_draw_suit = next((s for s, count in suit_counts.items() if count == 4), None)\n",
        "\n",
        "          if flush_draw_suit:\n",
        "              flush_outs = 13 - suit_counts[flush_draw_suit]\n",
        "              if len(board) == 3: # On the flop\n",
        "                  p_miss_turn = (len(remaining_deck) - flush_outs) / len(remaining_deck)\n",
        "                  p_miss_river = (len(remaining_deck) - 1 - flush_outs) / (len(remaining_deck) - 1)\n",
        "                  flush_potential = 1 - (p_miss_turn * p_miss_river)\n",
        "              elif len(board) == 4: # On the turn\n",
        "                  flush_potential = flush_outs / len(remaining_deck)\n",
        "\n",
        "          # --- Straight Potential Calculation (REPLACED with the new logic) ---\n",
        "          straight_potential = 0.0\n",
        "          # Only calculate straight potential if we don't already have a better hand.\n",
        "          # We use the phevaluator rank to check: Flush or better is rank 1609 or lower.\n",
        "          current_rank = evaluate_cards(*hand_and_board)\n",
        "          if current_rank > 1609: # If not already a flush or better\n",
        "\n",
        "              # *** THE KEY CHANGE IS HERE ***\n",
        "              # We now call your new, precise function.\n",
        "              num_straight_outs = self._calculate_straight_outs(hand_and_board)\n",
        "              # *** END OF KEY CHANGE ***\n",
        "\n",
        "              if num_straight_outs > 0:\n",
        "                  if len(board) == 3: # On the flop\n",
        "                      p_miss_turn = (len(remaining_deck) - num_straight_outs) / len(remaining_deck)\n",
        "                      p_miss_river = (len(remaining_deck) - 1 - num_straight_outs) / (len(remaining_deck) - 1)\n",
        "                      straight_potential = 1 - (p_miss_turn * p_miss_river)\n",
        "                  elif len(board) == 4: # On the turn\n",
        "                      straight_potential = num_straight_outs / len(remaining_deck)\n",
        "\n",
        "          return flush_potential, straight_potential\n",
        "\n",
        "    def _calculate_made_hand_potential(self, hand, board, remaining_deck):\n",
        "        \"\"\"Enhanced version with better edge case handling.\"\"\"\n",
        "        hand_and_board = hand + board\n",
        "        player_rank = evaluate_cards(*hand_and_board)\n",
        "\n",
        "        # Your existing range checks are correct\n",
        "        is_one_pair = 3003 <= player_rank <= 6185\n",
        "        is_two_pair = 1610 <= player_rank <= 3002\n",
        "\n",
        "        outs = 0\n",
        "\n",
        "        if is_one_pair:\n",
        "            # Check if it's a pocket pair\n",
        "            if hand[0][0] == hand[1][0]:\n",
        "                # Pocket pair - need to check if board is paired\n",
        "                board_ranks = [c[0] for c in board]\n",
        "                if hand[0][0] not in board_ranks:\n",
        "                    outs = 2  # Set outs\n",
        "                else:\n",
        "                    # We have trips, calculate full house outs\n",
        "                    remaining_ranks = set(board_ranks) - {hand[0][0]}\n",
        "                    outs = len(remaining_ranks) * 3  # Any remaining rank can pair the board\n",
        "            else:\n",
        "                # Top pair or other pair - your logic is good but could be more robust\n",
        "                # Consider kicker strength and multiple ways to improve\n",
        "                outs = 5  # Your calculation is correct for standard case\n",
        "\n",
        "        elif is_two_pair:\n",
        "            # Your logic for two pair is correct\n",
        "            outs = 4\n",
        "\n",
        "        # Add case for trips wanting to make full house/quads\n",
        "        elif 1610 > player_rank >= 167:  # This would be trips or better\n",
        "            # Calculate full house/quads outs more precisely\n",
        "            pass\n",
        "\n",
        "        # Your probability calculation is correct\n",
        "\n",
        "    def _calculate_board_connectivity(self, board):\n",
        "        \"\"\"More nuanced connectivity calculation.\"\"\"\n",
        "        if len(board) < 3:\n",
        "            return 0.0\n",
        "\n",
        "        board_ranks = sorted([RANK_MAP[c[0]] for c in board])\n",
        "\n",
        "        # Count gaps and consecutive cards\n",
        "        gaps = 0\n",
        "        consecutive_pairs = 0\n",
        "\n",
        "        for i in range(len(board_ranks) - 1):\n",
        "            gap = board_ranks[i+1] - board_ranks[i]\n",
        "            if gap == 1:\n",
        "                consecutive_pairs += 1\n",
        "            elif gap > 3:  # Large gaps reduce connectivity more\n",
        "                gaps += gap - 1\n",
        "\n",
        "        # Handle wheel connectivity (A-2-3, A-2-4, etc.)\n",
        "        if 12 in board_ranks and 0 in board_ranks:  # A and 2 present\n",
        "            consecutive_pairs += 0.5  # Partial credit for wheel potential\n",
        "\n",
        "        # Normalize: high consecutive pairs = high connectivity\n",
        "        max_consecutive = len(board) - 1\n",
        "        connectivity = consecutive_pairs / max_consecutive if max_consecutive > 0 else 0\n",
        "\n",
        "        # Penalize for gaps\n",
        "        connectivity = max(0, connectivity - gaps * 0.1)\n",
        "\n",
        "        return min(1.0, connectivity)\n",
        "\n",
        "    def _is_nut_hand(self, hand, board):\n",
        "        \"\"\"More accurate nut hand detection.\"\"\"\n",
        "        hand_and_board = hand + board\n",
        "        player_rank = evaluate_cards(*hand_and_board)\n",
        "\n",
        "        # Generate all possible opponent hands to see if we can be beaten\n",
        "        remaining_deck = [card for card in DECK if card not in hand_and_board]\n",
        "\n",
        "        # Quick check for obvious nuts\n",
        "        if player_rank <= 10:  # Straight flush\n",
        "            return 1.0\n",
        "        if player_rank <= 166:  # Four of a kind - usually nuts\n",
        "            return 0.9  # Small chance opponent has better quads\n",
        "\n",
        "        # For other hands, sample opponent possibilities\n",
        "        beaten_count = 0\n",
        "        total_samples = 100  # Limit for performance\n",
        "\n",
        "        for _ in range(total_samples):\n",
        "            try:\n",
        "                opp_hand = random.sample(remaining_deck, 2)\n",
        "                opp_rank = evaluate_cards(*opp_hand, *board)\n",
        "                if opp_rank < player_rank:  # Opponent wins\n",
        "                    beaten_count += 1\n",
        "            except ValueError:\n",
        "                continue\n",
        "\n",
        "        # Return inverted ratio (1.0 = never beaten = nuts)\n",
        "        return max(0.0, 1.0 - (beaten_count / total_samples))\n",
        "\n",
        "    def _calculate_board_texture(self, board):\n",
        "        \"\"\"\n",
        "        Calculates metrics for board suitedness and connectivity.\n",
        "        Returns a tuple: (board_suitedness, board_connectivity).\n",
        "        \"\"\"\n",
        "        # --- 1. Board Suitedness ---\n",
        "        board_suits = {card[1] for card in board}\n",
        "        if len(board_suits) == 1:\n",
        "            board_suitedness = 1.0  # Monotone\n",
        "        elif len(board_suits) == 2:\n",
        "            board_suitedness = 0.5  # Two-tone\n",
        "        else:\n",
        "            board_suitedness = 0.0  # Rainbow\n",
        "\n",
        "        # --- 2. Board Connectivity ---\n",
        "        board_ranks_idx = sorted([RANK_MAP[c[0]] for c in board])\n",
        "        # Max possible span on flop is 9 (e.g., K-Q-2 -> 11-1 = 10; A-7-2 -> 12-0 = 12)\n",
        "        # Let's normalize from 0 (gapped, e.g., K-7-2) to 1 (connected, e.g., 8-7-6).\n",
        "        max_span = board_ranks_idx[-1] - board_ranks_idx[0]\n",
        "        # A span of 2 for a 3-card board (e.g., 8-7-6) is max connectivity.\n",
        "        # A span of 12 (A-2-X) is min connectivity.\n",
        "        # Normalize it to a 0-1 range where 1 is highly connected.\n",
        "        normalized_span = max_span / 12.0\n",
        "        board_connectivity = 1.0 - normalized_span\n",
        "\n",
        "        return board_suitedness, board_connectivity\n",
        "\n",
        "    def calculate_feature_vector(self, hand, board):\n",
        "        \"\"\"Updated to include all new features.\"\"\"\n",
        "        # ... existing cache logic ...\n",
        "\n",
        "        known_cards = hand + board\n",
        "        remaining_deck = [card for card in DECK if card not in known_cards]\n",
        "\n",
        "        # Original features\n",
        "        equity = self._calculate_current_equity(hand, board, remaining_deck)\n",
        "        flush_pot, straight_pot = self._calculate_potential(hand, board, remaining_deck)\n",
        "\n",
        "        # New features\n",
        "        made_hand_pot = self._calculate_made_hand_potential(hand, board, remaining_deck)\n",
        "        board_suit, board_conn = self._calculate_board_texture(board)\n",
        "        backdoor_pot = self._calculate_backdoor_potential(hand, board)\n",
        "        nut_strength = self._is_nut_hand(hand, board)\n",
        "\n",
        "        feature_vector = [\n",
        "            equity,           # Current winning probability\n",
        "            flush_pot,        # Flush potential\n",
        "            straight_pot,     # Straight potential\n",
        "            made_hand_pot,    # Made hand improvement potential\n",
        "            board_suit,       # Board suitedness\n",
        "            board_conn,       # Board connectivity\n",
        "            backdoor_pot,     # Backdoor potential\n",
        "            nut_strength      # Relative hand strength\n",
        "        ]\n",
        "\n",
        "        self.cache[cache_key] = feature_vector\n",
        "        return feature_vector\n",
        "\n",
        "    def _categorize_straight_draw(self, hand_and_board, num_outs):\n",
        "          \"\"\"Optional: categorize the type of straight draw.\"\"\"\n",
        "          if num_outs == 8:\n",
        "              return \"open_ended\"  # Very strong draw\n",
        "          elif num_outs == 4:\n",
        "              return \"gutshot\"     # Moderate draw\n",
        "          elif num_outs > 8:\n",
        "              return \"wrap\"        # Multiple straight possibilities\n",
        "          else:\n",
        "              return \"weak\"        # Unusual or weak drawuckets.\") '''\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cy37Ey6dkOsk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb0c745d-bc30-4711-8734-29687695faca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting phevaluator\n",
            "  Downloading phevaluator-0.5.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from phevaluator) (2.0.2)\n",
            "Downloading phevaluator-0.5.3.1-py3-none-any.whl (3.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: phevaluator\n",
            "Successfully installed phevaluator-0.5.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip install phevaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmTq5mwgX73p"
      },
      "outputs": [],
      "source": [
        "def _calculate_potential(self, hand, board, remaining_deck):\n",
        "    \"\"\"\n",
        "    Calculates potential, now using the enhanced straight out calculation.\n",
        "    \"\"\"\n",
        "    if len(board) == 5:  # River - no more potential\n",
        "        return 0.0, 0.0\n",
        "\n",
        "\n",
        "    hand_and_board = hand + board\n",
        "\n",
        "    # --- Flush Potential Calculation (Unchanged) ---\n",
        "    suit_counts = {s: sum(1 for c in hand_and_board if c[1] == s) for s in SUITS}\n",
        "    flush_potential = 0.0\n",
        "    flush_draw_suit = next((s for s, count in suit_counts.items() if count == 4), None)\n",
        "\n",
        "    if flush_draw_suit:\n",
        "        flush_outs = 13 - suit_counts[flush_draw_suit]\n",
        "        if len(board) == 3: # On the flop\n",
        "            p_miss_turn = (len(remaining_deck) - flush_outs) / len(remaining_deck)\n",
        "            p_miss_river = (len(remaining_deck) - 1 - flush_outs) / (len(remaining_deck) - 1)\n",
        "            flush_potential = 1 - (p_miss_turn * p_miss_river)\n",
        "        elif len(board) == 4: # On the turn\n",
        "            flush_potential = flush_outs / len(remaining_deck)\n",
        "\n",
        "    # --- Straight Potential Calculation (REPLACED with the new logic) ---\n",
        "    straight_potential = 0.0\n",
        "    # Only calculate straight potential if we don't already have a better hand.\n",
        "    # We use the phevaluator rank to check: Flush or better is rank 1609 or lower.\n",
        "    current_rank = evaluate_cards(*hand_and_board)\n",
        "    if current_rank > 1609: # If not already a flush or better\n",
        "\n",
        "        # *** THE KEY CHANGE IS HERE ***\n",
        "        # We now call your new, precise function.\n",
        "        num_straight_outs = self._calculate_straight_outs(hand_and_board)\n",
        "        # *** END OF KEY CHANGE ***\n",
        "\n",
        "        if num_straight_outs > 0:\n",
        "            if len(board) == 3: # On the flop\n",
        "                p_miss_turn = (len(remaining_deck) - num_straight_outs) / len(remaining_deck)\n",
        "                p_miss_river = (len(remaining_deck) - 1 - num_straight_outs) / (len(remaining_deck) - 1)\n",
        "                straight_potential = 1 - (p_miss_turn * p_miss_river)\n",
        "            elif len(board) == 4: # On the turn\n",
        "                straight_potential = num_straight_outs / len(remaining_deck)\n",
        "\n",
        "    return flush_potential, straight_potential\n",
        "\n",
        "def _categorize_straight_draw(self, hand_and_board, num_outs):\n",
        "    \"\"\"Optional: categorize the type of straight draw.\"\"\"\n",
        "    if num_outs == 8:\n",
        "        return \"open_ended\"  # Very strong draw\n",
        "    elif num_outs == 4:\n",
        "        return \"gutshot\"     # Moderate draw\n",
        "    elif num_outs > 8:\n",
        "        return \"wrap\"        # Multiple straight possibilities\n",
        "    else:\n",
        "        return \"weak\"        # Unusual or weak draw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2n4pCr1X-Ac"
      },
      "outputs": [],
      "source": [
        "def _calculate_made_hand_potential(self, hand, board, remaining_deck):\n",
        "    \"\"\"Enhanced version with better edge case handling.\"\"\"\n",
        "    hand_and_board = hand + board\n",
        "    player_rank = evaluate_cards(*hand_and_board)\n",
        "\n",
        "    # Your existing range checks are correct\n",
        "    is_one_pair = 3003 <= player_rank <= 6185\n",
        "    is_two_pair = 1610 <= player_rank <= 3002\n",
        "\n",
        "    outs = 0\n",
        "\n",
        "    if is_one_pair:\n",
        "        # Check if it's a pocket pair\n",
        "        if hand[0][0] == hand[1][0]:\n",
        "            # Pocket pair - need to check if board is paired\n",
        "            board_ranks = [c[0] for c in board]\n",
        "            if hand[0][0] not in board_ranks:\n",
        "                outs = 2  # Set outs\n",
        "            else:\n",
        "                # We have trips, calculate full house outs\n",
        "                remaining_ranks = set(board_ranks) - {hand[0][0]}\n",
        "                outs = len(remaining_ranks) * 3  # Any remaining rank can pair the board\n",
        "        else:\n",
        "            # Top pair or other pair - your logic is good but could be more robust\n",
        "            # Consider kicker strength and multiple ways to improve\n",
        "            outs = 5  # Your calculation is correct for standard case\n",
        "\n",
        "    elif is_two_pair:\n",
        "        # Your logic for two pair is correct\n",
        "        outs = 4\n",
        "\n",
        "    # Add case for trips wanting to make full house/quads\n",
        "    elif 1610 > player_rank >= 167:  # This would be trips or better\n",
        "        # Calculate full house/quads outs more precisely\n",
        "        pass\n",
        "\n",
        "    # Your probability calculation is correct\n",
        "\n",
        "    def _calculate_board_connectivity(self, board):\n",
        "        \"\"\"More nuanced connectivity calculation.\"\"\"\n",
        "        if len(board) < 3:\n",
        "            return 0.0\n",
        "\n",
        "        board_ranks = sorted([RANK_MAP[c[0]] for c in board])\n",
        "\n",
        "        # Count gaps and consecutive cards\n",
        "        gaps = 0\n",
        "        consecutive_pairs = 0\n",
        "\n",
        "        for i in range(len(board_ranks) - 1):\n",
        "            gap = board_ranks[i+1] - board_ranks[i]\n",
        "            if gap == 1:\n",
        "                consecutive_pairs += 1\n",
        "            elif gap > 3:  # Large gaps reduce connectivity more\n",
        "                gaps += gap - 1\n",
        "\n",
        "        # Handle wheel connectivity (A-2-3, A-2-4, etc.)\n",
        "        if 12 in board_ranks and 0 in board_ranks:  # A and 2 present\n",
        "            consecutive_pairs += 0.5  # Partial credit for wheel potential\n",
        "\n",
        "        # Normalize: high consecutive pairs = high connectivity\n",
        "        max_consecutive = len(board) - 1\n",
        "        connectivity = consecutive_pairs / max_consecutive if max_consecutive > 0 else 0\n",
        "\n",
        "        # Penalize for gaps\n",
        "        connectivity = max(0, connectivity - gaps * 0.1)\n",
        "\n",
        "        return min(1.0, connectivity)\n",
        "\n",
        "    def _is_nut_hand(self, hand, board):\n",
        "        \"\"\"More accurate nut hand detection.\"\"\"\n",
        "        hand_and_board = hand + board\n",
        "        player_rank = evaluate_cards(*hand_and_board)\n",
        "\n",
        "        # Generate all possible opponent hands to see if we can be beaten\n",
        "        remaining_deck = [card for card in DECK if card not in hand_and_board]\n",
        "\n",
        "        # Quick check for obvious nuts\n",
        "        if player_rank <= 10:  # Straight flush\n",
        "            return 1.0\n",
        "        if player_rank <= 166:  # Four of a kind - usually nuts\n",
        "            return 0.9  # Small chance opponent has better quads\n",
        "\n",
        "        # For other hands, sample opponent possibilities\n",
        "        beaten_count = 0\n",
        "        total_samples = 100  # Limit for performance\n",
        "\n",
        "        for _ in range(total_samples):\n",
        "            try:\n",
        "                opp_hand = random.sample(remaining_deck, 2)\n",
        "                opp_rank = evaluate_cards(*opp_hand, *board)\n",
        "                if opp_rank < player_rank:  # Opponent wins\n",
        "                    beaten_count += 1\n",
        "            except ValueError:\n",
        "                continue\n",
        "\n",
        "        # Return inverted ratio (1.0 = never beaten = nuts)\n",
        "        return max(0.0, 1.0 - (beaten_count / total_samples))\n",
        "\n",
        "    def _calculate_board_texture(self, board):\n",
        "        \"\"\"\n",
        "        Calculates metrics for board suitedness and connectivity.\n",
        "        Returns a tuple: (board_suitedness, board_connectivity).\n",
        "        \"\"\"\n",
        "        # --- 1. Board Suitedness ---\n",
        "        board_suits = {card[1] for card in board}\n",
        "        if len(board_suits) == 1:\n",
        "            board_suitedness = 1.0  # Monotone\n",
        "        elif len(board_suits) == 2:\n",
        "            board_suitedness = 0.5  # Two-tone\n",
        "        else:\n",
        "            board_suitedness = 0.0  # Rainbow\n",
        "\n",
        "        # --- 2. Board Connectivity ---\n",
        "        board_ranks_idx = sorted([RANK_MAP[c[0]] for c in board])\n",
        "        # Max possible span on flop is 9 (e.g., K-Q-2 -> 11-1 = 10; A-7-2 -> 12-0 = 12)\n",
        "        # Let's normalize from 0 (gapped, e.g., K-7-2) to 1 (connected, e.g., 8-7-6).\n",
        "        max_span = board_ranks_idx[-1] - board_ranks_idx[0]\n",
        "        # A span of 2 for a 3-card board (e.g., 8-7-6) is max connectivity.\n",
        "        # A span of 12 (A-2-X) is min connectivity.\n",
        "        # Normalize it to a 0-1 range where 1 is highly connected.\n",
        "        normalized_span = max_span / 12.0\n",
        "        board_connectivity = 1.0 - normalized_span\n",
        "\n",
        "        return board_suitedness, board_connectivity\n",
        "\n",
        "    def calculate_feature_vector(self, hand, board):\n",
        "        \"\"\"Updated to include all new features.\"\"\"\n",
        "        # ... existing cache logic ...\n",
        "\n",
        "        known_cards = hand + board\n",
        "        remaining_deck = [card for card in DECK if card not in known_cards]\n",
        "\n",
        "        # Original features\n",
        "        equity = self._calculate_current_equity(hand, board, remaining_deck)\n",
        "        flush_pot, straight_pot = self._calculate_potential(hand, board, remaining_deck)\n",
        "\n",
        "        # New features\n",
        "        made_hand_pot = self._calculate_made_hand_potential(hand, board, remaining_deck)\n",
        "        board_suit, board_conn = self._calculate_board_texture(board)\n",
        "        backdoor_pot = self._calculate_backdoor_potential(hand, board)\n",
        "        nut_strength = self._is_nut_hand(hand, board)\n",
        "\n",
        "        feature_vector = [\n",
        "            equity,           # Current winning probability\n",
        "            flush_pot,        # Flush potential\n",
        "            straight_pot,     # Straight potential\n",
        "            made_hand_pot,    # Made hand improvement potential\n",
        "            board_suit,       # Board suitedness\n",
        "            board_conn,       # Board connectivity\n",
        "            backdoor_pot,     # Backdoor potential\n",
        "            nut_strength      # Relative hand strength\n",
        "        ]\n",
        "\n",
        "        self.cache[cache_key] = feature_vector\n",
        "        return feature_vector\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOyDsvwCYohJ"
      },
      "outputs": [],
      "source": [
        "def test_straight_calculation():\n",
        "    \"\"\"Validate the new straight calculation logic.\"\"\"\n",
        "    calc = PotentialAwareCalculator()\n",
        "\n",
        "    # Test case 1: Open-ended straight draw\n",
        "    hand1 = ['9h', '8c']\n",
        "    board1 = ['7d', '6s', '2h']\n",
        "    outs1 = calc._calculate_straight_outs(hand1 + board1)\n",
        "    assert outs1 == 8, f\"Expected 8 outs, got {outs1}\"\n",
        "\n",
        "    # Test case 2: Gutshot\n",
        "    hand2 = ['9h', '8c']\n",
        "    board2 = ['6d', '5s', '2h']\n",
        "    outs2 = calc._calculate_straight_outs(hand2 + board2)\n",
        "    assert outs2 == 4, f\"Expected 4 outs, got {outs2}\"\n",
        "\n",
        "    print(\"All straight calculation tests passed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTNgTNkaY28R",
        "outputId": "afbb16d8-9662-4035-d8ab-fcb54655ff64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PotentialAwareCalculator initialized. Cache is currently empty.\n",
            "All straight calculation tests passed!\n"
          ]
        }
      ],
      "source": [
        "test_straight_calculation()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QV2U4BCljCkd",
        "outputId": "e08c41b8-3982-4594-a20e-cf8570d1c187"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Testing Fixed Abstraction Manager ===\n",
            "Optimized PotentialAwareCalculator initialized.\n",
            "Fixed AbstractionManager initialized.\n",
            "\n",
            "=== STARTING K-MEANS MODEL TRAINING FOR ALL ROUNDS ===\n",
            "\n",
            "--- Training flop model ---\n",
            "--- Generating 5000 feature vectors for flop ---\n",
            "  ...attempting 1000, collected 999/5000...\n",
            "  ...attempting 2000, collected 1999/5000...\n",
            "  ...attempting 3000, collected 2999/5000...\n",
            "  ...attempting 4000, collected 3999/5000...\n",
            "  ...attempting 5000, collected 4999/5000...\n",
            "Generated 5000 valid vectors (0 failed) in 10.29s\n",
            "Removed 12 duplicate vectors\n",
            "Training K-Means on 4988 vectors with 8 features\n",
            "Using 10 clusters\n",
            "Silhouette Score: 0.272\n",
            "flop model trained successfully!\n",
            "\n",
            "--- Training turn model ---\n",
            "--- Generating 5000 feature vectors for turn ---\n",
            "  ...attempting 1000, collected 999/5000...\n",
            "  ...attempting 2000, collected 1999/5000...\n",
            "  ...attempting 3000, collected 2999/5000...\n",
            "  ...attempting 4000, collected 3999/5000...\n",
            "  ...attempting 5000, collected 4999/5000...\n",
            "Generated 5000 valid vectors (0 failed) in 10.93s\n",
            "Removed 31 duplicate vectors\n",
            "Training K-Means on 4969 vectors with 8 features\n",
            "Using 10 clusters\n",
            "Silhouette Score: 0.269\n",
            "turn model trained successfully!\n",
            "\n",
            "--- Training river model ---\n",
            "--- Generating 5000 feature vectors for river ---\n",
            "  ...attempting 1000, collected 999/5000...\n",
            "  ...attempting 2000, collected 1999/5000...\n",
            "  ...attempting 3000, collected 2999/5000...\n",
            "  ...attempting 4000, collected 3999/5000...\n",
            "  ...attempting 5000, collected 4999/5000...\n",
            "Generated 5000 valid vectors (0 failed) in 11.25s\n",
            "Removed 163 duplicate vectors\n",
            "Training K-Means on 4837 vectors with 8 features\n",
            "Using 10 clusters\n",
            "Silhouette Score: 0.289\n",
            "river model trained successfully!\n",
            "\n",
            "=== Validating All Models ===\n",
            "Testing flop model...\n",
            "flop: 50/50 successful (100.0%)\n",
            "Testing turn model...\n",
            "turn: 50/50 successful (100.0%)\n",
            "Testing river model...\n",
            "river: 50/50 successful (100.0%)\n",
            "\n",
            "=== Testing Individual Predictions ===\n",
            "Hand ['As', 'Kh'] + Board ['Qc', '7d', '2s'] -> Bucket 2\n",
            "Hand ['9h', '8c'] + Board ['7d', '6s', '2h', 'Tc'] -> Bucket 25\n",
            "Hand ['Ah', '2h'] + Board ['3h', '4h', '5c', 'Kd', '9s'] -> Bucket 48\n",
            "Models saved to test_models.pkl\n",
            "\n",
            "All tests completed successfully!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "import pickle\n",
        "from collections import defaultdict\n",
        "\n",
        "# Assuming your PotentialAwareCalculator is imported\n",
        "# from your_module import PotentialAwareCalculator\n",
        "\n",
        "class FixedAbstractionManager:\n",
        "    \"\"\"\n",
        "    Fixed version of AbstractionManager with proper data generation\n",
        "    and robust error handling.\n",
        "    \"\"\"\n",
        "    def __init__(self, n_clusters_per_round=20):\n",
        "        self.calculator = PotentialAwareCalculator()\n",
        "        self.n_clusters = n_clusters_per_round\n",
        "        self.kmeans_models = {}\n",
        "        self.cluster_offsets = {'flop': 0, 'turn': 20, 'river': 40}\n",
        "\n",
        "        # Card definitions\n",
        "        self.SUITS = ['h', 'd', 'c', 's']\n",
        "        self.RANKS = ['2', '3', '4', '5', '6', '7', '8', '9', 'T', 'J', 'Q', 'K', 'A']\n",
        "        self.DECK = [r + s for r in self.RANKS for s in self.SUITS]\n",
        "\n",
        "        print(\"Fixed AbstractionManager initialized.\")\n",
        "\n",
        "    def _generate_valid_hand_board(self, num_board_cards):\n",
        "        \"\"\"Generate a valid random hand and board combination.\"\"\"\n",
        "        max_attempts = 100\n",
        "\n",
        "        for attempt in range(max_attempts):\n",
        "            try:\n",
        "                # Shuffle deck and deal cards\n",
        "                deck = self.DECK.copy()\n",
        "                random.shuffle(deck)\n",
        "\n",
        "                # Deal 2 hole cards + board cards\n",
        "                total_cards_needed = 2 + num_board_cards\n",
        "                if total_cards_needed > len(deck):\n",
        "                    continue\n",
        "\n",
        "                hand = deck[:2]\n",
        "                board = deck[2:2 + num_board_cards]\n",
        "\n",
        "                # Validate that we have the required cards\n",
        "                if len(hand) != 2 or len(board) != num_board_cards:\n",
        "                    continue\n",
        "\n",
        "                # Test that the calculator can handle this combination\n",
        "                test_vector = self.calculator.calculate_feature_vector(hand, board)\n",
        "\n",
        "                # Validate the feature vector\n",
        "                if (isinstance(test_vector, list) and\n",
        "                    len(test_vector) > 0 and\n",
        "                    all(isinstance(x, (int, float)) and not np.isnan(x) for x in test_vector)):\n",
        "                    return hand, board\n",
        "\n",
        "            except Exception as e:\n",
        "                continue  # Try again with different cards\n",
        "\n",
        "        # Fallback: return a known good combination\n",
        "        return ['As', 'Kh'], ['Qc', '7d', '2s'][:num_board_cards]\n",
        "\n",
        "    def _generate_data_for_round(self, n_samples, round_name):\n",
        "        \"\"\"Generate valid feature vectors for clustering.\"\"\"\n",
        "        print(f\"--- Generating {n_samples} feature vectors for {round_name} ---\")\n",
        "\n",
        "        feature_vectors = []\n",
        "        num_board_cards = {'flop': 3, 'turn': 4, 'river': 5}[round_name]\n",
        "        failed_generations = 0\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        for i in range(n_samples * 2):  # Generate extra to account for failures\n",
        "            if len(feature_vectors) >= n_samples:\n",
        "                break\n",
        "\n",
        "            if (i + 1) % 1000 == 0:\n",
        "                print(f\"  ...attempting {i+1}, collected {len(feature_vectors)}/{n_samples}...\")\n",
        "\n",
        "            try:\n",
        "                # Generate valid hand and board\n",
        "                hand, board = self._generate_valid_hand_board(num_board_cards)\n",
        "\n",
        "                # Calculate feature vector\n",
        "                vector = self.calculator.calculate_feature_vector(hand, board)\n",
        "\n",
        "                # Validate vector\n",
        "                if self._validate_feature_vector(vector):\n",
        "                    feature_vectors.append(vector)\n",
        "                else:\n",
        "                    failed_generations += 1\n",
        "\n",
        "            except Exception as e:\n",
        "                failed_generations += 1\n",
        "                continue\n",
        "\n",
        "        duration = time.time() - start_time\n",
        "\n",
        "        if len(feature_vectors) < self.n_clusters:\n",
        "            raise ValueError(f\"Only generated {len(feature_vectors)} valid vectors, \"\n",
        "                           f\"need at least {self.n_clusters} for clustering\")\n",
        "\n",
        "        print(f\"Generated {len(feature_vectors)} valid vectors \"\n",
        "              f\"({failed_generations} failed) in {duration:.2f}s\")\n",
        "\n",
        "        return np.array(feature_vectors)\n",
        "\n",
        "    def _validate_feature_vector(self, vector):\n",
        "        \"\"\"Validate that a feature vector is suitable for clustering.\"\"\"\n",
        "        if not isinstance(vector, (list, tuple, np.ndarray)):\n",
        "            return False\n",
        "\n",
        "        if len(vector) == 0:\n",
        "            return False\n",
        "\n",
        "        # Check for NaN or infinite values\n",
        "        for val in vector:\n",
        "            if not isinstance(val, (int, float)):\n",
        "                return False\n",
        "            if np.isnan(val) or np.isinf(val):\n",
        "                return False\n",
        "\n",
        "        # Check that values are in reasonable ranges (0-1 for probabilities)\n",
        "        for val in vector:\n",
        "            if val < 0 or val > 1:\n",
        "                return False\n",
        "\n",
        "        return True\n",
        "\n",
        "    def _remove_duplicate_vectors(self, vectors):\n",
        "        \"\"\"Remove duplicate feature vectors to improve clustering.\"\"\"\n",
        "        unique_vectors = []\n",
        "        seen = set()\n",
        "\n",
        "        for vector in vectors:\n",
        "            vector_tuple = tuple(np.round(vector, 6))  # Round to avoid floating point issues\n",
        "            if vector_tuple not in seen:\n",
        "                seen.add(vector_tuple)\n",
        "                unique_vectors.append(vector)\n",
        "\n",
        "        print(f\"Removed {len(vectors) - len(unique_vectors)} duplicate vectors\")\n",
        "        return np.array(unique_vectors)\n",
        "\n",
        "    def train_all_postflop_models(self, n_samples_per_round=10000):\n",
        "        \"\"\"Train K-Means models with proper error handling.\"\"\"\n",
        "        print(\"\\n=== STARTING K-MEANS MODEL TRAINING FOR ALL ROUNDS ===\")\n",
        "\n",
        "        for round_name in ['flop', 'turn', 'river']:\n",
        "            try:\n",
        "                print(f\"\\n--- Training {round_name} model ---\")\n",
        "\n",
        "                # Generate data\n",
        "                data = self._generate_data_for_round(n_samples_per_round, round_name)\n",
        "\n",
        "                # Remove duplicates\n",
        "                data = self._remove_duplicate_vectors(data)\n",
        "\n",
        "                # Final validation\n",
        "                if len(data) < self.n_clusters:\n",
        "                    print(f\"Warning: Only {len(data)} unique vectors for {self.n_clusters} clusters\")\n",
        "                    # Reduce cluster count if necessary\n",
        "                    actual_clusters = min(self.n_clusters, len(data))\n",
        "                else:\n",
        "                    actual_clusters = self.n_clusters\n",
        "\n",
        "                # Reshape data if needed (should be 2D)\n",
        "                if data.ndim == 1:\n",
        "                    data = data.reshape(-1, 1)\n",
        "\n",
        "                print(f\"Training K-Means on {data.shape[0]} vectors with {data.shape[1]} features\")\n",
        "                print(f\"Using {actual_clusters} clusters\")\n",
        "\n",
        "                # Train K-Means\n",
        "                kmeans = KMeans(\n",
        "                    n_clusters=actual_clusters,\n",
        "                    random_state=42,\n",
        "                    n_init=10,\n",
        "                    max_iter=300\n",
        "                )\n",
        "\n",
        "                kmeans.fit(data)\n",
        "\n",
        "                # Store the model\n",
        "                self.kmeans_models[round_name] = kmeans\n",
        "\n",
        "                # Evaluate clustering quality\n",
        "                if len(data) > actual_clusters:\n",
        "                    labels = kmeans.predict(data)\n",
        "                    silhouette = silhouette_score(data, labels)\n",
        "                    print(f\"Silhouette Score: {silhouette:.3f}\")\n",
        "\n",
        "                print(f\"{round_name} model trained successfully!\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error training {round_name} model: {e}\")\n",
        "                # Create a dummy model to prevent crashes\n",
        "                self._create_fallback_model(round_name)\n",
        "\n",
        "    def _create_fallback_model(self, round_name):\n",
        "        \"\"\"Create a simple fallback model if training fails.\"\"\"\n",
        "        print(f\"Creating fallback model for {round_name}\")\n",
        "\n",
        "        # Create simple dummy data\n",
        "        dummy_data = np.random.rand(self.n_clusters * 10, 8)  # 8 features\n",
        "\n",
        "        kmeans = KMeans(n_clusters=self.n_clusters, random_state=42)\n",
        "        kmeans.fit(dummy_data)\n",
        "\n",
        "        self.kmeans_models[round_name] = kmeans\n",
        "\n",
        "    def get_postflop_bucket(self, hand, board):\n",
        "        \"\"\"Get bucket ID with proper error handling.\"\"\"\n",
        "        try:\n",
        "            # Validate inputs\n",
        "            if not isinstance(hand, list) or len(hand) != 2:\n",
        "                raise ValueError(\"Hand must be a list of 2 cards\")\n",
        "            if not isinstance(board, list) or len(board) not in [3, 4, 5]:\n",
        "                raise ValueError(\"Board must have 3, 4, or 5 cards\")\n",
        "\n",
        "            # Determine round\n",
        "            num_board_cards = len(board)\n",
        "            round_map = {3: 'flop', 4: 'turn', 5: 'river'}\n",
        "            round_name = round_map[num_board_cards]\n",
        "\n",
        "            if round_name not in self.kmeans_models:\n",
        "                raise RuntimeError(f\"No trained model for {round_name}\")\n",
        "\n",
        "            # Get feature vector\n",
        "            feature_vector = self.calculator.calculate_feature_vector(hand, board)\n",
        "\n",
        "            # Validate feature vector\n",
        "            if not self._validate_feature_vector(feature_vector):\n",
        "                print(f\"Warning: Invalid feature vector {feature_vector}, using fallback\")\n",
        "                return self.cluster_offsets[round_name]  # Return first bucket as fallback\n",
        "\n",
        "            # Predict cluster\n",
        "            model = self.kmeans_models[round_name]\n",
        "            vector_array = np.array([feature_vector])  # Ensure 2D shape\n",
        "\n",
        "            predicted_cluster = model.predict(vector_array)[0]\n",
        "\n",
        "            # Return final bucket ID\n",
        "            bucket_id = predicted_cluster + self.cluster_offsets[round_name]\n",
        "\n",
        "            # Ensure bucket ID is in valid range\n",
        "            min_bucket = self.cluster_offsets[round_name]\n",
        "            max_bucket = min_bucket + self.n_clusters - 1\n",
        "            bucket_id = max(min_bucket, min(max_bucket, bucket_id))\n",
        "\n",
        "            return int(bucket_id)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in get_postflop_bucket: {e}\")\n",
        "            # Return a safe fallback bucket\n",
        "            round_name = {3: 'flop', 4: 'turn', 5: 'river'}.get(len(board), 'flop')\n",
        "            return self.cluster_offsets[round_name]\n",
        "\n",
        "    def save_models(self, filepath):\n",
        "        \"\"\"Save trained models to disk.\"\"\"\n",
        "        try:\n",
        "            model_data = {\n",
        "                'kmeans_models': self.kmeans_models,\n",
        "                'n_clusters': self.n_clusters,\n",
        "                'cluster_offsets': self.cluster_offsets\n",
        "            }\n",
        "\n",
        "            with open(filepath, 'wb') as f:\n",
        "                pickle.dump(model_data, f)\n",
        "\n",
        "            print(f\"Models saved to {filepath}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving models: {e}\")\n",
        "\n",
        "    def load_models(self, filepath):\n",
        "        \"\"\"Load pre-trained models from disk.\"\"\"\n",
        "        try:\n",
        "            with open(filepath, 'rb') as f:\n",
        "                model_data = pickle.load(f)\n",
        "\n",
        "            self.kmeans_models = model_data['kmeans_models']\n",
        "            self.n_clusters = model_data['n_clusters']\n",
        "            self.cluster_offsets = model_data['cluster_offsets']\n",
        "\n",
        "            print(f\"Models loaded from {filepath}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading models: {e}\")\n",
        "\n",
        "    def validate_all_models(self, test_samples=100):\n",
        "        \"\"\"Test all models with random data to ensure they work.\"\"\"\n",
        "        print(\"\\n=== Validating All Models ===\")\n",
        "\n",
        "        for round_name in ['flop', 'turn', 'river']:\n",
        "            if round_name not in self.kmeans_models:\n",
        "                print(f\"No model found for {round_name}\")\n",
        "                continue\n",
        "\n",
        "            num_board_cards = {'flop': 3, 'turn': 4, 'river': 5}[round_name]\n",
        "            success_count = 0\n",
        "\n",
        "            print(f\"Testing {round_name} model...\")\n",
        "\n",
        "            for _ in range(test_samples):\n",
        "                try:\n",
        "                    hand, board = self._generate_valid_hand_board(num_board_cards)\n",
        "                    bucket_id = self.get_postflop_bucket(hand, board)\n",
        "\n",
        "                    # Check bucket ID is in valid range\n",
        "                    min_bucket = self.cluster_offsets[round_name]\n",
        "                    max_bucket = min_bucket + self.n_clusters - 1\n",
        "\n",
        "                    if min_bucket <= bucket_id <= max_bucket:\n",
        "                        success_count += 1\n",
        "\n",
        "                except Exception as e:\n",
        "                    continue\n",
        "\n",
        "            success_rate = success_count / test_samples\n",
        "            print(f\"{round_name}: {success_count}/{test_samples} successful ({success_rate:.1%})\")\n",
        "\n",
        "\n",
        "# Example usage with proper error handling\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=== Testing Fixed Abstraction Manager ===\")\n",
        "\n",
        "    try:\n",
        "        # Create manager\n",
        "        manager = FixedAbstractionManager(n_clusters_per_round=10)  # Use fewer clusters for testing\n",
        "\n",
        "        # Train models\n",
        "        manager.train_all_postflop_models(n_samples_per_round=5000)  # Smaller sample for testing\n",
        "\n",
        "        # Validate models\n",
        "        manager.validate_all_models(test_samples=50)\n",
        "\n",
        "        # Test individual predictions\n",
        "        print(\"\\n=== Testing Individual Predictions ===\")\n",
        "        test_cases = [\n",
        "            (['As', 'Kh'], ['Qc', '7d', '2s']),  # Flop\n",
        "            (['9h', '8c'], ['7d', '6s', '2h', 'Tc']),  # Turn\n",
        "            (['Ah', '2h'], ['3h', '4h', '5c', 'Kd', '9s'])  # River\n",
        "        ]\n",
        "\n",
        "        for hand, board in test_cases:\n",
        "            try:\n",
        "                bucket = manager.get_postflop_bucket(hand, board)\n",
        "                print(f\"Hand {hand} + Board {board} -> Bucket {bucket}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error with {hand} + {board}: {e}\")\n",
        "\n",
        "        # Save models\n",
        "        manager.save_models(\"test_models.pkl\")\n",
        "        print(\"\\nAll tests completed successfully!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Critical error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZplxpvzpa4R"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import time\n",
        "from phevaluator import evaluate_cards\n",
        "\n",
        "# --- Basic Game Definitions ---\n",
        "SUITS = ['h', 'd', 'c', 's']\n",
        "RANKS = ['2', '3', '4', '5', '6', '7', '8', '9', 'T', 'J', 'Q', 'K', 'A']\n",
        "DECK = [r + s for r in RANKS for s in SUITS]\n",
        "RANK_MAP = {rank: i for i, rank in enumerate(RANKS)}\n",
        "\n",
        "class PotentialAwareCalculator:\n",
        "    \"\"\"\n",
        "    Optimized version with reduced computational overhead for clustering.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.cache = {}\n",
        "        print(\"Optimized PotentialAwareCalculator initialized.\")\n",
        "\n",
        "    def _calculate_current_equity(self, hand, board, remaining_deck, num_sims=100):  # Reduced from 500\n",
        "        \"\"\"Reduced simulation count for faster performance.\"\"\"\n",
        "        wins = 0\n",
        "        cards_to_draw = 2 + (5 - len(board))\n",
        "\n",
        "        # Early return if not enough cards\n",
        "        if len(remaining_deck) < cards_to_draw:\n",
        "            return 0.0\n",
        "\n",
        "        for _ in range(num_sims):\n",
        "            try:\n",
        "                samples = random.sample(remaining_deck, cards_to_draw)\n",
        "                opp_hand, board_runout = samples[:2], samples[2:]\n",
        "                final_board = board + board_runout\n",
        "\n",
        "                player_rank = evaluate_cards(*hand, *final_board)\n",
        "                opp_rank = evaluate_cards(*opp_hand, *final_board)\n",
        "\n",
        "                if player_rank < opp_rank:\n",
        "                    wins += 1\n",
        "                elif player_rank == opp_rank:\n",
        "                    wins += 0.5\n",
        "            except (ValueError, IndexError):\n",
        "                continue\n",
        "        return wins / num_sims if num_sims > 0 else 0\n",
        "\n",
        "    def _has_straight_in_ranks(self, rank_set):\n",
        "        \"\"\"Optimized straight detection.\"\"\"\n",
        "        if len(rank_set) < 5:\n",
        "            return False\n",
        "\n",
        "        # Handle Ace-low straight\n",
        "        if all(x in rank_set for x in [12, 0, 1, 2, 3]):\n",
        "            return True\n",
        "\n",
        "        # Check for standard straights\n",
        "        sorted_ranks = sorted(list(rank_set))\n",
        "        for i in range(len(sorted_ranks) - 4):\n",
        "            if sorted_ranks[i+4] - sorted_ranks[i] == 4:\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def _calculate_straight_outs(self, hand_and_board):\n",
        "        \"\"\"Simplified straight outs calculation.\"\"\"\n",
        "        if len(hand_and_board) < 3:\n",
        "            return 0\n",
        "\n",
        "        ranks_idx = [RANK_MAP[c[0]] for c in hand_and_board]\n",
        "        rank_set = set(ranks_idx)\n",
        "\n",
        "        # Quick heuristic: if we have 4+ to a straight, likely 4-8 outs\n",
        "        # This is much faster than the exact calculation\n",
        "        if len(rank_set) >= 4:\n",
        "            # Check for obvious straight draws\n",
        "            sorted_ranks = sorted(rank_set)\n",
        "            max_gap = max(sorted_ranks[i+1] - sorted_ranks[i] for i in range(len(sorted_ranks)-1))\n",
        "            if max_gap <= 4:  # Reasonable straight potential\n",
        "                return 8 if max_gap <= 2 else 4\n",
        "\n",
        "        return 0\n",
        "\n",
        "    def _calculate_potential(self, hand, board, remaining_deck):\n",
        "        \"\"\"Simplified potential calculation.\"\"\"\n",
        "        if len(board) == 5:\n",
        "            return 0.0, 0.0\n",
        "\n",
        "        hand_and_board = hand + board\n",
        "\n",
        "        # Flush potential\n",
        "        suit_counts = {s: sum(1 for c in hand_and_board if c[1] == s) for s in SUITS}\n",
        "        flush_potential = 0.0\n",
        "\n",
        "        for suit, count in suit_counts.items():\n",
        "            if count == 4:  # Flush draw\n",
        "                remaining_suited = 13 - count\n",
        "                if len(board) == 3:  # Flop\n",
        "                    flush_potential = 1 - ((len(remaining_deck) - remaining_suited) / len(remaining_deck))**2\n",
        "                elif len(board) == 4:  # Turn\n",
        "                    flush_potential = remaining_suited / len(remaining_deck)\n",
        "                break\n",
        "\n",
        "        # Straight potential (simplified)\n",
        "        straight_potential = 0.0\n",
        "        current_rank = evaluate_cards(*hand_and_board)\n",
        "\n",
        "        if current_rank > 1609:  # Not already a strong hand\n",
        "            straight_outs = self._calculate_straight_outs(hand_and_board)\n",
        "            if straight_outs > 0:\n",
        "                if len(board) == 3:\n",
        "                    straight_potential = 1 - ((len(remaining_deck) - straight_outs) / len(remaining_deck))**2\n",
        "                elif len(board) == 4:\n",
        "                    straight_potential = straight_outs / len(remaining_deck)\n",
        "\n",
        "        return flush_potential, straight_potential\n",
        "\n",
        "    def _calculate_made_hand_potential(self, hand, board, remaining_deck):\n",
        "        \"\"\"Simplified made hand potential.\"\"\"\n",
        "        hand_and_board = hand + board\n",
        "        player_rank = evaluate_cards(*hand_and_board)\n",
        "\n",
        "        # Simple heuristic based on hand strength\n",
        "        if 3003 <= player_rank <= 6185:  # One pair\n",
        "            return 0.3  # Some potential to improve\n",
        "        elif 1610 <= player_rank <= 3002:  # Two pair\n",
        "            return 0.2  # Less potential\n",
        "        elif player_rank < 1610:  # Strong hand\n",
        "            return 0.1  # Little potential needed\n",
        "        else:\n",
        "            return 0.4  # High card, needs improvement\n",
        "\n",
        "    def _calculate_backdoor_potential(self, hand, board):\n",
        "        \"\"\"Simple backdoor potential calculation.\"\"\"\n",
        "        if len(board) != 3:  # Only relevant on flop\n",
        "            return 0.0\n",
        "\n",
        "        hand_and_board = hand + board\n",
        "\n",
        "        # Backdoor flush potential\n",
        "        suit_counts = {s: sum(1 for c in hand_and_board if c[1] == s) for s in SUITS}\n",
        "        max_suit_count = max(suit_counts.values())\n",
        "\n",
        "        backdoor_flush = 0.1 if max_suit_count == 3 else 0.0\n",
        "\n",
        "        # Backdoor straight potential (simplified)\n",
        "        ranks = set(RANK_MAP[c[0]] for c in hand_and_board)\n",
        "        backdoor_straight = 0.1 if len(ranks) >= 3 else 0.0\n",
        "\n",
        "        return max(backdoor_flush, backdoor_straight)\n",
        "\n",
        "    def _calculate_board_texture(self, board):\n",
        "        \"\"\"Board texture calculation.\"\"\"\n",
        "        if len(board) < 3:\n",
        "            return 0.0, 0.0\n",
        "\n",
        "        # Suitedness\n",
        "        board_suits = {card[1] for card in board}\n",
        "        if len(board_suits) == 1:\n",
        "            board_suitedness = 1.0\n",
        "        elif len(board_suits) == 2:\n",
        "            board_suitedness = 0.5\n",
        "        else:\n",
        "            board_suitedness = 0.0\n",
        "\n",
        "        # Connectivity\n",
        "        board_ranks_idx = sorted([RANK_MAP[c[0]] for c in board])\n",
        "        max_span = board_ranks_idx[-1] - board_ranks_idx[0]\n",
        "        board_connectivity = max(0.0, 1.0 - max_span / 12.0)\n",
        "\n",
        "        return board_suitedness, board_connectivity\n",
        "\n",
        "    def _is_nut_hand(self, hand, board):\n",
        "        \"\"\"Simplified nut hand detection.\"\"\"\n",
        "        hand_and_board = hand + board\n",
        "        player_rank = evaluate_cards(*hand_and_board)\n",
        "\n",
        "        # Quick heuristic based on hand rank\n",
        "        if player_rank <= 10:  # Straight flush\n",
        "            return 1.0\n",
        "        elif player_rank <= 166:  # Four of a kind\n",
        "            return 0.9\n",
        "        elif player_rank <= 322:  # Full house\n",
        "            return 0.8\n",
        "        elif player_rank <= 1609:  # Flush\n",
        "            return 0.7\n",
        "        elif player_rank <= 1609:  # Straight\n",
        "            return 0.6\n",
        "        else:\n",
        "            return min(1.0, (7463 - player_rank) / 7463)  # Normalize remaining ranks\n",
        "\n",
        "    def calculate_feature_vector(self, hand, board):\n",
        "        \"\"\"Main method to calculate feature vector.\"\"\"\n",
        "        # Simple cache key\n",
        "        cache_key = tuple(sorted(hand + board))\n",
        "        if cache_key in self.cache:\n",
        "            return self.cache[cache_key]\n",
        "\n",
        "        known_cards = hand + board\n",
        "        remaining_deck = [card for card in DECK if card not in known_cards]\n",
        "\n",
        "        if len(remaining_deck) < 2:  # Not enough cards for simulation\n",
        "            return [0.5] * 8  # Return neutral values\n",
        "\n",
        "        try:\n",
        "            # Calculate all features\n",
        "            equity = self._calculate_current_equity(hand, board, remaining_deck)\n",
        "            flush_pot, straight_pot = self._calculate_potential(hand, board, remaining_deck)\n",
        "            made_hand_pot = self._calculate_made_hand_potential(hand, board, remaining_deck)\n",
        "            board_suit, board_conn = self._calculate_board_texture(board)\n",
        "            backdoor_pot = self._calculate_backdoor_potential(hand, board)\n",
        "            nut_strength = self._is_nut_hand(hand, board)\n",
        "\n",
        "            feature_vector = [\n",
        "                equity,           # Current winning probability\n",
        "                flush_pot,        # Flush potential\n",
        "                straight_pot,     # Straight potential\n",
        "                made_hand_pot,    # Made hand improvement potential\n",
        "                board_suit,       # Board suitedness\n",
        "                board_conn,       # Board connectivity\n",
        "                backdoor_pot,     # Backdoor potential\n",
        "                nut_strength      # Relative hand strength\n",
        "            ]\n",
        "\n",
        "            # Ensure all values are valid\n",
        "            feature_vector = [max(0.0, min(1.0, float(x))) for x in feature_vector]\n",
        "\n",
        "            self.cache[cache_key] = feature_vector\n",
        "            return feature_vector\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error calculating feature vector: {e}\")\n",
        "            return [0.5] * 8  # Return neutral values on error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "K4qDVkaYjGWm",
        "outputId": "2216c488-513a-420a-f04c-1ab12c5540f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Advanced MCCFR Poker Trainer ===\n",
            "Initializing Advanced MCCFR Trainer...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'AbstractionManager' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-106314542.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;31m# Initialize trainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m     \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdvancedMCCFRTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \u001b[0;31m# Train the policy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-106314542.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, abstraction_manager, initial_stack)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# Initialize abstraction system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mabstraction_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabstraction_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAbstractionManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters_per_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training abstraction models...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabstraction_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_all_postflop_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples_per_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'AbstractionManager' is not defined"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from collections import defaultdict, Counter\n",
        "import pickle\n",
        "import time\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "from enum import Enum\n",
        "\n",
        "# Assuming your abstraction system is imported\n",
        "# from abstraction_engine import AbstractionManager, PotentialAwareCalculator\n",
        "\n",
        "class Action(Enum):\n",
        "    FOLD = \"fold\"\n",
        "    CHECK = \"check\"\n",
        "    CALL = \"call\"\n",
        "    BET = \"bet\"\n",
        "    RAISE = \"raise\"\n",
        "\n",
        "@dataclass\n",
        "class GameState:\n",
        "    \"\"\"Represents the current state of a poker game.\"\"\"\n",
        "    players: List[int]  # Active players\n",
        "    current_player: int\n",
        "    pot_size: float\n",
        "    street: str  # 'preflop', 'flop', 'turn', 'river'\n",
        "    board: List[str]\n",
        "    hands: Dict[int, List[str]]  # Player ID -> hole cards\n",
        "    bets: Dict[int, float]  # Current street bets\n",
        "    total_bets: Dict[int, float]  # Total bets across all streets\n",
        "    action_history: List[Tuple[int, Action, float]]\n",
        "    is_terminal: bool = False\n",
        "\n",
        "class AdvancedMCCFRTrainer:\n",
        "    \"\"\"\n",
        "    Advanced Monte Carlo Counterfactual Regret Minimization trainer\n",
        "    integrated with sophisticated poker abstraction system.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, abstraction_manager=None, initial_stack=1000.0):\n",
        "        print(\"Initializing Advanced MCCFR Trainer...\")\n",
        "\n",
        "        # Initialize abstraction system\n",
        "        if abstraction_manager is None:\n",
        "            self.abstraction_manager = AbstractionManager(n_clusters_per_round=20)\n",
        "            print(\"Training abstraction models...\")\n",
        "            self.abstraction_manager.train_all_postflop_models(n_samples_per_round=50000)\n",
        "        else:\n",
        "            self.abstraction_manager = abstraction_manager\n",
        "\n",
        "        self.initial_stack = initial_stack\n",
        "\n",
        "        # Core CFR data structures\n",
        "        self.regret_sum = defaultdict(lambda: defaultdict(float))\n",
        "        self.strategy_sum = defaultdict(lambda: defaultdict(float))\n",
        "        self.policy = defaultdict(lambda: defaultdict(float))\n",
        "\n",
        "        # Training statistics\n",
        "        self.iteration_count = 0\n",
        "        self.strategy_updates = 0\n",
        "\n",
        "        # Preflop abstraction (simplified - you'd want a more sophisticated system)\n",
        "        self._initialize_preflop_buckets()\n",
        "\n",
        "        print(\"MCCFR Trainer initialized successfully.\")\n",
        "\n",
        "    def _initialize_preflop_buckets(self):\n",
        "        \"\"\"Initialize preflop hand strength buckets.\"\"\"\n",
        "        # This is a simplified preflop abstraction\n",
        "        # In practice, you'd want a more sophisticated system\n",
        "        self.preflop_buckets = {}\n",
        "\n",
        "        # Example: Group hands by basic strength categories\n",
        "        premium_hands = ['AA', 'KK', 'QQ', 'JJ', 'AKs', 'AKo']\n",
        "        strong_hands = ['TT', '99', 'AQs', 'AQo', 'AJs', 'KQs']\n",
        "        medium_hands = ['88', '77', 'AJo', 'KQo', 'KJs', 'QJs', 'ATs']\n",
        "\n",
        "        # Assign bucket IDs (60-79 for preflop to avoid collision with postflop)\n",
        "        bucket_id = 60\n",
        "        for hand_group in [premium_hands, strong_hands, medium_hands]:\n",
        "            for hand in hand_group:\n",
        "                self.preflop_buckets[hand] = bucket_id\n",
        "            bucket_id += 1\n",
        "\n",
        "    def get_preflop_bucket(self, hand: List[str]) -> int:\n",
        "        \"\"\"Convert hole cards to preflop bucket ID.\"\"\"\n",
        "        # Convert cards to standard notation (e.g., ['As', 'Kh'] -> 'AKo')\n",
        "        ranks = [card[0] for card in hand]\n",
        "        suits = [card[1] for card in hand]\n",
        "\n",
        "        # Sort ranks for consistent representation\n",
        "        rank_order = ['2', '3', '4', '5', '6', '7', '8', '9', 'T', 'J', 'Q', 'K', 'A']\n",
        "        sorted_ranks = sorted(ranks, key=lambda x: rank_order.index(x), reverse=True)\n",
        "\n",
        "        if ranks[0] == ranks[1]:  # Pocket pair\n",
        "            hand_str = ranks[0] + ranks[0]\n",
        "        else:\n",
        "            suited = 's' if suits[0] == suits[1] else 'o'\n",
        "            hand_str = ''.join(sorted_ranks) + suited\n",
        "\n",
        "        return self.preflop_buckets.get(hand_str, 79)  # Default to weakest bucket\n",
        "\n",
        "    def get_info_state(self, state: GameState, player_id: int) -> str:\n",
        "        \"\"\"\n",
        "        Convert game state to information state string using abstraction.\n",
        "        This is the critical bridge between complex poker state and CFR.\n",
        "        \"\"\"\n",
        "        hand = state.hands[player_id]\n",
        "        board = state.board\n",
        "\n",
        "        # Get bucket ID using our sophisticated abstraction\n",
        "        if state.street == 'preflop':\n",
        "            bucket_id = self.get_preflop_bucket(hand)\n",
        "        else:\n",
        "            bucket_id = self.abstraction_manager.get_postflop_bucket(hand, board)\n",
        "\n",
        "        # Create action history string\n",
        "        action_history = self._get_action_sequence(state, player_id)\n",
        "\n",
        "        # Include position and betting context\n",
        "        position = self._get_position_context(state, player_id)\n",
        "        pot_odds = self._get_pot_odds_context(state, player_id)\n",
        "\n",
        "        info_state = f\"B{bucket_id}|H{action_history}|P{position}|O{pot_odds}\"\n",
        "        return info_state\n",
        "\n",
        "    def _get_action_sequence(self, state: GameState, player_id: int) -> str:\n",
        "        \"\"\"Convert action history to compact string representation.\"\"\"\n",
        "        # Group actions by street and player\n",
        "        street_actions = {\n",
        "            'preflop': [],\n",
        "            'flop': [],\n",
        "            'turn': [],\n",
        "            'river': []\n",
        "        }\n",
        "\n",
        "        current_street = 'preflop'\n",
        "        for pid, action, amount in state.action_history:\n",
        "            if action == Action.BET or action == Action.RAISE:\n",
        "                street_actions[current_street].append(f\"{action.value[0]}{int(amount)}\")\n",
        "            else:\n",
        "                street_actions[current_street].append(action.value[0])\n",
        "\n",
        "        # Create compact representation\n",
        "        history_parts = []\n",
        "        for street, actions in street_actions.items():\n",
        "            if actions:\n",
        "                history_parts.append(f\"{street[0]}{''.join(actions)}\")\n",
        "\n",
        "        return '|'.join(history_parts)\n",
        "\n",
        "    def _get_position_context(self, state: GameState, player_id: int) -> str:\n",
        "        \"\"\"Get simplified position context.\"\"\"\n",
        "        # Simplified: just early/late position\n",
        "        num_players = len(state.players)\n",
        "        player_pos = state.players.index(player_id)\n",
        "\n",
        "        if player_pos < num_players // 2:\n",
        "            return \"early\"\n",
        "        else:\n",
        "            return \"late\"\n",
        "\n",
        "    def _get_pot_odds_context(self, state: GameState, player_id: int) -> str:\n",
        "        \"\"\"Get pot odds context for decision making.\"\"\"\n",
        "        to_call = max(state.bets.values()) - state.bets.get(player_id, 0)\n",
        "        if to_call <= 0:\n",
        "            return \"0\"\n",
        "\n",
        "        pot_odds = state.pot_size / to_call\n",
        "\n",
        "        # Discretize pot odds into buckets\n",
        "        if pot_odds < 2:\n",
        "            return \"low\"\n",
        "        elif pot_odds < 4:\n",
        "            return \"med\"\n",
        "        else:\n",
        "            return \"high\"\n",
        "\n",
        "    def get_legal_actions(self, state: GameState, player_id: int) -> List[Tuple[Action, float]]:\n",
        "        \"\"\"Get legal actions and bet sizes for current state.\"\"\"\n",
        "        actions = []\n",
        "        to_call = max(state.bets.values()) - state.bets.get(player_id, 0)\n",
        "        stack_size = self.initial_stack - state.total_bets.get(player_id, 0)\n",
        "\n",
        "        # Fold (always legal if facing bet)\n",
        "        if to_call > 0:\n",
        "            actions.append((Action.FOLD, 0))\n",
        "\n",
        "        # Check/Call\n",
        "        if to_call == 0:\n",
        "            actions.append((Action.CHECK, 0))\n",
        "        else:\n",
        "            if to_call <= stack_size:\n",
        "                actions.append((Action.CALL, to_call))\n",
        "\n",
        "        # Bet/Raise with multiple sizing options\n",
        "        min_bet = max(to_call * 2, state.pot_size * 0.5)  # Min raise or half pot\n",
        "        bet_sizes = [\n",
        "            state.pot_size * 0.5,   # Half pot\n",
        "            state.pot_size * 0.75,  # 3/4 pot\n",
        "            state.pot_size * 1.0,   # Pot\n",
        "            state.pot_size * 1.5,   # 1.5x pot\n",
        "            stack_size              # All-in\n",
        "        ]\n",
        "\n",
        "        for bet_size in bet_sizes:\n",
        "            total_bet = bet_size + state.bets.get(player_id, 0)\n",
        "            if total_bet >= min_bet and total_bet <= stack_size:\n",
        "                if to_call == 0:\n",
        "                    actions.append((Action.BET, bet_size))\n",
        "                else:\n",
        "                    actions.append((Action.RAISE, bet_size))\n",
        "\n",
        "        return actions\n",
        "\n",
        "    def get_strategy(self, info_state: str, legal_actions: List[Tuple[Action, float]]) -> Dict[Tuple[Action, float], float]:\n",
        "        \"\"\"Get current strategy for an information state using regret matching.\"\"\"\n",
        "        strategy = {}\n",
        "        regret_sum = sum(max(0, self.regret_sum[info_state][action]) for action, _ in legal_actions)\n",
        "\n",
        "        if regret_sum > 0:\n",
        "            # Regret matching strategy\n",
        "            for action, amount in legal_actions:\n",
        "                strategy[(action, amount)] = max(0, self.regret_sum[info_state][(action, amount)]) / regret_sum\n",
        "        else:\n",
        "            # Uniform strategy if no positive regrets\n",
        "            uniform_prob = 1.0 / len(legal_actions)\n",
        "            for action, amount in legal_actions:\n",
        "                strategy[(action, amount)] = uniform_prob\n",
        "\n",
        "        return strategy\n",
        "\n",
        "    def train(self, num_iterations: int = 100000):\n",
        "        \"\"\"Main training loop for MCCFR algorithm.\"\"\"\n",
        "        print(f\"\\n=== Starting MCCFR Training for {num_iterations} iterations ===\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        for i in range(num_iterations):\n",
        "            self.iteration_count += 1\n",
        "\n",
        "            if (i + 1) % 10000 == 0:\n",
        "                elapsed = time.time() - start_time\n",
        "                print(f\"Iteration {i+1}/{num_iterations} | \"\n",
        "                      f\"Time: {elapsed:.1f}s | \"\n",
        "                      f\"Avg: {elapsed/(i+1)*1000:.2f}ms/iter\")\n",
        "\n",
        "            # Run MCCFR iteration\n",
        "            self._run_mccfr_iteration()\n",
        "\n",
        "            # Update strategy every 100 iterations\n",
        "            if i % 100 == 0:\n",
        "                self._update_average_strategy()\n",
        "\n",
        "        total_time = time.time() - start_time\n",
        "        print(f\"Training complete! Total time: {total_time:.1f}s\")\n",
        "        print(f\"Final policy contains {len(self.policy)} information states\")\n",
        "\n",
        "    def _run_mccfr_iteration(self):\n",
        "        \"\"\"Run one iteration of Monte Carlo CFR.\"\"\"\n",
        "        # Create random initial game state\n",
        "        initial_state = self._create_random_game_state()\n",
        "\n",
        "        # Run MCCFR recursion for both players\n",
        "        for player_id in [0, 1]:\n",
        "            self._mccfr_recursive(initial_state, player_id, 1.0, 1.0)\n",
        "\n",
        "    def _create_random_game_state(self) -> GameState:\n",
        "        \"\"\"Create a random initial poker game state.\"\"\"\n",
        "        # Deal random cards\n",
        "        deck = ['2h', '2d', '2c', '2s', '3h', '3d', '3c', '3s', '4h', '4d', '4c', '4s',\n",
        "                '5h', '5d', '5c', '5s', '6h', '6d', '6c', '6s', '7h', '7d', '7c', '7s',\n",
        "                '8h', '8d', '8c', '8s', '9h', '9d', '9c', '9s', 'Th', 'Td', 'Tc', 'Ts',\n",
        "                'Jh', 'Jd', 'Jc', 'Js', 'Qh', 'Qd', 'Qc', 'Qs', 'Kh', 'Kd', 'Kc', 'Ks',\n",
        "                'Ah', 'Ad', 'Ac', 'As']\n",
        "\n",
        "        random.shuffle(deck)\n",
        "\n",
        "        # Deal hole cards\n",
        "        hands = {0: deck[:2], 1: deck[2:4]}\n",
        "\n",
        "        # Start with preflop state\n",
        "        state = GameState(\n",
        "            players=[0, 1],\n",
        "            current_player=0,\n",
        "            pot_size=3.0,  # Small blind + big blind\n",
        "            street='preflop',\n",
        "            board=[],\n",
        "            hands=hands,\n",
        "            bets={0: 1.0, 1: 2.0},  # Small blind, big blind\n",
        "            total_bets={0: 1.0, 1: 2.0},\n",
        "            action_history=[]\n",
        "        )\n",
        "\n",
        "        return state\n",
        "\n",
        "    def _mccfr_recursive(self, state: GameState, traversing_player: int,\n",
        "                         pi_player: float, pi_opponent: float) -> float:\n",
        "        \"\"\"Recursive MCCFR algorithm implementation.\"\"\"\n",
        "\n",
        "        # Terminal node - return utility\n",
        "        if state.is_terminal:\n",
        "            return self._get_utility(state, traversing_player)\n",
        "\n",
        "        # Get current player info state and legal actions\n",
        "        current_player = state.current_player\n",
        "        info_state = self.get_info_state(state, current_player)\n",
        "        legal_actions = self.get_legal_actions(state, current_player)\n",
        "\n",
        "        if not legal_actions:\n",
        "            # No legal actions - fold\n",
        "            return self._get_utility(state, traversing_player)\n",
        "\n",
        "        # Get strategy for current info state\n",
        "        strategy = self.get_strategy(info_state, legal_actions)\n",
        "\n",
        "        # Calculate action utilities\n",
        "        action_utilities = {}\n",
        "        for action, amount in legal_actions:\n",
        "            # Create new state after taking this action\n",
        "            new_state = self._apply_action(state, action, amount)\n",
        "\n",
        "            if current_player == traversing_player:\n",
        "                action_utilities[(action, amount)] = self._mccfr_recursive(\n",
        "                    new_state, traversing_player,\n",
        "                    pi_player * strategy[(action, amount)], pi_opponent\n",
        "                )\n",
        "            else:\n",
        "                action_utilities[(action, amount)] = self._mccfr_recursive(\n",
        "                    new_state, traversing_player, pi_player,\n",
        "                    pi_opponent * strategy[(action, amount)]\n",
        "                )\n",
        "\n",
        "        # Calculate node utility\n",
        "        node_utility = sum(strategy[(action, amount)] * action_utilities[(action, amount)]\n",
        "                          for action, amount in legal_actions)\n",
        "\n",
        "        # Update regrets for traversing player\n",
        "        if current_player == traversing_player:\n",
        "            for action, amount in legal_actions:\n",
        "                regret = action_utilities[(action, amount)] - node_utility\n",
        "                self.regret_sum[info_state][(action, amount)] += pi_opponent * regret\n",
        "\n",
        "        return node_utility\n",
        "\n",
        "    def _apply_action(self, state: GameState, action: Action, amount: float) -> GameState:\n",
        "        \"\"\"Apply an action to create a new game state.\"\"\"\n",
        "        # Deep copy state\n",
        "        new_state = GameState(\n",
        "            players=state.players.copy(),\n",
        "            current_player=state.current_player,\n",
        "            pot_size=state.pot_size,\n",
        "            street=state.street,\n",
        "            board=state.board.copy(),\n",
        "            hands=state.hands.copy(),\n",
        "            bets=state.bets.copy(),\n",
        "            total_bets=state.total_bets.copy(),\n",
        "            action_history=state.action_history.copy()\n",
        "        )\n",
        "\n",
        "        player_id = state.current_player\n",
        "\n",
        "        # Apply action\n",
        "        if action == Action.FOLD:\n",
        "            new_state.is_terminal = True\n",
        "            new_state.players.remove(player_id)\n",
        "        elif action == Action.CHECK:\n",
        "            pass  # No bet change\n",
        "        elif action == Action.CALL:\n",
        "            call_amount = max(state.bets.values()) - state.bets.get(player_id, 0)\n",
        "            new_state.bets[player_id] += call_amount\n",
        "            new_state.total_bets[player_id] += call_amount\n",
        "            new_state.pot_size += call_amount\n",
        "        elif action in [Action.BET, Action.RAISE]:\n",
        "            new_state.bets[player_id] += amount\n",
        "            new_state.total_bets[player_id] += amount\n",
        "            new_state.pot_size += amount\n",
        "\n",
        "        # Add to action history\n",
        "        new_state.action_history.append((player_id, action, amount))\n",
        "\n",
        "        # Advance to next player or next street\n",
        "        if not new_state.is_terminal:\n",
        "            new_state.current_player = 1 - player_id  # Switch players\n",
        "\n",
        "            # Check if betting round is complete\n",
        "            if self._is_betting_round_complete(new_state):\n",
        "                new_state = self._advance_street(new_state)\n",
        "\n",
        "        return new_state\n",
        "\n",
        "    def _is_betting_round_complete(self, state: GameState) -> bool:\n",
        "        \"\"\"Check if the current betting round is complete.\"\"\"\n",
        "        # Simple check: all active players have equal bets\n",
        "        active_bets = [state.bets[p] for p in state.players if p in state.bets]\n",
        "        return len(set(active_bets)) <= 1\n",
        "\n",
        "    def _advance_street(self, state: GameState) -> GameState:\n",
        "        \"\"\"Advance to the next street (flop -> turn -> river).\"\"\"\n",
        "        street_progression = {\n",
        "            'preflop': ('flop', 3),\n",
        "            'flop': ('turn', 4),\n",
        "            'turn': ('river', 5),\n",
        "            'river': ('terminal', 5)\n",
        "        }\n",
        "\n",
        "        if state.street in street_progression:\n",
        "            next_street, board_size = street_progression[state.street]\n",
        "\n",
        "            if next_street == 'terminal':\n",
        "                state.is_terminal = True\n",
        "            else:\n",
        "                state.street = next_street\n",
        "                # Add community cards (simplified - would need proper deck tracking)\n",
        "                while len(state.board) < board_size:\n",
        "                    state.board.append('Xx')  # Placeholder\n",
        "\n",
        "                # Reset street bets\n",
        "                state.bets = {p: 0.0 for p in state.players}\n",
        "                state.current_player = 0  # Reset position\n",
        "\n",
        "        return state\n",
        "\n",
        "    def _get_utility(self, state: GameState, player_id: int) -> float:\n",
        "        \"\"\"Calculate utility (winnings) for a player in terminal state.\"\"\"\n",
        "        if player_id not in state.players:\n",
        "            # Player folded - lose total bets\n",
        "            return -state.total_bets.get(player_id, 0)\n",
        "        else:\n",
        "            # Player won - get pot minus their bets\n",
        "            return state.pot_size - state.total_bets.get(player_id, 0)\n",
        "\n",
        "    def _update_average_strategy(self):\n",
        "        \"\"\"Update the average strategy (policy) from strategy sums.\"\"\"\n",
        "        for info_state in self.regret_sum:\n",
        "            strategy = self.get_strategy(info_state,\n",
        "                                       list(self.regret_sum[info_state].keys()))\n",
        "\n",
        "            for action in strategy:\n",
        "                self.strategy_sum[info_state][action] += strategy[action]\n",
        "\n",
        "        self.strategy_updates += 1\n",
        "\n",
        "    def get_final_policy(self) -> Dict[str, Dict]:\n",
        "        \"\"\"Get the final average policy after training.\"\"\"\n",
        "        final_policy = {}\n",
        "\n",
        "        for info_state in self.strategy_sum:\n",
        "            total_sum = sum(self.strategy_sum[info_state].values())\n",
        "            if total_sum > 0:\n",
        "                final_policy[info_state] = {\n",
        "                    action: prob / total_sum\n",
        "                    for action, prob in self.strategy_sum[info_state].items()\n",
        "                }\n",
        "            else:\n",
        "                # Uniform distribution if no data\n",
        "                actions = list(self.strategy_sum[info_state].keys())\n",
        "                uniform_prob = 1.0 / len(actions) if actions else 1.0\n",
        "                final_policy[info_state] = {\n",
        "                    action: uniform_prob for action in actions\n",
        "                }\n",
        "\n",
        "        return final_policy\n",
        "\n",
        "    def save_policy(self, filepath: str):\n",
        "        \"\"\"Save the trained policy to disk.\"\"\"\n",
        "        policy_data = {\n",
        "            'final_policy': self.get_final_policy(),\n",
        "            'regret_sum': dict(self.regret_sum),\n",
        "            'strategy_sum': dict(self.strategy_sum),\n",
        "            'iteration_count': self.iteration_count,\n",
        "            'abstraction_models': self.abstraction_manager.kmeans_models\n",
        "        }\n",
        "\n",
        "        with open(filepath, 'wb') as f:\n",
        "            pickle.dump(policy_data, f)\n",
        "        print(f\"Policy saved to {filepath}\")\n",
        "\n",
        "    def load_policy(self, filepath: str):\n",
        "        \"\"\"Load a trained policy from disk.\"\"\"\n",
        "        with open(filepath, 'rb') as f:\n",
        "            policy_data = pickle.load(f)\n",
        "\n",
        "        self.regret_sum = defaultdict(lambda: defaultdict(float), policy_data['regret_sum'])\n",
        "        self.strategy_sum = defaultdict(lambda: defaultdict(float), policy_data['strategy_sum'])\n",
        "        self.iteration_count = policy_data['iteration_count']\n",
        "\n",
        "        if 'abstraction_models' in policy_data:\n",
        "            self.abstraction_manager.kmeans_models = policy_data['abstraction_models']\n",
        "\n",
        "        print(f\"Policy loaded from {filepath}\")\n",
        "\n",
        "\n",
        "# Example usage and testing\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=== Advanced MCCFR Poker Trainer ===\")\n",
        "\n",
        "    # Initialize trainer\n",
        "    trainer = AdvancedMCCFRTrainer()\n",
        "\n",
        "    # Train the policy\n",
        "    trainer.train(num_iterations=50000)\n",
        "\n",
        "    # Save the trained policy\n",
        "    trainer.save_policy(\"poker_cfr_policy.pkl\")\n",
        "\n",
        "    # Get final policy stats\n",
        "    final_policy = trainer.get_final_policy()\n",
        "    print(f\"\\nTraining Results:\")\n",
        "    print(f\"- Information states learned: {len(final_policy)}\")\n",
        "    print(f\"- Total iterations: {trainer.iteration_count}\")\n",
        "    print(f\"- Strategy updates: {trainer.strategy_updates}\")\n",
        "\n",
        "    # Example: Get strategy for a specific situation\n",
        "    example_info_state = list(final_policy.keys())[0] if final_policy else None\n",
        "    if example_info_state:\n",
        "        print(f\"\\nExample strategy for info state '{example_info_state}':\")\n",
        "        for action, prob in final_policy[example_info_state].items():\n",
        "            print(f\"  {action}: {prob:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ev71roF-2uTx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from collections import defaultdict, Counter\n",
        "import pickle\n",
        "import time\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "from enum import Enum\n",
        "\n",
        "# Import your optimized calculator\n",
        "from phevaluator import evaluate_cards\n",
        "\n",
        "# --- Basic Game Definitions ---\n",
        "SUITS = ['h', 'd', 'c', 's']\n",
        "RANKS = ['2', '3', '4', '5', '6', '7', '8', '9', 'T', 'J', 'Q', 'K', 'A']\n",
        "DECK = [r + s for r in RANKS for s in SUITS]\n",
        "RANK_MAP = {rank: i for i, rank in enumerate(RANKS)}\n",
        "\n",
        "class PotentialAwareCalculator:\n",
        "    \"\"\"Fixed version of your sophisticated calculator.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.cache = {}\n",
        "        print(\"PotentialAwareCalculator initialized.\")\n",
        "\n",
        "    def _calculate_current_equity(self, hand, board, remaining_deck, num_sims=200):\n",
        "        \"\"\"Reduced sims for performance but still meaningful.\"\"\"\n",
        "        wins = 0\n",
        "        cards_to_draw = 2 + (5 - len(board))\n",
        "\n",
        "        if len(remaining_deck) < cards_to_draw:\n",
        "            return 0.0\n",
        "\n",
        "        for _ in range(num_sims):\n",
        "            try:\n",
        "                samples = random.sample(remaining_deck, cards_to_draw)\n",
        "                opp_hand, board_runout = samples[:2], samples[2:]\n",
        "                final_board = board + board_runout\n",
        "\n",
        "                player_rank = evaluate_cards(*hand, *final_board)\n",
        "                opp_rank = evaluate_cards(*opp_hand, *final_board)\n",
        "\n",
        "                if player_rank < opp_rank:\n",
        "                    wins += 1\n",
        "                elif player_rank == opp_rank:\n",
        "                    wins += 0.5\n",
        "            except (ValueError, IndexError):\n",
        "                continue\n",
        "        return wins / num_sims if num_sims > 0 else 0\n",
        "\n",
        "    def _has_straight_in_ranks(self, rank_set):\n",
        "        \"\"\"Your original straight detection.\"\"\"\n",
        "        if len(rank_set) < 5:\n",
        "            return False\n",
        "\n",
        "        if all(x in rank_set for x in [12, 0, 1, 2, 3]):\n",
        "            return True\n",
        "\n",
        "        sorted_ranks = sorted(list(rank_set), reverse=True)\n",
        "        for i in range(len(sorted_ranks) - 4):\n",
        "            if sorted_ranks[i] - sorted_ranks[i+4] == 4:\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def _calculate_straight_outs(self, hand_and_board):\n",
        "        \"\"\"Your enhanced straight outs calculation.\"\"\"\n",
        "        if len(hand_and_board) < 3:\n",
        "            return 0\n",
        "\n",
        "        ranks_idx = [RANK_MAP[c[0]] for c in hand_and_board]\n",
        "        rank_set = set(ranks_idx)\n",
        "        straight_out_cards = set()\n",
        "\n",
        "        for missing_rank_idx in range(13):\n",
        "            if missing_rank_idx not in rank_set:\n",
        "                test_ranks = rank_set | {missing_rank_idx}\n",
        "                if self._has_straight_in_ranks(test_ranks):\n",
        "                    completing_rank_str = RANKS[missing_rank_idx]\n",
        "                    for suit in SUITS:\n",
        "                        card = completing_rank_str + suit\n",
        "                        if card not in hand_and_board:\n",
        "                            straight_out_cards.add(card)\n",
        "        return len(straight_out_cards)\n",
        "\n",
        "    def _calculate_potential(self, hand, board, remaining_deck):\n",
        "        \"\"\"Your potential calculation with the enhanced straight logic.\"\"\"\n",
        "        if len(board) == 5:\n",
        "            return 0.0, 0.0\n",
        "\n",
        "        hand_and_board = hand + board\n",
        "\n",
        "        # Flush potential\n",
        "        suit_counts = {s: sum(1 for c in hand_and_board if c[1] == s) for s in SUITS}\n",
        "        flush_potential = 0.0\n",
        "        flush_draw_suit = next((s for s, count in suit_counts.items() if count == 4), None)\n",
        "\n",
        "        if flush_draw_suit:\n",
        "            flush_outs = 13 - suit_counts[flush_draw_suit]\n",
        "            if len(board) == 3:\n",
        "                p_miss_turn = (len(remaining_deck) - flush_outs) / len(remaining_deck)\n",
        "                p_miss_river = (len(remaining_deck) - 1 - flush_outs) / (len(remaining_deck) - 1)\n",
        "                flush_potential = 1 - (p_miss_turn * p_miss_river)\n",
        "            elif len(board) == 4:\n",
        "                flush_potential = flush_outs / len(remaining_deck)\n",
        "\n",
        "        # Straight potential using your enhanced method\n",
        "        straight_potential = 0.0\n",
        "        current_rank = evaluate_cards(*hand_and_board)\n",
        "        if current_rank > 1609:\n",
        "            num_straight_outs = self._calculate_straight_outs(hand_and_board)\n",
        "            if num_straight_outs > 0:\n",
        "                if len(board) == 3:\n",
        "                    p_miss_turn = (len(remaining_deck) - num_straight_outs) / len(remaining_deck)\n",
        "                    p_miss_river = (len(remaining_deck) - 1 - num_straight_outs) / (len(remaining_deck) - 1)\n",
        "                    straight_potential = 1 - (p_miss_turn * p_miss_river)\n",
        "                elif len(board) == 4:\n",
        "                    straight_potential = num_straight_outs / len(remaining_deck)\n",
        "\n",
        "        return flush_potential, straight_potential\n",
        "\n",
        "    def _calculate_made_hand_potential(self, hand, board, remaining_deck):\n",
        "        \"\"\"Your made hand potential - properly implemented.\"\"\"\n",
        "        hand_and_board = hand + board\n",
        "        player_rank = evaluate_cards(*hand_and_board)\n",
        "\n",
        "        is_one_pair = 3003 <= player_rank <= 6185\n",
        "        is_two_pair = 1610 <= player_rank <= 3002\n",
        "\n",
        "        outs = 0\n",
        "\n",
        "        if is_one_pair:\n",
        "            if hand[0][0] == hand[1][0]:  # Pocket pair\n",
        "                board_ranks = [c[0] for c in board]\n",
        "                if hand[0][0] not in board_ranks:\n",
        "                    outs = 2  # Set outs\n",
        "                else:\n",
        "                    remaining_ranks = set(board_ranks) - {hand[0][0]}\n",
        "                    outs = len(remaining_ranks) * 3\n",
        "            else:\n",
        "                outs = 5  # Standard improvement outs\n",
        "        elif is_two_pair:\n",
        "            outs = 4  # Full house outs\n",
        "        elif 1610 > player_rank >= 167:  # Trips or better\n",
        "            outs = 7  # Boat/quads outs\n",
        "\n",
        "        # Convert to probability\n",
        "        if outs > 0 and len(remaining_deck) > 0:\n",
        "            if len(board) == 3:  # Flop\n",
        "                prob = 1 - ((len(remaining_deck) - outs) / len(remaining_deck)) * \\\n",
        "                          ((len(remaining_deck) - 1 - outs) / (len(remaining_deck) - 1))\n",
        "            else:  # Turn\n",
        "                prob = outs / len(remaining_deck)\n",
        "            return min(1.0, prob)\n",
        "\n",
        "        return 0.0\n",
        "\n",
        "    def _calculate_backdoor_potential(self, hand, board):\n",
        "        \"\"\"Your backdoor potential calculation.\"\"\"\n",
        "        if len(board) != 3:\n",
        "            return 0.0\n",
        "\n",
        "        hand_and_board = hand + board\n",
        "\n",
        "        # Backdoor flush\n",
        "        suit_counts = {s: sum(1 for c in hand_and_board if c[1] == s) for s in SUITS}\n",
        "        backdoor_flush = 0.0\n",
        "        for suit, count in suit_counts.items():\n",
        "            if count == 3:  # Need runner-runner\n",
        "                backdoor_flush = 0.04  # Approximate probability\n",
        "                break\n",
        "\n",
        "        # Backdoor straight\n",
        "        ranks = set(RANK_MAP[c[0]] for c in hand_and_board)\n",
        "        backdoor_straight = 0.0\n",
        "        if len(ranks) >= 3:\n",
        "            # Simplified: if we have 3+ ranks, some backdoor straight potential\n",
        "            backdoor_straight = 0.02\n",
        "\n",
        "        return max(backdoor_flush, backdoor_straight)\n",
        "\n",
        "    def _calculate_board_texture(self, board):\n",
        "        \"\"\"Your board texture calculation.\"\"\"\n",
        "        if len(board) < 3:\n",
        "            return 0.0, 0.0\n",
        "\n",
        "        # Board suitedness\n",
        "        board_suits = {card[1] for card in board}\n",
        "        if len(board_suits) == 1:\n",
        "            board_suitedness = 1.0  # Monotone\n",
        "        elif len(board_suits) == 2:\n",
        "            board_suitedness = 0.5  # Two-tone\n",
        "        else:\n",
        "            board_suitedness = 0.0  # Rainbow\n",
        "\n",
        "        # Board connectivity\n",
        "        board_ranks_idx = sorted([RANK_MAP[c[0]] for c in board])\n",
        "        max_span = board_ranks_idx[-1] - board_ranks_idx[0]\n",
        "        normalized_span = max_span / 12.0\n",
        "        board_connectivity = 1.0 - normalized_span\n",
        "\n",
        "        return board_suitedness, board_connectivity\n",
        "\n",
        "    def _is_nut_hand(self, hand, board):\n",
        "        \"\"\"Your nut hand detection - optimized.\"\"\"\n",
        "        hand_and_board = hand + board\n",
        "        player_rank = evaluate_cards(*hand_and_board)\n",
        "\n",
        "        # Quick checks for obvious nuts\n",
        "        if player_rank <= 10:  # Straight flush\n",
        "            return 1.0\n",
        "        if player_rank <= 166:  # Four of a kind\n",
        "            return 0.9\n",
        "        if player_rank <= 322:  # Full house\n",
        "            return 0.8\n",
        "        if player_rank <= 1609:  # Flush or straight\n",
        "            return 0.7\n",
        "\n",
        "        # For other hands, use rank-based approximation\n",
        "        return min(1.0, (7463 - player_rank) / 7463)\n",
        "\n",
        "    def calculate_feature_vector(self, hand, board):\n",
        "        \"\"\"Your main feature vector calculation - with all methods implemented.\"\"\"\n",
        "        cache_key = tuple(sorted(hand + board))\n",
        "        if cache_key in self.cache:\n",
        "            return self.cache[cache_key]\n",
        "\n",
        "        known_cards = hand + board\n",
        "        remaining_deck = [card for card in DECK if card not in known_cards]\n",
        "\n",
        "        if len(remaining_deck) < 2:\n",
        "            return [0.5] * 8\n",
        "\n",
        "        try:\n",
        "            equity = self._calculate_current_equity(hand, board, remaining_deck)\n",
        "            flush_pot, straight_pot = self._calculate_potential(hand, board, remaining_deck)\n",
        "            made_hand_pot = self._calculate_made_hand_potential(hand, board, remaining_deck)\n",
        "            board_suit, board_conn = self._calculate_board_texture(board)\n",
        "            backdoor_pot = self._calculate_backdoor_potential(hand, board)\n",
        "            nut_strength = self._is_nut_hand(hand, board)\n",
        "\n",
        "            feature_vector = [\n",
        "                equity,           # Current winning probability\n",
        "                flush_pot,        # Flush potential\n",
        "                straight_pot,     # Straight potential\n",
        "                made_hand_pot,    # Made hand improvement potential\n",
        "                board_suit,       # Board suitedness\n",
        "                board_conn,       # Board connectivity\n",
        "                backdoor_pot,     # Backdoor potential\n",
        "                nut_strength      # Relative hand strength\n",
        "            ]\n",
        "\n",
        "            # Validate and clamp values\n",
        "            feature_vector = [max(0.0, min(1.0, float(x))) for x in feature_vector]\n",
        "\n",
        "            self.cache[cache_key] = feature_vector\n",
        "            return feature_vector\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in feature calculation: {e}\")\n",
        "            return [0.5] * 8\n",
        "\n",
        "class FixedAbstractionManager:\n",
        "    \"\"\"Your abstraction manager with the critical bug fixed.\"\"\"\n",
        "    def __init__(self, n_clusters_per_round=20):\n",
        "        self.calculator = PotentialAwareCalculator()\n",
        "        self.n_clusters = n_clusters_per_round\n",
        "        self.kmeans_models = {}\n",
        "        self.cluster_offsets = {'flop': 0, 'turn': 20, 'river': 40}\n",
        "\n",
        "        # Card definitions\n",
        "        self.SUITS = SUITS\n",
        "        self.RANKS = RANKS\n",
        "        self.DECK = DECK\n",
        "\n",
        "        print(\"Fixed AbstractionManager initialized.\")\n",
        "\n",
        "    def _generate_valid_hand_board(self, num_board_cards):\n",
        "        \"\"\"Your original method.\"\"\"\n",
        "        max_attempts = 100\n",
        "\n",
        "        for attempt in range(max_attempts):\n",
        "            try:\n",
        "                deck = self.DECK.copy()\n",
        "                random.shuffle(deck)\n",
        "\n",
        "                total_cards_needed = 2 + num_board_cards\n",
        "                if total_cards_needed > len(deck):\n",
        "                    continue\n",
        "\n",
        "                hand = deck[:2]\n",
        "                board = deck[2:2 + num_board_cards]\n",
        "\n",
        "                if len(hand) != 2 or len(board) != num_board_cards:\n",
        "                    continue\n",
        "\n",
        "                test_vector = self.calculator.calculate_feature_vector(hand, board)\n",
        "\n",
        "                if (isinstance(test_vector, list) and\n",
        "                    len(test_vector) > 0 and\n",
        "                    all(isinstance(x, (int, float)) and not np.isnan(x) for x in test_vector)):\n",
        "                    return hand, board\n",
        "\n",
        "            except Exception as e:\n",
        "                continue\n",
        "\n",
        "        return ['As', 'Kh'], ['Qc', '7d', '2s'][:num_board_cards]\n",
        "\n",
        "    def _generate_data_for_round(self, n_samples, round_name):\n",
        "        \"\"\"Your data generation with better progress reporting.\"\"\"\n",
        "        print(f\"--- Generating {n_samples} feature vectors for {round_name} ---\")\n",
        "\n",
        "        feature_vectors = []\n",
        "        num_board_cards = {'flop': 3, 'turn': 4, 'river': 5}[round_name]\n",
        "        failed_generations = 0\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        for i in range(n_samples * 2):\n",
        "            if len(feature_vectors) >= n_samples:\n",
        "                break\n",
        "\n",
        "            if (i + 1) % 5000 == 0:\n",
        "                print(f\"  ...attempting {i+1}, collected {len(feature_vectors)}/{n_samples}...\")\n",
        "\n",
        "            try:\n",
        "                hand, board = self._generate_valid_hand_board(num_board_cards)\n",
        "                vector = self.calculator.calculate_feature_vector(hand, board)\n",
        "\n",
        "                if self._validate_feature_vector(vector):\n",
        "                    feature_vectors.append(vector)\n",
        "                else:\n",
        "                    failed_generations += 1\n",
        "\n",
        "            except Exception as e:\n",
        "                failed_generations += 1\n",
        "                continue\n",
        "\n",
        "        duration = time.time() - start_time\n",
        "\n",
        "        if len(feature_vectors) < self.n_clusters:\n",
        "            raise ValueError(f\"Only generated {len(feature_vectors)} valid vectors, \"\n",
        "                           f\"need at least {self.n_clusters} for clustering\")\n",
        "\n",
        "        print(f\"Generated {len(feature_vectors)} valid vectors \"\n",
        "              f\"({failed_generations} failed) in {duration:.2f}s\")\n",
        "\n",
        "        return np.array(feature_vectors)\n",
        "\n",
        "    def _validate_feature_vector(self, vector):\n",
        "        \"\"\"Your validation method.\"\"\"\n",
        "        if not isinstance(vector, (list, tuple, np.ndarray)):\n",
        "            return False\n",
        "\n",
        "        if len(vector) == 0:\n",
        "            return False\n",
        "\n",
        "        for val in vector:\n",
        "            if not isinstance(val, (int, float)):\n",
        "                return False\n",
        "            if np.isnan(val) or np.isinf(val):\n",
        "                return False\n",
        "\n",
        "        for val in vector:\n",
        "            if val < 0 or val > 1:\n",
        "                return False\n",
        "\n",
        "        return True\n",
        "\n",
        "    def _remove_duplicate_vectors(self, vectors):\n",
        "        \"\"\"Your deduplication method.\"\"\"\n",
        "        unique_vectors = []\n",
        "        seen = set()\n",
        "\n",
        "        for vector in vectors:\n",
        "            vector_tuple = tuple(np.round(vector, 6))\n",
        "            if vector_tuple not in seen:\n",
        "                seen.add(vector_tuple)\n",
        "                unique_vectors.append(vector)\n",
        "\n",
        "        print(f\"Removed {len(vectors) - len(unique_vectors)} duplicate vectors\")\n",
        "        return np.array(unique_vectors)\n",
        "\n",
        "    def train_all_postflop_models(self, n_samples_per_round=10000):\n",
        "        \"\"\"Your training method with sklearn import fix.\"\"\"\n",
        "        print(\"\\n=== STARTING K-MEANS MODEL TRAINING FOR ALL ROUNDS ===\")\n",
        "\n",
        "        # Import sklearn here to handle missing dependency gracefully\n",
        "        try:\n",
        "            from sklearn.cluster import KMeans\n",
        "            from sklearn.metrics import silhouette_score\n",
        "        except ImportError:\n",
        "            print(\"ERROR: sklearn not installed. Install with: pip install scikit-learn\")\n",
        "            return\n",
        "\n",
        "        for round_name in ['flop', 'turn', 'river']:\n",
        "            try:\n",
        "                print(f\"\\n--- Training {round_name} model ---\")\n",
        "\n",
        "                data = self._generate_data_for_round(n_samples_per_round, round_name)\n",
        "                data = self._remove_duplicate_vectors(data)\n",
        "\n",
        "                if len(data) < self.n_clusters:\n",
        "                    print(f\"Warning: Only {len(data)} unique vectors for {self.n_clusters} clusters\")\n",
        "                    actual_clusters = min(self.n_clusters, len(data))\n",
        "                else:\n",
        "                    actual_clusters = self.n_clusters\n",
        "\n",
        "                if data.ndim == 1:\n",
        "                    data = data.reshape(-1, 1)\n",
        "\n",
        "                print(f\"Training K-Means on {data.shape[0]} vectors with {data.shape[1]} features\")\n",
        "                print(f\"Using {actual_clusters} clusters\")\n",
        "\n",
        "                kmeans = KMeans(\n",
        "                    n_clusters=actual_clusters,\n",
        "                    random_state=42,\n",
        "                    n_init=10,\n",
        "                    max_iter=300\n",
        "                )\n",
        "\n",
        "                kmeans.fit(data)\n",
        "                self.kmeans_models[round_name] = kmeans\n",
        "\n",
        "                if len(data) > actual_clusters:\n",
        "                    labels = kmeans.predict(data)\n",
        "                    silhouette = silhouette_score(data, labels)\n",
        "                    print(f\"Silhouette Score: {silhouette:.3f}\")\n",
        "\n",
        "                print(f\"{round_name} model trained successfully!\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error training {round_name} model: {e}\")\n",
        "                self._create_fallback_model(round_name)\n",
        "\n",
        "    def _create_fallback_model(self, round_name):\n",
        "        \"\"\"Your fallback model creation.\"\"\"\n",
        "        print(f\"Creating fallback model for {round_name}\")\n",
        "\n",
        "        try:\n",
        "            from sklearn.cluster import KMeans\n",
        "            dummy_data = np.random.rand(self.n_clusters * 10, 8)\n",
        "            kmeans = KMeans(n_clusters=self.n_clusters, random_state=42)\n",
        "            kmeans.fit(dummy_data)\n",
        "            self.kmeans_models[round_name] = kmeans\n",
        "        except ImportError:\n",
        "            print(\"Cannot create fallback model without sklearn\")\n",
        "\n",
        "    def get_postflop_bucket(self, hand, board):\n",
        "        \"\"\"Your method with the critical bug FIXED.\"\"\"\n",
        "        try:\n",
        "            if not isinstance(hand, list) or len(hand) != 2:\n",
        "                raise ValueError(\"Hand must be a list of 2 cards\")\n",
        "            if not isinstance(board, list) or len(board) not in [3, 4, 5]:\n",
        "                raise ValueError(\"Board must have 3, 4, or 5 cards\")\n",
        "\n",
        "            num_board_cards = len(board)\n",
        "            round_map = {3: 'flop', 4: 'turn', 5: 'river'}\n",
        "            round_name = round_map[num_board_cards]\n",
        "\n",
        "            if round_name not in self.kmeans_models:\n",
        "                raise RuntimeError(f\"No trained model for {round_name}\")\n",
        "\n",
        "            feature_vector = self.calculator.calculate_feature_vector(hand, board)\n",
        "\n",
        "            if not self._validate_feature_vector(feature_vector):\n",
        "                print(f\"Warning: Invalid feature vector {feature_vector}, using fallback\")\n",
        "                return self.cluster_offsets[round_name]\n",
        "\n",
        "            model = self.kmeans_models[round_name]\n",
        "            vector_array = np.array([feature_vector])\n",
        "\n",
        "            predicted_cluster = model.predict(vector_array)[0]\n",
        "\n",
        "            # THE CRITICAL BUG FIX - was: final_bucket_idclass\n",
        "            final_bucket_id = predicted_cluster + self.cluster_offsets[round_name]\n",
        "\n",
        "            # Ensure bucket ID is in valid range\n",
        "            min_bucket = self.cluster_offsets[round_name]\n",
        "            max_bucket = min_bucket + self.n_clusters - 1\n",
        "            final_bucket_id = max(min_bucket, min(max_bucket, final_bucket_id))\n",
        "\n",
        "            return int(final_bucket_id)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in get_postflop_bucket: {e}\")\n",
        "            round_name = {3: 'flop', 4: 'turn', 5: 'river'}.get(len(board), 'flop')\n",
        "            return self.cluster_offsets[round_name]\n",
        "\n",
        "    def save_models(self, filepath):\n",
        "        \"\"\"Your save method.\"\"\"\n",
        "        try:\n",
        "            model_data = {\n",
        "                'kmeans_models': self.kmeans_models,\n",
        "                'n_clusters': self.n_clusters,\n",
        "                'cluster_offsets': self.cluster_offsets\n",
        "            }\n",
        "\n",
        "            with open(filepath, 'wb') as f:\n",
        "                pickle.dump(model_data, f)\n",
        "\n",
        "            print(f\"Models saved to {filepath}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving models: {e}\")\n",
        "\n",
        "    def load_models(self, filepath):\n",
        "        \"\"\"Your load method.\"\"\"\n",
        "        try:\n",
        "            with open(filepath, 'rb') as f:\n",
        "                model_data = pickle.load(f)\n",
        "\n",
        "            self.kmeans_models = model_data['kmeans_models']\n",
        "            self.n_clusters = model_data['n_clusters']\n",
        "            self.cluster_offsets = model_data['cluster_offsets']\n",
        "\n",
        "            print(f\"Models loaded from {filepath}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading models: {e}\")\n",
        "\n",
        "# Your original Action and GameState classes\n",
        "class Action(Enum):\n",
        "    FOLD = \"fold\"\n",
        "    CHECK = \"check\"\n",
        "    CALL = \"call\"\n",
        "    BET = \"bet\"\n",
        "    RAISE = \"raise\"\n",
        "\n",
        "@dataclass\n",
        "class GameState:\n",
        "    \"\"\"Your original GameState class.\"\"\"\n",
        "    players: List[int]\n",
        "    current_player: int\n",
        "    pot_size: float\n",
        "    street: str\n",
        "    board: List[str]\n",
        "    hands: Dict[int, List[str]]\n",
        "    bets: Dict[int, float]\n",
        "    total_bets: Dict[int, float]\n",
        "    action_history: List[Tuple[int, Action, float]]\n",
        "    is_terminal: bool = False\n",
        "\n",
        "# Key fixes for the MCCFR training performance issues\n",
        "\n",
        "class OptimizedMCCFRTrainer:\n",
        "    \"\"\"Fixed version of your MCCFR trainer with performance optimizations.\"\"\"\n",
        "\n",
        "    def __init__(self, abstraction_manager=None, initial_stack=1000.0):\n",
        "        print(\"Initializing Optimized MCCFR Trainer...\")\n",
        "\n",
        "        if abstraction_manager is None:\n",
        "            self.abstraction_manager = FixedAbstractionManager(n_clusters_per_round=20)\n",
        "            print(\"Training abstraction models...\")\n",
        "            self.abstraction_manager.train_all_postflop_models(n_samples_per_round=5000)  # Reduced\n",
        "        else:\n",
        "            self.abstraction_manager = abstraction_manager\n",
        "\n",
        "        self.initial_stack = initial_stack\n",
        "\n",
        "        # CFR data structures\n",
        "        self.regret_sum = defaultdict(lambda: defaultdict(float))\n",
        "        self.strategy_sum = defaultdict(lambda: defaultdict(float))\n",
        "        self.policy = defaultdict(lambda: defaultdict(float))\n",
        "\n",
        "        self.iteration_count = 0\n",
        "        self.strategy_updates = 0\n",
        "\n",
        "        # CRITICAL FIX 1: Add recursion depth tracking\n",
        "        self.max_recursion_depth = 15\n",
        "        self.current_depth = 0\n",
        "\n",
        "        # CRITICAL FIX 2: Add action sequence tracking to prevent infinite loops\n",
        "        self.action_sequence_cache = {}\n",
        "\n",
        "        self._initialize_preflop_buckets()\n",
        "\n",
        "        print(\"Optimized MCCFR Trainer initialized successfully.\")\n",
        "\n",
        "    def _initialize_preflop_buckets(self):\n",
        "        \"\"\"Simplified preflop bucketing for testing.\"\"\"\n",
        "        self.preflop_buckets = {}\n",
        "\n",
        "        # Simplified bucketing - just a few categories\n",
        "        premium_hands = ['AA', 'KK', 'QQ', 'AK']\n",
        "        strong_hands = ['JJ', 'TT', 'AQ', 'AJ']\n",
        "\n",
        "        bucket_id = 60\n",
        "        for hand in premium_hands:\n",
        "            self.preflop_buckets[hand] = bucket_id\n",
        "        bucket_id += 1\n",
        "\n",
        "        for hand in strong_hands:\n",
        "            self.preflop_buckets[hand] = bucket_id\n",
        "        bucket_id += 1\n",
        "\n",
        "    def get_preflop_bucket(self, hand: List[str]) -> int:\n",
        "        \"\"\"Simplified preflop bucketing.\"\"\"\n",
        "        ranks = sorted([card[0] for card in hand], key=lambda x: RANKS.index(x), reverse=True)\n",
        "        suits = [card[1] for card in hand]\n",
        "\n",
        "        if ranks[0] == ranks[1]:\n",
        "            hand_str = ranks[0] + ranks[0]\n",
        "        else:\n",
        "            suited = 's' if suits[0] == suits[1] else 'o'\n",
        "            hand_str = ''.join(ranks) + suited\n",
        "\n",
        "        return self.preflop_buckets.get(hand_str, 79)\n",
        "\n",
        "    def get_info_state(self, state: GameState, player_id: int) -> str:\n",
        "        \"\"\"CRITICAL FIX 3: Simplified information state to prevent explosion.\"\"\"\n",
        "        hand = state.hands[player_id]\n",
        "        board = state.board\n",
        "\n",
        "        # Get bucket ID\n",
        "        if state.street == 'preflop':\n",
        "            bucket_id = self.get_preflop_bucket(hand)\n",
        "        else:\n",
        "            bucket_id = self.abstraction_manager.get_postflop_bucket(hand, board)\n",
        "\n",
        "        # SIMPLIFIED: Only include essential info to prevent state explosion\n",
        "        recent_actions = state.action_history[-3:] if len(state.action_history) > 3 else state.action_history\n",
        "        action_str = ''.join([f\"{a.value[0]}\" for _, a, _ in recent_actions])\n",
        "\n",
        "        pot_ratio = min(9, int(state.pot_size / 10))  # Discretize pot size\n",
        "\n",
        "        info_state = f\"B{bucket_id}S{state.street[0]}A{action_str}P{pot_ratio}\"\n",
        "        return info_state\n",
        "\n",
        "    def get_legal_actions(self, state: GameState, player_id: int) -> List[Tuple[Action, float]]:\n",
        "        \"\"\"CRITICAL FIX 4: Simplified action space to prevent explosion.\"\"\"\n",
        "        actions = []\n",
        "        to_call = max(state.bets.values()) - state.bets.get(player_id, 0)\n",
        "        stack_size = self.initial_stack - state.total_bets.get(player_id, 0)\n",
        "\n",
        "        # Always allow fold if facing a bet\n",
        "        if to_call > 0:\n",
        "            actions.append((Action.FOLD, 0))\n",
        "\n",
        "        # Check/Call\n",
        "        if to_call == 0:\n",
        "            actions.append((Action.CHECK, 0))\n",
        "        else:\n",
        "            if to_call <= stack_size:\n",
        "                actions.append((Action.CALL, to_call))\n",
        "\n",
        "        # SIMPLIFIED: Only 2 bet sizes instead of 5\n",
        "        pot_bet = state.pot_size\n",
        "        min_bet = max(to_call * 2, pot_bet * 0.5) if to_call > 0 else pot_bet * 0.5\n",
        "\n",
        "        if pot_bet <= stack_size and pot_bet >= min_bet:\n",
        "            if to_call == 0:\n",
        "                actions.append((Action.BET, pot_bet))\n",
        "            else:\n",
        "                actions.append((Action.RAISE, pot_bet))\n",
        "\n",
        "        # All-in as second option\n",
        "        if stack_size > pot_bet and stack_size >= min_bet:\n",
        "            if to_call == 0:\n",
        "                actions.append((Action.BET, stack_size))\n",
        "            else:\n",
        "                actions.append((Action.RAISE, stack_size))\n",
        "\n",
        "        return actions if actions else [(Action.FOLD, 0)]\n",
        "\n",
        "    def get_strategy(self, info_state: str, legal_actions: List[Tuple[Action, float]]) -> Dict[Tuple[Action, float], float]:\n",
        "        \"\"\"Your original regret matching - no changes needed.\"\"\"\n",
        "        strategy = {}\n",
        "        regret_sum = sum(max(0, self.regret_sum[info_state][action]) for action, _ in legal_actions)\n",
        "\n",
        "        if regret_sum > 0:\n",
        "            for action, amount in legal_actions:\n",
        "                strategy[(action, amount)] = max(0, self.regret_sum[info_state][(action, amount)]) / regret_sum\n",
        "        else:\n",
        "            uniform_prob = 1.0 / len(legal_actions)\n",
        "            for action, amount in legal_actions:\n",
        "                strategy[(action, amount)] = uniform_prob\n",
        "\n",
        "        return strategy\n",
        "\n",
        "    def train(self, num_iterations: int = 1000):  # Reduced default\n",
        "        \"\"\"CRITICAL FIX 5: Better training loop with timeout protection.\"\"\"\n",
        "        print(f\"\\n=== Starting Optimized MCCFR Training for {num_iterations} iterations ===\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        for i in range(num_iterations):\n",
        "            self.iteration_count += 1\n",
        "\n",
        "            # Progress reporting\n",
        "            if (i + 1) % 100 == 0:\n",
        "                elapsed = time.time() - start_time\n",
        "                print(f\"Iteration {i+1}/{num_iterations} | \"\n",
        "                      f\"Time: {elapsed:.1f}s | \"\n",
        "                      f\"States: {len(self.regret_sum)}\")\n",
        "\n",
        "            try:\n",
        "                # CRITICAL: Reset depth counter for each iteration\n",
        "                self.current_depth = 0\n",
        "                self._run_mccfr_iteration()\n",
        "\n",
        "                # Timeout protection\n",
        "                if time.time() - start_time > 300:  # 5 minute timeout\n",
        "                    print(f\"Training timeout after {i+1} iterations\")\n",
        "                    break\n",
        "\n",
        "            except RecursionError:\n",
        "                print(f\"Recursion limit hit at iteration {i+1}\")\n",
        "                continue\n",
        "            except Exception as e:\n",
        "                print(f\"Error in iteration {i+1}: {e}\")\n",
        "                continue\n",
        "\n",
        "            if i % 50 == 0:  # More frequent strategy updates\n",
        "                self._update_average_strategy()\n",
        "\n",
        "        total_time = time.time() - start_time\n",
        "        print(f\"Training complete! Total time: {total_time:.1f}s\")\n",
        "        print(f\"Final policy contains {len(self.policy)} information states\")\n",
        "\n",
        "    def _run_mccfr_iteration(self):\n",
        "        \"\"\"CRITICAL FIX 6: Simplified iteration with better initial state.\"\"\"\n",
        "        initial_state = self._create_simple_game_state()\n",
        "\n",
        "        # Run MCCFR for both players\n",
        "        for player_id in [0, 1]:\n",
        "            self.current_depth = 0  # Reset depth\n",
        "            try:\n",
        "                self._mccfr_recursive(initial_state, player_id, 1.0, 1.0)\n",
        "            except Exception as e:\n",
        "                # Gracefully handle errors and continue\n",
        "                continue\n",
        "\n",
        "    def _create_simple_game_state(self) -> GameState:\n",
        "        \"\"\"CRITICAL FIX 7: Simplified initial game state.\"\"\"\n",
        "        deck = DECK.copy()\n",
        "        random.shuffle(deck)\n",
        "\n",
        "        # Simple preflop state\n",
        "        hands = {0: deck[:2], 1: deck[2:4]}\n",
        "\n",
        "        state = GameState(\n",
        "            players=[0, 1],\n",
        "            current_player=0,\n",
        "            pot_size=3.0,\n",
        "            street='preflop',\n",
        "            board=[],\n",
        "            hands=hands,\n",
        "            bets={0: 1.0, 1: 2.0},  # Small blind, big blind\n",
        "            total_bets={0: 1.0, 1: 2.0},\n",
        "            action_history=[]\n",
        "        )\n",
        "\n",
        "        return state\n",
        "\n",
        "    def _mccfr_recursive(self, state: GameState, traversing_player: int,\n",
        "                         pi_player: float, pi_opponent: float) -> float:\n",
        "        \"\"\"CRITICAL FIX 8: Protected recursive function with depth limits.\"\"\"\n",
        "\n",
        "        # CRITICAL: Depth protection\n",
        "        self.current_depth += 1\n",
        "        if self.current_depth > self.max_recursion_depth:\n",
        "            self.current_depth -= 1\n",
        "            return self._get_utility(state, traversing_player)\n",
        "\n",
        "        # Terminal state check\n",
        "        if state.is_terminal:\n",
        "            self.current_depth -= 1\n",
        "            return self._get_utility(state, traversing_player)\n",
        "\n",
        "        # Action sequence protection against infinite loops\n",
        "        action_sequence = tuple((p, a.value, amt) for p, a, amt in state.action_history[-5:])\n",
        "        if len(state.action_history) > 10:  # Reduced from 20\n",
        "            self.current_depth -= 1\n",
        "            return self._get_utility(state, traversing_player)\n",
        "\n",
        "        current_player = state.current_player\n",
        "        info_state = self.get_info_state(state, current_player)\n",
        "        legal_actions = self.get_legal_actions(state, current_player)\n",
        "\n",
        "        if not legal_actions:\n",
        "            self.current_depth -= 1\n",
        "            return self._get_utility(state, traversing_player)\n",
        "\n",
        "        strategy = self.get_strategy(info_state, legal_actions)\n",
        "\n",
        "        # Calculate utilities for each action\n",
        "        action_utilities = {}\n",
        "        for action, amount in legal_actions:\n",
        "            try:\n",
        "                new_state = self._apply_action(state, action, amount)\n",
        "\n",
        "                if current_player == traversing_player:\n",
        "                    action_utilities[(action, amount)] = self._mccfr_recursive(\n",
        "                        new_state, traversing_player,\n",
        "                        pi_player * strategy[(action, amount)], pi_opponent\n",
        "                    )\n",
        "                else:\n",
        "                    action_utilities[(action, amount)] = self._mccfr_recursive(\n",
        "                        new_state, traversing_player, pi_player,\n",
        "                        pi_opponent * strategy[(action, amount)]\n",
        "                    )\n",
        "            except Exception:\n",
        "                # Fallback utility if recursion fails\n",
        "                action_utilities[(action, amount)] = 0.0\n",
        "\n",
        "        # Node utility calculation\n",
        "        node_utility = sum(strategy[(action, amount)] * action_utilities[(action, amount)]\n",
        "                          for action, amount in legal_actions)\n",
        "\n",
        "        # Update regrets\n",
        "        if current_player == traversing_player:\n",
        "            for action, amount in legal_actions:\n",
        "                regret = action_utilities[(action, amount)] - node_utility\n",
        "                self.regret_sum[info_state][(action, amount)] += pi_opponent * regret\n",
        "\n",
        "        self.current_depth -= 1\n",
        "        return node_utility\n",
        "\n",
        "    def _apply_action(self, state: GameState, action: Action, amount: float) -> GameState:\n",
        "        \"\"\"CRITICAL FIX 9: Simplified action application.\"\"\"\n",
        "        from copy import copy\n",
        "\n",
        "        # Shallow copy for performance\n",
        "        new_state = copy(state)\n",
        "        new_state.bets = state.bets.copy()\n",
        "        new_state.total_bets = state.total_bets.copy()\n",
        "        new_state.players = state.players.copy()\n",
        "        new_state.action_history = state.action_history.copy()\n",
        "        new_state.hands = state.hands.copy()\n",
        "        new_state.board = state.board.copy()\n",
        "\n",
        "        player_id = state.current_player\n",
        "\n",
        "        # Apply the action\n",
        "        if action == Action.FOLD:\n",
        "            new_state.is_terminal = True\n",
        "            if player_id in new_state.players:\n",
        "                new_state.players.remove(player_id)\n",
        "        elif action == Action.CHECK:\n",
        "            pass  # No bet change\n",
        "        elif action == Action.CALL:\n",
        "            call_amount = max(state.bets.values()) - state.bets.get(player_id, 0)\n",
        "            new_state.bets[player_id] += call_amount\n",
        "            new_state.total_bets[player_id] += call_amount\n",
        "            new_state.pot_size += call_amount\n",
        "        elif action in [Action.BET, Action.RAISE]:\n",
        "            new_state.bets[player_id] += amount\n",
        "            new_state.total_bets[player_id] += amount\n",
        "            new_state.pot_size += amount\n",
        "\n",
        "        # Add to history\n",
        "        new_state.action_history.append((player_id, action, amount))\n",
        "\n",
        "        # CRITICAL FIX 10: Simplified game advancement\n",
        "        if not new_state.is_terminal:\n",
        "            new_state.current_player = 1 - player_id\n",
        "\n",
        "            # Simple completion check\n",
        "            if len(new_state.action_history) >= 4:  # Both players acted twice\n",
        "                new_state = self._try_advance_street(new_state)\n",
        "            elif action in [Action.CHECK, Action.CALL] and len(new_state.action_history) >= 2:\n",
        "                # Check if both players checked or one called\n",
        "                last_two = new_state.action_history[-2:]\n",
        "                if all(act in [Action.CHECK, Action.CALL] for _, act, _ in last_two):\n",
        "                    new_state = self._try_advance_street(new_state)\n",
        "\n",
        "        return new_state\n",
        "\n",
        "    def _try_advance_street(self, state: GameState) -> GameState:\n",
        "        \"\"\"CRITICAL FIX 11: Simplified street advancement.\"\"\"\n",
        "        street_map = {\n",
        "            'preflop': ('flop', 3),\n",
        "            'flop': ('turn', 4),\n",
        "            'turn': ('river', 5),\n",
        "            'river': ('terminal', 5)\n",
        "        }\n",
        "\n",
        "        if state.street in street_map:\n",
        "            next_street, target_board_size = street_map[state.street]\n",
        "\n",
        "            if next_street == 'terminal':\n",
        "                state.is_terminal = True\n",
        "            else:\n",
        "                # Deal cards to reach target board size\n",
        "                cards_needed = target_board_size - len(state.board)\n",
        "                if cards_needed > 0:\n",
        "                    # Get available cards\n",
        "                    used_cards = set()\n",
        "                    for hand in state.hands.values():\n",
        "                        used_cards.update(hand)\n",
        "                    used_cards.update(state.board)\n",
        "\n",
        "                    available_cards = [c for c in DECK if c not in used_cards]\n",
        "                    random.shuffle(available_cards)\n",
        "\n",
        "                    # Deal new cards\n",
        "                    new_cards = available_cards[:cards_needed]\n",
        "                    state.board.extend(new_cards)\n",
        "\n",
        "                state.street = next_street\n",
        "                state.bets = {p: 0.0 for p in state.players}\n",
        "                state.current_player = 0\n",
        "\n",
        "        return state\n",
        "\n",
        "    def _get_utility(self, state: GameState, player_id: int) -> float:\n",
        "        \"\"\"CRITICAL FIX 12: Simplified utility calculation.\"\"\"\n",
        "        if player_id not in state.players:\n",
        "            return -state.total_bets.get(player_id, 0)\n",
        "\n",
        "        if len(state.players) == 1:\n",
        "            return state.pot_size - state.total_bets.get(player_id, 0)\n",
        "\n",
        "        # Simplified showdown\n",
        "        if len(state.board) >= 3:  # Any postflop situation\n",
        "            try:\n",
        "                # Use your hand evaluator if available\n",
        "                player_hand = state.hands[player_id] + state.board\n",
        "                if len(player_hand) >= 5:\n",
        "                    player_rank = evaluate_cards(*player_hand)\n",
        "\n",
        "                    best_opponent_rank = float('inf')\n",
        "                    for opp_id in state.players:\n",
        "                        if opp_id != player_id:\n",
        "                            opp_hand = state.hands[opp_id] + state.board\n",
        "                            if len(opp_hand) >= 5:\n",
        "                                opp_rank = evaluate_cards(*opp_hand)\n",
        "                                best_opponent_rank = min(best_opponent_rank, opp_rank)\n",
        "\n",
        "                    if best_opponent_rank == float('inf'):\n",
        "                        # No valid opponent hands\n",
        "                        return state.pot_size - state.total_bets.get(player_id, 0)\n",
        "\n",
        "                    if player_rank < best_opponent_rank:\n",
        "                        return state.pot_size - state.total_bets.get(player_id, 0)\n",
        "                    elif player_rank == best_opponent_rank:\n",
        "                        return (state.pot_size / len(state.players)) - state.total_bets.get(player_id, 0)\n",
        "                    else:\n",
        "                        return -state.total_bets.get(player_id, 0)\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        # Fallback: random outcome weighted by pot investment\n",
        "        random_outcome = random.choice([1, -1])\n",
        "        return random_outcome * (state.pot_size / 2) - state.total_bets.get(player_id, 0)\n",
        "\n",
        "    def _update_average_strategy(self):\n",
        "        \"\"\"Your original method - no changes needed.\"\"\"\n",
        "        for info_state in self.regret_sum:\n",
        "            actions = list(self.regret_sum[info_state].keys())\n",
        "            strategy = self.get_strategy(info_state, actions)\n",
        "\n",
        "            for action in strategy:\n",
        "                self.strategy_sum[info_state][action] += strategy[action]\n",
        "\n",
        "        self.strategy_updates += 1\n",
        "\n",
        "    def get_final_policy(self) -> Dict[str, Dict]:\n",
        "        \"\"\"Your original method - no changes needed.\"\"\"\n",
        "        final_policy = {}\n",
        "\n",
        "        for info_state in self.strategy_sum:\n",
        "            total_sum = sum(self.strategy_sum[info_state].values())\n",
        "            if total_sum > 0:\n",
        "                final_policy[info_state] = {\n",
        "                    str(action): prob / total_sum\n",
        "                    for action, prob in self.strategy_sum[info_state].items()\n",
        "                }\n",
        "            else:\n",
        "                actions = list(self.strategy_sum[info_state].keys())\n",
        "                uniform_prob = 1.0 / len(actions) if actions else 1.0\n",
        "                final_policy[info_state] = {\n",
        "                    str(action): uniform_prob for action in actions\n",
        "                }\n",
        "\n",
        "        return final_policy\n",
        "\n",
        "    def save_policy(self, filepath: str):\n",
        "        \"\"\"Your original method - simplified.\"\"\"\n",
        "        policy_data = {\n",
        "            'final_policy': self.get_final_policy(),\n",
        "            'iteration_count': self.iteration_count,\n",
        "            'regret_states': len(self.regret_sum)\n",
        "        }\n",
        "\n",
        "        with open(filepath, 'wb') as f:\n",
        "            pickle.dump(policy_data, f)\n",
        "        print(f\"Policy saved to {filepath}\")\n",
        "\n",
        "\n",
        "# USAGE EXAMPLE - Replace your test section with this:\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=== Testing OPTIMIZED MCCFR System ===\")\n",
        "\n",
        "    try:\n",
        "        # Use your existing abstraction manager\n",
        "        print(\"Testing abstraction system...\")\n",
        "        manager = FixedAbstractionManager(n_clusters_per_round=10)\n",
        "        manager.train_all_postflop_models(n_samples_per_round=1000)\n",
        "\n",
        "        # Test predictions\n",
        "        test_hands = [\n",
        "            (['As', 'Kh'], ['Qc', '7d', '2s']),\n",
        "            (['9h', '8c'], ['7d', '6s', '2h', 'Tc']),\n",
        "        ]\n",
        "\n",
        "        for hand, board in test_hands:\n",
        "            bucket = manager.get_postflop_bucket(hand, board)\n",
        "            print(f\"Hand {hand} + Board {board} -> Bucket {bucket}\")\n",
        "\n",
        "        print(\"Abstraction system working! Now testing OPTIMIZED MCCFR...\")\n",
        "\n",
        "        # Use the optimized trainer\n",
        "        trainer = OptimizedMCCFRTrainer(manager)\n",
        "        trainer.train(num_iterations=500)  # Start small\n",
        "\n",
        "        # Show results\n",
        "        final_policy = trainer.get_final_policy()\n",
        "        print(f\"\\nTraining Results:\")\n",
        "        print(f\"- Information states learned: {len(final_policy)}\")\n",
        "        print(f\"- Total iterations: {trainer.iteration_count}\")\n",
        "        print(f\"- Strategy updates: {trainer.strategy_updates}\")\n",
        "\n",
        "        if final_policy:\n",
        "            example_info_state = list(final_policy.keys())[0]\n",
        "            print(f\"\\nExample strategy for info state '{example_info_state}':\")\n",
        "            for action, prob in final_policy[example_info_state].items():\n",
        "                print(f\"  {action}: {prob:.3f}\")\n",
        "\n",
        "        trainer.save_policy(\"optimized_cfr_policy.pkl\")\n",
        "\n",
        "        print(\"SUCCESS: Optimized system is working!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGbTj9-GDKtX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Al2xM5XDLvn"
      },
      "source": [
        "#ACtual work\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class GameState:\n",
        "    \"\"\"\n",
        "    Represents the complete state of a poker game.\n",
        "    \"\"\"\n",
        "    players: List[int]\n",
        "    current_player: int\n",
        "    pot_size: float\n",
        "    street: str  # 'preflop', 'flop', 'turn', 'river'\n",
        "    board: List[str]  # Community cards\n",
        "    hands: Dict[int, List[str]]  # Player hole cards\n",
        "    bets: Dict[int, float]  # Current round bets\n",
        "    total_bets: Dict[int, float]  # Total bets across all rounds\n",
        "    action_history: List[Tuple[int, Action, float]] = field(default_factory=list)\n",
        "    is_terminal: bool = False\n",
        "\n",
        "    def copy(self) -> 'GameState':\n",
        "        \"\"\"Create a deep copy of the game state.\"\"\"\n",
        "        return GameState(\n",
        "            players=self.players.copy(),\n",
        "            current_player=self.current_player,\n",
        "            pot_size=self.pot_size,\n",
        "            street=self.street,\n",
        "            board=self.board.copy(),\n",
        "            hands={k: v.copy() for k, v in self.hands.items()},\n",
        "            bets=self.bets.copy(),\n",
        "            total_bets=self.total_bets.copy(),\n",
        "            action_history=self.action_history.copy(),\n",
        "            is_terminal=self.is_terminal\n",
        "        )"
      ],
      "metadata": {
        "id": "DoV5FipQAVNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlCWeIyl3B1J",
        "outputId": "b1895a26-d475-435a-f8d9-117428f047ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Testing OPTIMIZED MCCFR System ===\n",
            "Testing abstraction system...\n",
            "Optimized PotentialAwareCalculator initialized.\n",
            "Fixed AbstractionManager initialized.\n",
            "\n",
            "=== STARTING K-MEANS MODEL TRAINING FOR ALL ROUNDS ===\n",
            "\n",
            "--- Training flop model ---\n",
            "--- Generating 1000 feature vectors for flop ---\n",
            "  ...attempting 1000, collected 999/1000...\n",
            "Generated 1000 valid vectors (0 failed) in 0.61s\n",
            "Removed 5 duplicate vectors\n",
            "Training K-Means on 995 vectors with 8 features\n",
            "Using 10 clusters\n",
            "Silhouette Score: 0.260\n",
            "flop model trained successfully!\n",
            "\n",
            "--- Training turn model ---\n",
            "--- Generating 1000 feature vectors for turn ---\n",
            "  ...attempting 1000, collected 999/1000...\n",
            "Generated 1000 valid vectors (0 failed) in 0.61s\n",
            "Removed 10 duplicate vectors\n",
            "Training K-Means on 990 vectors with 8 features\n",
            "Using 10 clusters\n",
            "Silhouette Score: 0.255\n",
            "turn model trained successfully!\n",
            "\n",
            "--- Training river model ---\n",
            "--- Generating 1000 feature vectors for river ---\n",
            "  ...attempting 1000, collected 999/1000...\n",
            "Generated 1000 valid vectors (0 failed) in 0.53s\n",
            "Removed 23 duplicate vectors\n",
            "Training K-Means on 977 vectors with 8 features\n",
            "Using 10 clusters\n",
            "Silhouette Score: 0.269\n",
            "river model trained successfully!\n",
            "Hand ['As', 'Kh'] + Board ['Qc', '7d', '2s'] -> Bucket 2\n",
            "Hand ['9h', '8c'] + Board ['7d', '6s', '2h', 'Tc'] -> Bucket 27\n",
            "Abstraction system working! Now testing OPTIMIZED MCCFR...\n",
            "Initializing Optimized MCCFR Trainer...\n",
            "Optimized MCCFR Trainer initialized successfully.\n",
            "\n",
            "=== Starting Optimized MCCFR Training for 500 iterations ===\n",
            "Iteration 100/500 | Time: 31.7s | States: 1120\n",
            "Iteration 200/500 | Time: 65.3s | States: 1120\n",
            "Iteration 300/500 | Time: 97.3s | States: 1120\n",
            "Iteration 400/500 | Time: 132.9s | States: 1120\n",
            "Iteration 500/500 | Time: 165.0s | States: 1120\n",
            "Training complete! Total time: 165.3s\n",
            "Final policy contains 0 information states\n",
            "\n",
            "Training Results:\n",
            "- Information states learned: 1120\n",
            "- Total iterations: 500\n",
            "- Strategy updates: 10\n",
            "\n",
            "Example strategy for info state 'B79SpAP0':\n",
            "  (<Action.FOLD: 'fold'>, 0): 0.059\n",
            "  (<Action.CALL: 'call'>, 1.0): 0.014\n",
            "  (<Action.RAISE: 'raise'>, 3.0): 0.409\n",
            "  (<Action.RAISE: 'raise'>, 999.0): 0.518\n",
            "Policy saved to optimized_cfr_policy.pkl\n",
            "SUCCESS: Optimized system is working!\n"
          ]
        }
      ],
      "source": [
        "#++++++++++++++++++++++++++++++++++\n",
        "\n",
        "# Key fixes for the MCCFR training performance issues\n",
        "\n",
        "class OptimizedMCCFRTrainer:\n",
        "    \"\"\"Fixed version of your MCCFR trainer with performance optimizations.\"\"\"\n",
        "\n",
        "    def __init__(self, abstraction_manager=None, initial_stack=1000.0):\n",
        "        print(\"Initializing Optimized MCCFR Trainer...\")\n",
        "\n",
        "        if abstraction_manager is None:\n",
        "            self.abstraction_manager = FixedAbstractionManager(n_clusters_per_round=20)\n",
        "            print(\"Training abstraction models...\")\n",
        "            self.abstraction_manager.train_all_postflop_models(n_samples_per_round=5000)  # Reduced\n",
        "        else:\n",
        "            self.abstraction_manager = abstraction_manager\n",
        "\n",
        "        self.initial_stack = initial_stack\n",
        "\n",
        "        # CFR data structures\n",
        "        self.regret_sum = defaultdict(lambda: defaultdict(float))\n",
        "        self.strategy_sum = defaultdict(lambda: defaultdict(float))\n",
        "        self.policy = defaultdict(lambda: defaultdict(float))\n",
        "\n",
        "        self.iteration_count = 0\n",
        "        self.strategy_updates = 0\n",
        "\n",
        "        # CRITICAL FIX 1: Add recursion depth tracking\n",
        "        self.max_recursion_depth = 15\n",
        "        self.current_depth = 0\n",
        "\n",
        "        # CRITICAL FIX 2: Add action sequence tracking to prevent infinite loops\n",
        "        self.action_sequence_cache = {}\n",
        "\n",
        "        self._initialize_preflop_buckets()\n",
        "\n",
        "        print(\"Optimized MCCFR Trainer initialized successfully.\")\n",
        "\n",
        "    def _initialize_preflop_buckets(self):\n",
        "        \"\"\"Simplified preflop bucketing for testing.\"\"\"\n",
        "        self.preflop_buckets = {}\n",
        "\n",
        "        # Simplified bucketing - just a few categories\n",
        "        premium_hands = ['AA', 'KK', 'QQ', 'AK']\n",
        "        strong_hands = ['JJ', 'TT', 'AQ', 'AJ']\n",
        "\n",
        "        bucket_id = 60\n",
        "        for hand in premium_hands:\n",
        "            self.preflop_buckets[hand] = bucket_id\n",
        "        bucket_id += 1\n",
        "\n",
        "        for hand in strong_hands:\n",
        "            self.preflop_buckets[hand] = bucket_id\n",
        "        bucket_id += 1\n",
        "\n",
        "    def get_preflop_bucket(self, hand: List[str]) -> int:\n",
        "        \"\"\"Simplified preflop bucketing.\"\"\"\n",
        "        ranks = sorted([card[0] for card in hand], key=lambda x: RANKS.index(x), reverse=True)\n",
        "        suits = [card[1] for card in hand]\n",
        "\n",
        "        if ranks[0] == ranks[1]:\n",
        "            hand_str = ranks[0] + ranks[0]\n",
        "        else:\n",
        "            suited = 's' if suits[0] == suits[1] else 'o'\n",
        "            hand_str = ''.join(ranks) + suited\n",
        "\n",
        "        return self.preflop_buckets.get(hand_str, 79)\n",
        "\n",
        "    def get_info_state(self, state: GameState, player_id: int) -> str:\n",
        "        \"\"\"CRITICAL FIX 3: Simplified information state to prevent explosion.\"\"\"\n",
        "        hand = state.hands[player_id]\n",
        "        board = state.board\n",
        "\n",
        "        # Get bucket ID\n",
        "        if state.street == 'preflop':\n",
        "            bucket_id = self.get_preflop_bucket(hand)\n",
        "        else:\n",
        "            bucket_id = self.abstraction_manager.get_postflop_bucket(hand, board)\n",
        "\n",
        "        # SIMPLIFIED: Only include essential info to prevent state explosion\n",
        "        recent_actions = state.action_history[-3:] if len(state.action_history) > 3 else state.action_history\n",
        "        action_str = ''.join([f\"{a.value[0]}\" for _, a, _ in recent_actions])\n",
        "\n",
        "        pot_ratio = min(9, int(state.pot_size / 10))  # Discretize pot size\n",
        "\n",
        "        info_state = f\"B{bucket_id}S{state.street[0]}A{action_str}P{pot_ratio}\"\n",
        "        return info_state\n",
        "\n",
        "    def get_legal_actions(self, state: GameState, player_id: int) -> List[Tuple[Action, float]]:\n",
        "        \"\"\"CRITICAL FIX 4: Simplified action space to prevent explosion.\"\"\"\n",
        "        actions = []\n",
        "        to_call = max(state.bets.values()) - state.bets.get(player_id, 0)\n",
        "        stack_size = self.initial_stack - state.total_bets.get(player_id, 0)\n",
        "\n",
        "        # Always allow fold if facing a bet\n",
        "        if to_call > 0:\n",
        "            actions.append((Action.FOLD, 0))\n",
        "\n",
        "        # Check/Call\n",
        "        if to_call == 0:\n",
        "            actions.append((Action.CHECK, 0))\n",
        "        else:\n",
        "            if to_call <= stack_size:\n",
        "                actions.append((Action.CALL, to_call))\n",
        "\n",
        "        # SIMPLIFIED: Only 2 bet sizes instead of 5\n",
        "        pot_bet = state.pot_size\n",
        "        min_bet = max(to_call * 2, pot_bet * 0.5) if to_call > 0 else pot_bet * 0.5\n",
        "\n",
        "        if pot_bet <= stack_size and pot_bet >= min_bet:\n",
        "            if to_call == 0:\n",
        "                actions.append((Action.BET, pot_bet))\n",
        "            else:\n",
        "                actions.append((Action.RAISE, pot_bet))\n",
        "\n",
        "        # All-in as second option\n",
        "        if stack_size > pot_bet and stack_size >= min_bet:\n",
        "            if to_call == 0:\n",
        "                actions.append((Action.BET, stack_size))\n",
        "            else:\n",
        "                actions.append((Action.RAISE, stack_size))\n",
        "\n",
        "        return actions if actions else [(Action.FOLD, 0)]\n",
        "\n",
        "    def get_strategy(self, info_state: str, legal_actions: List[Tuple[Action, float]]) -> Dict[Tuple[Action, float], float]:\n",
        "        \"\"\"FIXED: Consistent action tuple handling.\"\"\"\n",
        "        strategy = {}\n",
        "\n",
        "        # Calculate regret sum for normalization\n",
        "        regret_sum = 0.0\n",
        "        for action_tuple in legal_actions:\n",
        "            regret_value = self.regret_sum[info_state].get(action_tuple, 0.0)\n",
        "            regret_sum += max(0, regret_value)\n",
        "\n",
        "        # Generate strategy based on regret matching\n",
        "        if regret_sum > 0:\n",
        "            for action_tuple in legal_actions:\n",
        "                regret_value = self.regret_sum[info_state].get(action_tuple, 0.0)\n",
        "                strategy[action_tuple] = max(0, regret_value) / regret_sum\n",
        "        else:\n",
        "            # Uniform strategy if no positive regrets\n",
        "            uniform_prob = 1.0 / len(legal_actions)\n",
        "            for action_tuple in legal_actions:\n",
        "                strategy[action_tuple] = uniform_prob\n",
        "\n",
        "        return strategy\n",
        "\n",
        "    def train(self, num_iterations: int = 1000):  # Reduced default\n",
        "        \"\"\"CRITICAL FIX 5: Better training loop with timeout protection.\"\"\"\n",
        "        print(f\"\\n=== Starting Optimized MCCFR Training for {num_iterations} iterations ===\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        for i in range(num_iterations):\n",
        "            self.iteration_count += 1\n",
        "\n",
        "            # Progress reporting\n",
        "            if (i + 1) % 100 == 0:\n",
        "                elapsed = time.time() - start_time\n",
        "                print(f\"Iteration {i+1}/{num_iterations} | \"\n",
        "                      f\"Time: {elapsed:.1f}s | \"\n",
        "                      f\"States: {len(self.regret_sum)}\")\n",
        "\n",
        "            try:\n",
        "                # CRITICAL: Reset depth counter for each iteration\n",
        "                self.current_depth = 0\n",
        "                self._run_mccfr_iteration()\n",
        "\n",
        "                # Timeout protection\n",
        "                if time.time() - start_time > 300:  # 5 minute timeout\n",
        "                    print(f\"Training timeout after {i+1} iterations\")\n",
        "                    break\n",
        "\n",
        "            except RecursionError:\n",
        "                print(f\"Recursion limit hit at iteration {i+1}\")\n",
        "                continue\n",
        "            except Exception as e:\n",
        "                print(f\"Error in iteration {i+1}: {e}\")\n",
        "                continue\n",
        "\n",
        "            if i % 50 == 0:  # More frequent strategy updates\n",
        "                self._update_average_strategy()\n",
        "\n",
        "        total_time = time.time() - start_time\n",
        "        print(f\"Training complete! Total time: {total_time:.1f}s\")\n",
        "        print(f\"Final policy contains {len(self.policy)} information states\")\n",
        "\n",
        "    def _run_mccfr_iteration(self):\n",
        "        \"\"\"CRITICAL FIX 6: Simplified iteration with better initial state.\"\"\"\n",
        "        initial_state = self._create_simple_game_state()\n",
        "\n",
        "        # Run MCCFR for both players\n",
        "        for player_id in [0, 1]:\n",
        "            self.current_depth = 0  # Reset depth\n",
        "            try:\n",
        "                self._mccfr_recursive(initial_state, player_id, 1.0, 1.0)\n",
        "            except Exception as e:\n",
        "                # Gracefully handle errors and continue\n",
        "                continue\n",
        "\n",
        "    def _create_simple_game_state(self) -> GameState:\n",
        "        \"\"\"CRITICAL FIX 7: Simplified initial game state.\"\"\"\n",
        "        deck = DECK.copy()\n",
        "        random.shuffle(deck)\n",
        "\n",
        "        # Simple preflop state\n",
        "        hands = {0: deck[:2], 1: deck[2:4]}\n",
        "\n",
        "        state = GameState(\n",
        "            players=[0, 1],\n",
        "            current_player=0,\n",
        "            pot_size=3.0,\n",
        "            street='preflop',\n",
        "            board=[],\n",
        "            hands=hands,\n",
        "            bets={0: 1.0, 1: 2.0},  # Small blind, big blind\n",
        "            total_bets={0: 1.0, 1: 2.0},\n",
        "            action_history=[]\n",
        "        )\n",
        "\n",
        "        return state\n",
        "\n",
        "    def _mccfr_recursive(self, state: GameState, traversing_player: int,\n",
        "                         pi_player: float, pi_opponent: float) -> float:\n",
        "        \"\"\"CRITICAL FIX 8: Protected recursive function with depth limits.\"\"\"\n",
        "\n",
        "        # CRITICAL: Depth protection\n",
        "        self.current_depth += 1\n",
        "        if self.current_depth > self.max_recursion_depth:\n",
        "            self.current_depth -= 1\n",
        "            return self._get_utility(state, traversing_player)\n",
        "\n",
        "        # Terminal state check\n",
        "        if state.is_terminal:\n",
        "            self.current_depth -= 1\n",
        "            return self._get_utility(state, traversing_player)\n",
        "\n",
        "        # Action sequence protection against infinite loops\n",
        "        action_sequence = tuple((p, a.value, amt) for p, a, amt in state.action_history[-5:])\n",
        "        if len(state.action_history) > 10:  # Reduced from 20\n",
        "            self.current_depth -= 1\n",
        "            return self._get_utility(state, traversing_player)\n",
        "\n",
        "        current_player = state.current_player\n",
        "        info_state = self.get_info_state(state, current_player)\n",
        "        legal_actions = self.get_legal_actions(state, current_player)\n",
        "\n",
        "        if not legal_actions:\n",
        "            self.current_depth -= 1\n",
        "            return self._get_utility(state, traversing_player)\n",
        "\n",
        "        strategy = self.get_strategy(info_state, legal_actions)\n",
        "\n",
        "        # Calculate utilities for each action\n",
        "        action_utilities = {}\n",
        "        for action_tuple in legal_actions:\n",
        "            try:\n",
        "                new_state = self._apply_action(state, action_tuple[0], action_tuple[1])\n",
        "\n",
        "                if current_player == traversing_player:\n",
        "                    action_utilities[action_tuple] = self._mccfr_recursive(\n",
        "                        new_state, traversing_player,\n",
        "                        pi_player * strategy[action_tuple], pi_opponent\n",
        "                    )\n",
        "                else:\n",
        "                    action_utilities[action_tuple] = self._mccfr_recursive(\n",
        "                        new_state, traversing_player, pi_player,\n",
        "                        pi_opponent * strategy[action_tuple]\n",
        "                    )\n",
        "            except Exception:\n",
        "                # Fallback utility if recursion fails\n",
        "                action_utilities[action_tuple] = 0.0\n",
        "\n",
        "        # Node utility calculation\n",
        "        node_utility = sum(strategy[action_tuple] * action_utilities[action_tuple]\n",
        "                          for action_tuple in legal_actions)\n",
        "\n",
        "        # Update regrets\n",
        "        if current_player == traversing_player:\n",
        "            for action_tuple in legal_actions:\n",
        "                regret = action_utilities[action_tuple] - node_utility\n",
        "                self.regret_sum[info_state][action_tuple] += pi_opponent * regret\n",
        "\n",
        "        self.current_depth -= 1\n",
        "        return node_utility\n",
        "\n",
        "    def _apply_action(self, state: GameState, action: Action, amount: float) -> GameState:\n",
        "        \"\"\"CRITICAL FIX 9: Simplified action application.\"\"\"\n",
        "        from copy import copy\n",
        "\n",
        "        # Shallow copy for performance\n",
        "        new_state = copy(state)\n",
        "        new_state.bets = state.bets.copy()\n",
        "        new_state.total_bets = state.total_bets.copy()\n",
        "        new_state.players = state.players.copy()\n",
        "        new_state.action_history = state.action_history.copy()\n",
        "        new_state.hands = state.hands.copy()\n",
        "        new_state.board = state.board.copy()\n",
        "\n",
        "        player_id = state.current_player\n",
        "\n",
        "        # Apply the action\n",
        "        if action == Action.FOLD:\n",
        "            new_state.is_terminal = True\n",
        "            if player_id in new_state.players:\n",
        "                new_state.players.remove(player_id)\n",
        "        elif action == Action.CHECK:\n",
        "            pass  # No bet change\n",
        "        elif action == Action.CALL:\n",
        "            call_amount = max(state.bets.values()) - state.bets.get(player_id, 0)\n",
        "            new_state.bets[player_id] += call_amount\n",
        "            new_state.total_bets[player_id] += call_amount\n",
        "            new_state.pot_size += call_amount\n",
        "        elif action in [Action.BET, Action.RAISE]:\n",
        "            new_state.bets[player_id] += amount\n",
        "            new_state.total_bets[player_id] += amount\n",
        "            new_state.pot_size += amount\n",
        "\n",
        "        # Add to history\n",
        "        new_state.action_history.append((player_id, action, amount))\n",
        "\n",
        "        # CRITICAL FIX 10: Simplified game advancement\n",
        "        if not new_state.is_terminal:\n",
        "            new_state.current_player = 1 - player_id\n",
        "\n",
        "            # Simple completion check\n",
        "            if len(new_state.action_history) >= 4:  # Both players acted twice\n",
        "                new_state = self._try_advance_street(new_state)\n",
        "            elif action in [Action.CHECK, Action.CALL] and len(new_state.action_history) >= 2:\n",
        "                # Check if both players checked or one called\n",
        "                last_two = new_state.action_history[-2:]\n",
        "                if all(act in [Action.CHECK, Action.CALL] for _, act, _ in last_two):\n",
        "                    new_state = self._try_advance_street(new_state)\n",
        "\n",
        "        return new_state\n",
        "\n",
        "    def _try_advance_street(self, state: GameState) -> GameState:\n",
        "        \"\"\"CRITICAL FIX 11: Simplified street advancement.\"\"\"\n",
        "        street_map = {\n",
        "            'preflop': ('flop', 3),\n",
        "            'flop': ('turn', 4),\n",
        "            'turn': ('river', 5),\n",
        "            'river': ('terminal', 5)\n",
        "        }\n",
        "\n",
        "        if state.street in street_map:\n",
        "            next_street, target_board_size = street_map[state.street]\n",
        "\n",
        "            if next_street == 'terminal':\n",
        "                state.is_terminal = True\n",
        "            else:\n",
        "                # Deal cards to reach target board size\n",
        "                cards_needed = target_board_size - len(state.board)\n",
        "                if cards_needed > 0:\n",
        "                    # Get available cards\n",
        "                    used_cards = set()\n",
        "                    for hand in state.hands.values():\n",
        "                        used_cards.update(hand)\n",
        "                    used_cards.update(state.board)\n",
        "\n",
        "                    available_cards = [c for c in DECK if c not in used_cards]\n",
        "                    random.shuffle(available_cards)\n",
        "\n",
        "                    # Deal new cards\n",
        "                    new_cards = available_cards[:cards_needed]\n",
        "                    state.board.extend(new_cards)\n",
        "\n",
        "                state.street = next_street\n",
        "                state.bets = {p: 0.0 for p in state.players}\n",
        "                state.current_player = 0\n",
        "\n",
        "        return state\n",
        "\n",
        "    def _get_utility(self, state: GameState, player_id: int) -> float:\n",
        "        \"\"\"CRITICAL FIX 12: Simplified utility calculation.\"\"\"\n",
        "        if player_id not in state.players:\n",
        "            return -state.total_bets.get(player_id, 0)\n",
        "\n",
        "        if len(state.players) == 1:\n",
        "            return state.pot_size - state.total_bets.get(player_id, 0)\n",
        "\n",
        "        # Simplified showdown\n",
        "        if len(state.board) >= 3:  # Any postflop situation\n",
        "            try:\n",
        "                # Use your hand evaluator if available\n",
        "                player_hand = state.hands[player_id] + state.board\n",
        "                if len(player_hand) >= 5:\n",
        "                    player_rank = evaluate_cards(*player_hand)\n",
        "\n",
        "                    best_opponent_rank = float('inf')\n",
        "                    for opp_id in state.players:\n",
        "                        if opp_id != player_id:\n",
        "                            opp_hand = state.hands[opp_id] + state.board\n",
        "                            if len(opp_hand) >= 5:\n",
        "                                opp_rank = evaluate_cards(*opp_hand)\n",
        "                                best_opponent_rank = min(best_opponent_rank, opp_rank)\n",
        "\n",
        "                    if best_opponent_rank == float('inf'):\n",
        "                        # No valid opponent hands\n",
        "                        return state.pot_size - state.total_bets.get(player_id, 0)\n",
        "\n",
        "                    if player_rank < best_opponent_rank:\n",
        "                        return state.pot_size - state.total_bets.get(player_id, 0)\n",
        "                    elif player_rank == best_opponent_rank:\n",
        "                        return (state.pot_size / len(state.players)) - state.total_bets.get(player_id, 0)\n",
        "                    else:\n",
        "                        return -state.total_bets.get(player_id, 0)\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        # Fallback: random outcome weighted by pot investment\n",
        "        random_outcome = random.choice([1, -1])\n",
        "        return random_outcome * (state.pot_size / 2) - state.total_bets.get(player_id, 0)\n",
        "\n",
        "    def _update_average_strategy(self):\n",
        "        \"\"\"FIXED: Proper handling of action tuples.\"\"\"\n",
        "        for info_state in self.regret_sum:\n",
        "            # The keys in regret_sum are (Action, amount) tuples\n",
        "            action_tuples = list(self.regret_sum[info_state].keys())\n",
        "\n",
        "            # Convert to the format expected by get_strategy\n",
        "            legal_actions = [(action, amount) for action, amount in action_tuples]\n",
        "\n",
        "            if legal_actions:\n",
        "                strategy = self.get_strategy(info_state, legal_actions)\n",
        "\n",
        "                for action_tuple in strategy:\n",
        "                    self.strategy_sum[info_state][action_tuple] += strategy[action_tuple]\n",
        "\n",
        "        self.strategy_updates += 1\n",
        "\n",
        "    def get_final_policy(self) -> Dict[str, Dict]:\n",
        "        \"\"\"Your original method - no changes needed.\"\"\"\n",
        "        final_policy = {}\n",
        "\n",
        "        for info_state in self.strategy_sum:\n",
        "            total_sum = sum(self.strategy_sum[info_state].values())\n",
        "            if total_sum > 0:\n",
        "                final_policy[info_state] = {\n",
        "                    str(action): prob / total_sum\n",
        "                    for action, prob in self.strategy_sum[info_state].items()\n",
        "                }\n",
        "            else:\n",
        "                actions = list(self.strategy_sum[info_state].keys())\n",
        "                uniform_prob = 1.0 / len(actions) if actions else 1.0\n",
        "                final_policy[info_state] = {\n",
        "                    str(action): uniform_prob for action in actions\n",
        "                }\n",
        "\n",
        "        return final_policy\n",
        "\n",
        "    def save_policy(self, filepath: str):\n",
        "        \"\"\"Your original method - simplified.\"\"\"\n",
        "        policy_data = {\n",
        "            'final_policy': self.get_final_policy(),\n",
        "            'iteration_count': self.iteration_count,\n",
        "            'regret_states': len(self.regret_sum)\n",
        "        }\n",
        "\n",
        "        with open(filepath, 'wb') as f:\n",
        "            pickle.dump(policy_data, f)\n",
        "        print(f\"Policy saved to {filepath}\")\n",
        "\n",
        "\n",
        "# USAGE EXAMPLE - Replace your test section with this:\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=== Testing OPTIMIZED MCCFR System ===\")\n",
        "\n",
        "    try:\n",
        "        # Use your existing abstraction manager\n",
        "        print(\"Testing abstraction system...\")\n",
        "        manager = FixedAbstractionManager(n_clusters_per_round=10)\n",
        "        manager.train_all_postflop_models(n_samples_per_round=1000)\n",
        "\n",
        "        # Test predictions\n",
        "        test_hands = [\n",
        "            (['As', 'Kh'], ['Qc', '7d', '2s']),\n",
        "            (['9h', '8c'], ['7d', '6s', '2h', 'Tc']),\n",
        "        ]\n",
        "\n",
        "        for hand, board in test_hands:\n",
        "            bucket = manager.get_postflop_bucket(hand, board)\n",
        "            print(f\"Hand {hand} + Board {board} -> Bucket {bucket}\")\n",
        "\n",
        "        print(\"Abstraction system working! Now testing OPTIMIZED MCCFR...\")\n",
        "\n",
        "        # Use the optimized trainer\n",
        "        trainer = OptimizedMCCFRTrainer(manager)\n",
        "        trainer.train(num_iterations=500)  # Start small\n",
        "\n",
        "        # Show results\n",
        "        final_policy = trainer.get_final_policy()\n",
        "        print(f\"\\nTraining Results:\")\n",
        "        print(f\"- Information states learned: {len(final_policy)}\")\n",
        "        print(f\"- Total iterations: {trainer.iteration_count}\")\n",
        "        print(f\"- Strategy updates: {trainer.strategy_updates}\")\n",
        "\n",
        "        if final_policy:\n",
        "            example_info_state = list(final_policy.keys())[0]\n",
        "            print(f\"\\nExample strategy for info state '{example_info_state}':\")\n",
        "            for action, prob in final_policy[example_info_state].items():\n",
        "                print(f\"  {action}: {prob:.3f}\")\n",
        "\n",
        "        trainer.save_policy(\"optimized_cfr_policy.pkl\")\n",
        "\n",
        "        print(\"SUCCESS: Optimized system is working!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "import itertools\n",
        "import random\n",
        "import time\n",
        "import pickle\n",
        "from typing import List, Dict, Tuple, Set\n",
        "from collections import defaultdict\n",
        "from enum import Enum\n",
        "from dataclasses import dataclass, field\n",
        "from copy import deepcopy\n",
        "\n",
        "# Card and game constants\n",
        "SUITS = ['h', 'd', 'c', 's']  # Hearts, Diamonds, Clubs, Spades\n",
        "RANKS = ['2', '3', '4', '5', '6', '7', '8', '9', 'T', 'J', 'Q', 'K', 'A']\n",
        "\n",
        "# Create a standard deck\n",
        "DECK = [f\"{rank}{suit}\" for rank in RANKS for suit in SUITS]\n",
        "\n",
        "class Action(Enum):\n",
        "    \"\"\"Poker actions available to players.\"\"\"\n",
        "    FOLD = \"fold\"\n",
        "    CHECK = \"check\"\n",
        "    CALL = \"call\"\n",
        "    BET = \"bet\"\n",
        "    RAISE = \"raise\"\n",
        "\n",
        "@dataclass\n",
        "class GameState:\n",
        "    \"\"\"\n",
        "    Represents the complete state of a poker game.\n",
        "    \"\"\"\n",
        "    players: List[int]\n",
        "    current_player: int\n",
        "    pot_size: float\n",
        "    street: str  # 'preflop', 'flop', 'turn', 'river'\n",
        "    board: List[str]  # Community cards\n",
        "    hands: Dict[int, List[str]]  # Player hole cards\n",
        "    bets: Dict[int, float]  # Current round bets\n",
        "    total_bets: Dict[int, float]  # Total bets across all rounds\n",
        "    action_history: List[Tuple[int, Action, float]] = field(default_factory=list)\n",
        "    is_terminal: bool = False\n",
        "\n",
        "    def copy(self) -> 'GameState':\n",
        "        \"\"\"Create a deep copy of the game state.\"\"\"\n",
        "        return GameState(\n",
        "            players=self.players.copy(),\n",
        "            current_player=self.current_player,\n",
        "            pot_size=self.pot_size,\n",
        "            street=self.street,\n",
        "            board=self.board.copy(),\n",
        "            hands={k: v.copy() for k, v in self.hands.items()},\n",
        "            bets=self.bets.copy(),\n",
        "            total_bets=self.total_bets.copy(),\n",
        "            action_history=self.action_history.copy(),\n",
        "            is_terminal=self.is_terminal\n",
        "        )\n",
        "\n",
        "class Card:\n",
        "    \"\"\"\n",
        "    Represents a single playing card with rank and suit.\n",
        "    \"\"\"\n",
        "    __slots__ = ('rank', 'suit')\n",
        "\n",
        "    def __init__(self, rank: str, suit: str) -> None:\n",
        "        if rank not in RANKS:\n",
        "            raise ValueError(f\"Invalid rank: {rank}. Must be one of {RANKS}\")\n",
        "        if suit not in SUITS:\n",
        "            raise ValueError(f\"Invalid suit: {suit}. Must be one of {SUITS}\")\n",
        "        self.rank = rank\n",
        "        self.suit = suit\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return f\"{self.rank}{self.suit}\"\n",
        "\n",
        "    def __eq__(self, other: object) -> bool:\n",
        "        if not isinstance(other, Card):\n",
        "            return NotImplemented\n",
        "        return self.rank == other.rank and self.suit == other.suit\n",
        "\n",
        "    def __hash__(self) -> int:\n",
        "        return hash((self.rank, self.suit))\n",
        "\n",
        "    def get_numeric_rank(self) -> int:\n",
        "        \"\"\"Returns the numeric rank of the card (2-14, where Ace is 14).\"\"\"\n",
        "        return RANKS.index(self.rank) + 2\n",
        "\n",
        "def create_deck() -> List[Card]:\n",
        "    \"\"\"Creates a standard 52-card deck.\"\"\"\n",
        "    return [Card(rank, suit) for rank in RANKS for suit in SUITS]\n",
        "\n",
        "def get_hand_bucket(hand: List[Card]) -> str:\n",
        "    \"\"\"\n",
        "    Determines the preflop bucket for a given two-card hand.\n",
        "    \"\"\"\n",
        "    if len(hand) != 2:\n",
        "        raise ValueError(\"Hand must consist of exactly two cards.\")\n",
        "\n",
        "    # Sort cards by rank (higher rank first)\n",
        "    sorted_hand = sorted(hand, key=lambda card: RANKS.index(card.rank), reverse=True)\n",
        "    card1, card2 = sorted_hand\n",
        "\n",
        "    if card1.rank == card2.rank:\n",
        "        return f\"{card1.rank}{card2.rank}\"  # Pocket pair\n",
        "    elif card1.suit == card2.suit:\n",
        "        return f\"{card1.rank}{card2.rank}s\"  # Suited\n",
        "    else:\n",
        "        return f\"{card1.rank}{card2.rank}o\"  # Offsuit\n",
        "\n",
        "# Simple hand evaluator (placeholder - you can integrate your actual evaluator)\n",
        "def evaluate_hand_strength(hand: List[str], board: List[str]) -> float:\n",
        "    \"\"\"\n",
        "    Simple hand strength evaluator. Replace with your actual hand evaluator.\n",
        "    Returns a value between 0 and 1 where higher is better.\n",
        "    \"\"\"\n",
        "    all_cards = hand + board\n",
        "    if len(all_cards) < 5:\n",
        "        return 0.5  # Unknown strength\n",
        "\n",
        "    # Very simplified evaluation based on high cards\n",
        "    ranks_values = {'2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8,\n",
        "                   '9': 9, 'T': 10, 'J': 11, 'Q': 12, 'K': 13, 'A': 14}\n",
        "\n",
        "    card_ranks = [ranks_values[card[0]] for card in all_cards]\n",
        "    max_rank = max(card_ranks)\n",
        "    avg_rank = sum(card_ranks) / len(card_ranks)\n",
        "\n",
        "    # Simple strength calculation\n",
        "    strength = (max_rank + avg_rank) / 28.0  # Normalize roughly to 0-1\n",
        "    return min(1.0, max(0.0, strength))\n",
        "\n",
        "# Mock abstraction manager for testing\n",
        "class MockAbstractionManager:\n",
        "    \"\"\"Simple mock abstraction manager for testing.\"\"\"\n",
        "\n",
        "    def __init__(self, n_clusters_per_round=10):\n",
        "        self.n_clusters = n_clusters_per_round\n",
        "\n",
        "    def get_postflop_bucket(self, hand: List[str], board: List[str]) -> int:\n",
        "        \"\"\"Return a simple bucket based on hand strength.\"\"\"\n",
        "        strength = evaluate_hand_strength(hand, board)\n",
        "        return int(strength * (self.n_clusters - 1))\n",
        "\n",
        "    def train_all_postflop_models(self, n_samples_per_round=1000):\n",
        "        \"\"\"Mock training method.\"\"\"\n",
        "        print(f\"Mock abstraction manager trained with {n_samples_per_round} samples\")\n",
        "\n",
        "class OptimizedMCCFRTrainer:\n",
        "    \"\"\"Fixed version of MCCFR trainer with performance optimizations.\"\"\"\n",
        "\n",
        "    def __init__(self, abstraction_manager=None, initial_stack=1000.0):\n",
        "        print(\"Initializing Optimized MCCFR Trainer...\")\n",
        "\n",
        "        if abstraction_manager is None:\n",
        "            self.abstraction_manager = MockAbstractionManager(n_clusters_per_round=20)\n",
        "            self.abstraction_manager.train_all_postflop_models(n_samples_per_round=1000)\n",
        "        else:\n",
        "            self.abstraction_manager = abstraction_manager\n",
        "\n",
        "        self.initial_stack = initial_stack\n",
        "\n",
        "        # CFR data structures\n",
        "        self.regret_sum = defaultdict(lambda: defaultdict(float))\n",
        "        self.strategy_sum = defaultdict(lambda: defaultdict(float))\n",
        "        self.policy = defaultdict(lambda: defaultdict(float))\n",
        "\n",
        "        self.iteration_count = 0\n",
        "        self.strategy_updates = 0\n",
        "\n",
        "        # Recursion depth tracking\n",
        "        self.max_recursion_depth = 15\n",
        "        self.current_depth = 0\n",
        "\n",
        "        # Action sequence tracking to prevent infinite loops\n",
        "        self.action_sequence_cache = {}\n",
        "\n",
        "        self._initialize_preflop_buckets()\n",
        "\n",
        "        print(\"Optimized MCCFR Trainer initialized successfully.\")\n",
        "\n",
        "    def _initialize_preflop_buckets(self):\n",
        "        \"\"\"Simplified preflop bucketing for testing.\"\"\"\n",
        "        self.preflop_buckets = {}\n",
        "\n",
        "        # Simplified bucketing - just a few categories\n",
        "        premium_hands = ['AA', 'KK', 'QQ', 'AKs', 'AKo']\n",
        "        strong_hands = ['JJ', 'TT', 'AQs', 'AQo', 'AJs', 'AJo']\n",
        "        medium_hands = ['99', '88', 'KQs', 'KQo', 'KJs', 'KJo']\n",
        "\n",
        "        bucket_id = 60\n",
        "        for hand in premium_hands:\n",
        "            self.preflop_buckets[hand] = bucket_id\n",
        "        bucket_id += 1\n",
        "\n",
        "        for hand in strong_hands:\n",
        "            self.preflop_buckets[hand] = bucket_id\n",
        "        bucket_id += 1\n",
        "\n",
        "        for hand in medium_hands:\n",
        "            self.preflop_buckets[hand] = bucket_id\n",
        "\n",
        "    def get_preflop_bucket(self, hand: List[str]) -> int:\n",
        "        \"\"\"Simplified preflop bucketing.\"\"\"\n",
        "        if len(hand) != 2:\n",
        "            return 79  # Default bucket\n",
        "\n",
        "        ranks = sorted([card[0] for card in hand], key=lambda x: RANKS.index(x), reverse=True)\n",
        "        suits = [card[1] for card in hand]\n",
        "\n",
        "        if ranks[0] == ranks[1]:\n",
        "            hand_str = ranks[0] + ranks[0]\n",
        "        else:\n",
        "            suited = 's' if suits[0] == suits[1] else 'o'\n",
        "            hand_str = ''.join(ranks) + suited\n",
        "\n",
        "        return self.preflop_buckets.get(hand_str, 79)\n",
        "\n",
        "    def get_info_state(self, state: GameState, player_id: int) -> str:\n",
        "        \"\"\"Simplified information state to prevent explosion.\"\"\"\n",
        "        hand = state.hands[player_id]\n",
        "        board = state.board\n",
        "\n",
        "        # Get bucket ID\n",
        "        if state.street == 'preflop':\n",
        "            bucket_id = self.get_preflop_bucket(hand)\n",
        "        else:\n",
        "            bucket_id = self.abstraction_manager.get_postflop_bucket(hand, board)\n",
        "\n",
        "        # Only include essential info to prevent state explosion\n",
        "        recent_actions = state.action_history[-3:] if len(state.action_history) > 3 else state.action_history\n",
        "        action_str = ''.join([f\"{a.value[0]}\" for _, a, _ in recent_actions])\n",
        "\n",
        "        pot_ratio = min(9, int(state.pot_size / 10))  # Discretize pot size\n",
        "\n",
        "        info_state = f\"B{bucket_id}S{state.street[0]}A{action_str}P{pot_ratio}\"\n",
        "        return info_state\n",
        "\n",
        "    def get_legal_actions(self, state: GameState, player_id: int) -> List[Tuple[Action, float]]:\n",
        "        \"\"\"Simplified action space to prevent explosion.\"\"\"\n",
        "        actions = []\n",
        "        to_call = max(state.bets.values()) - state.bets.get(player_id, 0)\n",
        "        stack_size = self.initial_stack - state.total_bets.get(player_id, 0)\n",
        "\n",
        "        # Always allow fold if facing a bet\n",
        "        if to_call > 0:\n",
        "            actions.append((Action.FOLD, 0))\n",
        "\n",
        "        # Check/Call\n",
        "        if to_call == 0:\n",
        "            actions.append((Action.CHECK, 0))\n",
        "        else:\n",
        "            if to_call <= stack_size:\n",
        "                actions.append((Action.CALL, to_call))\n",
        "\n",
        "        # Simplified: Only 2 bet sizes instead of 5\n",
        "        pot_bet = state.pot_size\n",
        "        min_bet = max(to_call * 2, pot_bet * 0.5) if to_call > 0 else pot_bet * 0.5\n",
        "\n",
        "        if pot_bet <= stack_size and pot_bet >= min_bet:\n",
        "            if to_call == 0:\n",
        "                actions.append((Action.BET, pot_bet))\n",
        "            else:\n",
        "                actions.append((Action.RAISE, pot_bet))\n",
        "\n",
        "        # All-in as second option\n",
        "        if stack_size > pot_bet and stack_size >= min_bet:\n",
        "            if to_call == 0:\n",
        "                actions.append((Action.BET, stack_size))\n",
        "            else:\n",
        "                actions.append((Action.RAISE, stack_size))\n",
        "\n",
        "        return actions if actions else [(Action.FOLD, 0)]\n",
        "\n",
        "    def get_strategy(self, info_state: str, legal_actions: List[Tuple[Action, float]]) -> Dict[Tuple[Action, float], float]:\n",
        "        \"\"\"Consistent action tuple handling.\"\"\"\n",
        "        strategy = {}\n",
        "\n",
        "        # Calculate regret sum for normalization\n",
        "        regret_sum = 0.0\n",
        "        for action_tuple in legal_actions:\n",
        "            regret_value = self.regret_sum[info_state].get(action_tuple, 0.0)\n",
        "            regret_sum += max(0, regret_value)\n",
        "\n",
        "        # Generate strategy based on regret matching\n",
        "        if regret_sum > 0:\n",
        "            for action_tuple in legal_actions:\n",
        "                regret_value = self.regret_sum[info_state].get(action_tuple, 0.0)\n",
        "                strategy[action_tuple] = max(0, regret_value) / regret_sum\n",
        "        else:\n",
        "            # Uniform strategy if no positive regrets\n",
        "            uniform_prob = 1.0 / len(legal_actions)\n",
        "            for action_tuple in legal_actions:\n",
        "                strategy[action_tuple] = uniform_prob\n",
        "\n",
        "        return strategy\n",
        "\n",
        "    def train(self, num_iterations: int = 1000):\n",
        "        \"\"\"Better training loop with timeout protection.\"\"\"\n",
        "        print(f\"\\n=== Starting Optimized MCCFR Training for {num_iterations} iterations ===\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        for i in range(num_iterations):\n",
        "            self.iteration_count += 1\n",
        "\n",
        "            # Progress reporting\n",
        "            if (i + 1) % 100 == 0:\n",
        "                elapsed = time.time() - start_time\n",
        "                print(f\"Iteration {i+1}/{num_iterations} | \"\n",
        "                      f\"Time: {elapsed:.1f}s | \"\n",
        "                      f\"States: {len(self.regret_sum)}\")\n",
        "\n",
        "            try:\n",
        "                # Reset depth counter for each iteration\n",
        "                self.current_depth = 0\n",
        "                self._run_mccfr_iteration()\n",
        "\n",
        "                # Timeout protection\n",
        "                if time.time() - start_time > 300:  # 5 minute timeout\n",
        "                    print(f\"Training timeout after {i+1} iterations\")\n",
        "                    break\n",
        "\n",
        "            except RecursionError:\n",
        "                print(f\"Recursion limit hit at iteration {i+1}\")\n",
        "                continue\n",
        "            except Exception as e:\n",
        "                print(f\"Error in iteration {i+1}: {e}\")\n",
        "                continue\n",
        "\n",
        "            if i % 50 == 0:  # More frequent strategy updates\n",
        "                self._update_average_strategy()\n",
        "\n",
        "        total_time = time.time() - start_time\n",
        "        print(f\"Training complete! Total time: {total_time:.1f}s\")\n",
        "        print(f\"Final policy contains {len(self.policy)} information states\")\n",
        "\n",
        "    def _run_mccfr_iteration(self):\n",
        "        \"\"\"Simplified iteration with better initial state.\"\"\"\n",
        "        initial_state = self._create_simple_game_state()\n",
        "\n",
        "        # Run MCCFR for both players\n",
        "        for player_id in [0, 1]:\n",
        "            self.current_depth = 0  # Reset depth\n",
        "            try:\n",
        "                self._mccfr_recursive(initial_state, player_id, 1.0, 1.0)\n",
        "            except Exception as e:\n",
        "                # Gracefully handle errors and continue\n",
        "                continue\n",
        "\n",
        "    def _create_simple_game_state(self) -> GameState:\n",
        "        \"\"\"Simplified initial game state.\"\"\"\n",
        "        deck = DECK.copy()\n",
        "        random.shuffle(deck)\n",
        "\n",
        "        # Simple preflop state\n",
        "        hands = {0: deck[:2], 1: deck[2:4]}\n",
        "\n",
        "        state = GameState(\n",
        "            players=[0, 1],\n",
        "            current_player=0,\n",
        "            pot_size=3.0,\n",
        "            street='preflop',\n",
        "            board=[],\n",
        "            hands=hands,\n",
        "            bets={0: 1.0, 1: 2.0},  # Small blind, big blind\n",
        "            total_bets={0: 1.0, 1: 2.0},\n",
        "            action_history=[]\n",
        "        )\n",
        "\n",
        "        return state\n",
        "\n",
        "    def _mccfr_recursive(self, state: GameState, traversing_player: int,\n",
        "                         pi_player: float, pi_opponent: float) -> float:\n",
        "        \"\"\"Protected recursive function with depth limits.\"\"\"\n",
        "\n",
        "        # Depth protection\n",
        "        self.current_depth += 1\n",
        "        if self.current_depth > self.max_recursion_depth:\n",
        "            self.current_depth -= 1\n",
        "            return self._get_utility(state, traversing_player)\n",
        "\n",
        "        # Terminal state check\n",
        "        if state.is_terminal:\n",
        "            self.current_depth -= 1\n",
        "            return self._get_utility(state, traversing_player)\n",
        "\n",
        "        # Action sequence protection against infinite loops\n",
        "        if len(state.action_history) > 10:  # Reduced from 20\n",
        "            self.current_depth -= 1\n",
        "            return self._get_utility(state, traversing_player)\n",
        "\n",
        "        current_player = state.current_player\n",
        "        info_state = self.get_info_state(state, current_player)\n",
        "        legal_actions = self.get_legal_actions(state, current_player)\n",
        "\n",
        "        if not legal_actions:\n",
        "            self.current_depth -= 1\n",
        "            return self._get_utility(state, traversing_player)\n",
        "\n",
        "        strategy = self.get_strategy(info_state, legal_actions)\n",
        "\n",
        "        # Calculate utilities for each action\n",
        "        action_utilities = {}\n",
        "        for action_tuple in legal_actions:\n",
        "            try:\n",
        "                new_state = self._apply_action(state, action_tuple[0], action_tuple[1])\n",
        "\n",
        "                if current_player == traversing_player:\n",
        "                    action_utilities[action_tuple] = self._mccfr_recursive(\n",
        "                        new_state, traversing_player,\n",
        "                        pi_player * strategy[action_tuple], pi_opponent\n",
        "                    )\n",
        "                else:\n",
        "                    action_utilities[action_tuple] = self._mccfr_recursive(\n",
        "                        new_state, traversing_player, pi_player,\n",
        "                        pi_opponent * strategy[action_tuple]\n",
        "                    )\n",
        "            except Exception:\n",
        "                # Fallback utility if recursion fails\n",
        "                action_utilities[action_tuple] = 0.0\n",
        "\n",
        "        # Node utility calculation\n",
        "        node_utility = sum(strategy[action_tuple] * action_utilities[action_tuple]\n",
        "                          for action_tuple in legal_actions)\n",
        "\n",
        "        # Update regrets\n",
        "        if current_player == traversing_player:\n",
        "            for action_tuple in legal_actions:\n",
        "                regret = action_utilities[action_tuple] - node_utility\n",
        "                self.regret_sum[info_state][action_tuple] += pi_opponent * regret\n",
        "\n",
        "        self.current_depth -= 1\n",
        "        return node_utility\n",
        "\n",
        "    def _apply_action(self, state: GameState, action: Action, amount: float) -> GameState:\n",
        "        \"\"\"Simplified action application.\"\"\"\n",
        "        # Create a copy of the state\n",
        "        new_state = state.copy()\n",
        "\n",
        "        player_id = state.current_player\n",
        "\n",
        "        # Apply the action\n",
        "        if action == Action.FOLD:\n",
        "            new_state.is_terminal = True\n",
        "            if player_id in new_state.players:\n",
        "                new_state.players.remove(player_id)\n",
        "        elif action == Action.CHECK:\n",
        "            pass  # No bet change\n",
        "        elif action == Action.CALL:\n",
        "            call_amount = max(state.bets.values()) - state.bets.get(player_id, 0)\n",
        "            new_state.bets[player_id] += call_amount\n",
        "            new_state.total_bets[player_id] += call_amount\n",
        "            new_state.pot_size += call_amount\n",
        "        elif action in [Action.BET, Action.RAISE]:\n",
        "            new_state.bets[player_id] += amount\n",
        "            new_state.total_bets[player_id] += amount\n",
        "            new_state.pot_size += amount\n",
        "\n",
        "        # Add to history\n",
        "        new_state.action_history.append((player_id, action, amount))\n",
        "\n",
        "        # Simplified game advancement\n",
        "        if not new_state.is_terminal:\n",
        "            new_state.current_player = 1 - player_id\n",
        "\n",
        "            # Simple completion check\n",
        "            if len(new_state.action_history) >= 4:  # Both players acted twice\n",
        "                new_state = self._try_advance_street(new_state)\n",
        "            elif action in [Action.CHECK, Action.CALL] and len(new_state.action_history) >= 2:\n",
        "                # Check if both players checked or one called\n",
        "                last_two = new_state.action_history[-2:]\n",
        "                if all(act in [Action.CHECK, Action.CALL] for _, act, _ in last_two):\n",
        "                    new_state = self._try_advance_street(new_state)\n",
        "\n",
        "        return new_state\n",
        "\n",
        "    def _try_advance_street(self, state: GameState) -> GameState:\n",
        "        \"\"\"Simplified street advancement.\"\"\"\n",
        "        street_map = {\n",
        "            'preflop': ('flop', 3),\n",
        "            'flop': ('turn', 4),\n",
        "            'turn': ('river', 5),\n",
        "            'river': ('terminal', 5)\n",
        "        }\n",
        "\n",
        "        if state.street in street_map:\n",
        "            next_street, target_board_size = street_map[state.street]\n",
        "\n",
        "            if next_street == 'terminal':\n",
        "                state.is_terminal = True\n",
        "            else:\n",
        "                # Deal cards to reach target board size\n",
        "                cards_needed = target_board_size - len(state.board)\n",
        "                if cards_needed > 0:\n",
        "                    # Get available cards\n",
        "                    used_cards = set()\n",
        "                    for hand in state.hands.values():\n",
        "                        used_cards.update(hand)\n",
        "                    used_cards.update(state.board)\n",
        "\n",
        "                    available_cards = [c for c in DECK if c not in used_cards]\n",
        "                    random.shuffle(available_cards)\n",
        "\n",
        "                    # Deal new cards\n",
        "                    new_cards = available_cards[:cards_needed]\n",
        "                    state.board.extend(new_cards)\n",
        "\n",
        "                state.street = next_street\n",
        "                state.bets = {p: 0.0 for p in state.players}\n",
        "                state.current_player = 0\n",
        "\n",
        "        return state\n",
        "\n",
        "    def _get_utility(self, state: GameState, player_id: int) -> float:\n",
        "        \"\"\"Simplified utility calculation.\"\"\"\n",
        "        if player_id not in state.players:\n",
        "            return -state.total_bets.get(player_id, 0)\n",
        "\n",
        "        if len(state.players) == 1:\n",
        "            return state.pot_size - state.total_bets.get(player_id, 0)\n",
        "\n",
        "        # Simplified showdown using hand strength\n",
        "        if len(state.board) >= 3:  # Any postflop situation\n",
        "            try:\n",
        "                player_strength = evaluate_hand_strength(state.hands[player_id], state.board)\n",
        "\n",
        "                best_opponent_strength = 0\n",
        "                for opp_id in state.players:\n",
        "                    if opp_id != player_id:\n",
        "                        opp_strength = evaluate_hand_strength(state.hands[opp_id], state.board)\n",
        "                        best_opponent_strength = max(best_opponent_strength, opp_strength)\n",
        "\n",
        "                if player_strength > best_opponent_strength:\n",
        "                    return state.pot_size - state.total_bets.get(player_id, 0)\n",
        "                elif player_strength == best_opponent_strength:\n",
        "                    return (state.pot_size / len(state.players)) - state.total_bets.get(player_id, 0)\n",
        "                else:\n",
        "                    return -state.total_bets.get(player_id, 0)\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        # Fallback: random outcome weighted by pot investment\n",
        "        random_outcome = random.choice([1, -1])\n",
        "        return random_outcome * (state.pot_size / 2) - state.total_bets.get(player_id, 0)\n",
        "\n",
        "    def _update_average_strategy(self):\n",
        "        \"\"\"Proper handling of action tuples.\"\"\"\n",
        "        for info_state in self.regret_sum:\n",
        "            # The keys in regret_sum are (Action, amount) tuples\n",
        "            action_tuples = list(self.regret_sum[info_state].keys())\n",
        "\n",
        "            # Convert to the format expected by get_strategy\n",
        "            legal_actions = [(action, amount) for action, amount in action_tuples]\n",
        "\n",
        "            if legal_actions:\n",
        "                strategy = self.get_strategy(info_state, legal_actions)\n",
        "\n",
        "                for action_tuple in strategy:\n",
        "                    self.strategy_sum[info_state][action_tuple] += strategy[action_tuple]\n",
        "\n",
        "        self.strategy_updates += 1\n",
        "\n",
        "    def get_final_policy(self) -> Dict[str, Dict]:\n",
        "        \"\"\"Get the final averaged policy.\"\"\"\n",
        "        final_policy = {}\n",
        "\n",
        "        for info_state in self.strategy_sum:\n",
        "            total_sum = sum(self.strategy_sum[info_state].values())\n",
        "            if total_sum > 0:\n",
        "                final_policy[info_state] = {\n",
        "                    str(action): prob / total_sum\n",
        "                    for action, prob in self.strategy_sum[info_state].items()\n",
        "                }\n",
        "            else:\n",
        "                actions = list(self.strategy_sum[info_state].keys())\n",
        "                uniform_prob = 1.0 / len(actions) if actions else 1.0\n",
        "                final_policy[info_state] = {\n",
        "                    str(action): uniform_prob for action in actions\n",
        "                }\n",
        "\n",
        "        return final_policy\n",
        "\n",
        "    def save_policy(self, filepath: str):\n",
        "        \"\"\"Save the trained policy to disk.\"\"\"\n",
        "        policy_data = {\n",
        "            'final_policy': self.get_final_policy(),\n",
        "            'iteration_count': self.iteration_count,\n",
        "            'regret_states': len(self.regret_sum)\n",
        "        }\n",
        "\n",
        "        with open(filepath, 'wb') as f:\n",
        "            pickle.dump(policy_data, f)\n",
        "        print(f\"Policy saved to {filepath}\")\n",
        "\n",
        "# Test the complete system\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=== Testing Complete MCCFR System ===\")\n",
        "\n",
        "    try:\n",
        "        # Test with mock abstraction manager\n",
        "        print(\"Creating mock abstraction system...\")\n",
        "        manager = MockAbstractionManager(n_clusters_per_round=10)\n",
        "\n",
        "        # Test predictions\n",
        "        test_hands = [\n",
        "            (['As', 'Kh'], ['Qc', '7d', '2s']),\n",
        "            (['9h', '8c'], ['7d', '6s', '2h', 'Tc']),\n",
        "        ]\n",
        "\n",
        "        for hand, board in test_hands:\n",
        "            bucket = manager.get_postflop_bucket(hand, board)\n",
        "            print(f\"Hand {hand} + Board {board} -> Bucket {bucket}\")\n",
        "\n",
        "        print(\"Abstraction system working! Now testing MCCFR...\")\n",
        "\n",
        "        # Use the optimized trainer\n",
        "        trainer = OptimizedMCCFRTrainer(manager)\n",
        "        trainer.train(num_iterations=200)  # Start small\n",
        "\n",
        "        # Show results\n",
        "        final_policy = trainer.get_final_policy()\n",
        "        print(f\"\\nTraining Results:\")\n",
        "        print(f\"- Information states learned: {len(final_policy)}\")\n",
        "        print(f\"- Total iterations: {trainer.iteration_count}\")\n",
        "        print(f\"- Strategy updates: {trainer.strategy_updates}\")\n",
        "\n",
        "        if final_policy:\n",
        "            example_info_state = list(final_policy.keys())[0]\n",
        "            print(f\"\\nExample strategy for info state '{example_info_state}':\")\n",
        "            for action, prob in final_policy[example_info_state].items():\n",
        "                print(f\"  {action}: {prob:.3f}\")\n",
        "\n",
        "        trainer.save_policy(\"optimized_cfr_policy.pkl\")\n",
        "\n",
        "        print(\"SUCCESS: Complete system is working!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGHx8-Lk2_e4",
        "outputId": "67be01d0-1013-47ec-9741-2cd41338e082"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Testing Complete MCCFR System ===\n",
            "Creating mock abstraction system...\n",
            "Hand ['As', 'Kh'] + Board ['Qc', '7d', '2s'] -> Bucket 7\n",
            "Hand ['9h', '8c'] + Board ['7d', '6s', '2h', 'Tc'] -> Bucket 5\n",
            "Abstraction system working! Now testing MCCFR...\n",
            "Initializing Optimized MCCFR Trainer...\n",
            "Optimized MCCFR Trainer initialized successfully.\n",
            "\n",
            "=== Starting Optimized MCCFR Training for 200 iterations ===\n",
            "Iteration 100/200 | Time: 1.9s | States: 673\n",
            "Iteration 200/200 | Time: 3.9s | States: 705\n",
            "Training complete! Total time: 3.9s\n",
            "Final policy contains 0 information states\n",
            "\n",
            "Training Results:\n",
            "- Information states learned: 666\n",
            "- Total iterations: 200\n",
            "- Strategy updates: 4\n",
            "\n",
            "Example strategy for info state 'B79SpAP0':\n",
            "  (<Action.FOLD: 'fold'>, 0): 0.900\n",
            "  (<Action.CALL: 'call'>, 1.0): 0.086\n",
            "  (<Action.RAISE: 'raise'>, 3.0): 0.014\n",
            "  (<Action.RAISE: 'raise'>, 999.0): 0.000\n",
            "Policy saved to optimized_cfr_policy.pkl\n",
            "SUCCESS: Complete system is working!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7FOimylq2lc",
        "outputId": "5ac287ab-1629-4a61-ad5d-226925b6693b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== ULTRA-FAST MCCFR SYSTEM TEST ===\n",
            "Setting up abstraction...\n",
            "Optimized PotentialAwareCalculator initialized.\n",
            "Fixed AbstractionManager initialized.\n",
            "\n",
            "=== STARTING K-MEANS MODEL TRAINING FOR ALL ROUNDS ===\n",
            "\n",
            "--- Training flop model ---\n",
            "--- Generating 1000 feature vectors for flop ---\n",
            "  ...attempting 1000, collected 999/1000...\n",
            "Generated 1000 valid vectors (0 failed) in 1.81s\n",
            "Removed 4 duplicate vectors\n",
            "Training K-Means on 996 vectors with 8 features\n",
            "Using 10 clusters\n",
            "Silhouette Score: 0.287\n",
            "flop model trained successfully!\n",
            "\n",
            "--- Training turn model ---\n",
            "--- Generating 1000 feature vectors for turn ---\n",
            "  ...attempting 1000, collected 999/1000...\n",
            "Generated 1000 valid vectors (0 failed) in 3.01s\n",
            "Removed 2 duplicate vectors\n",
            "Training K-Means on 998 vectors with 8 features\n",
            "Using 10 clusters\n",
            "Silhouette Score: 0.270\n",
            "turn model trained successfully!\n",
            "\n",
            "--- Training river model ---\n",
            "--- Generating 1000 feature vectors for river ---\n",
            "  ...attempting 1000, collected 999/1000...\n",
            "Generated 1000 valid vectors (0 failed) in 1.67s\n",
            "Removed 8 duplicate vectors\n",
            "Training K-Means on 992 vectors with 8 features\n",
            "Using 10 clusters\n",
            "Silhouette Score: 0.304\n",
            "river model trained successfully!\n",
            "Testing ultra-fast trainer...\n",
            "Initializing Ultra-Fast MCCFR Trainer...\n",
            "Ultra-Fast MCCFR Trainer initialized.\n",
            "\n",
            "=== Ultra-Fast MCCFR Training: 1000 iterations ===\n",
            "Iter 50/1000 | 4.6s | 10.9 iter/s | States: 180\n",
            "Iter 100/1000 | 10.3s | 9.7 iter/s | States: 182\n",
            "Iter 150/1000 | 15.1s | 9.9 iter/s | States: 182\n",
            "Iter 200/1000 | 19.7s | 10.2 iter/s | States: 182\n",
            "Iter 250/1000 | 25.7s | 9.7 iter/s | States: 182\n",
            "Iter 300/1000 | 30.3s | 9.9 iter/s | States: 182\n",
            "Iter 350/1000 | 35.8s | 9.8 iter/s | States: 182\n",
            "Iter 400/1000 | 40.8s | 9.8 iter/s | States: 182\n",
            "Iter 450/1000 | 45.5s | 9.9 iter/s | States: 182\n",
            "Iter 500/1000 | 51.4s | 9.7 iter/s | States: 182\n",
            "Iter 550/1000 | 56.2s | 9.8 iter/s | States: 182\n",
            "Iter 600/1000 | 62.0s | 9.7 iter/s | States: 182\n",
            "Iter 650/1000 | 66.7s | 9.7 iter/s | States: 182\n",
            "Iter 700/1000 | 71.4s | 9.8 iter/s | States: 182\n",
            "Iter 750/1000 | 77.3s | 9.7 iter/s | States: 182\n",
            "Iter 800/1000 | 81.9s | 9.8 iter/s | States: 182\n",
            "Iter 850/1000 | 87.7s | 9.7 iter/s | States: 182\n",
            "Iter 900/1000 | 92.4s | 9.7 iter/s | States: 182\n",
            "Iter 950/1000 | 97.0s | 9.8 iter/s | States: 182\n",
            "Iter 1000/1000 | 103.0s | 9.7 iter/s | States: 182\n",
            "Training done! 103.1s | 9.7 iter/s | 182 states\n",
            "\n",
            "Results:\n",
            "- States: 182\n",
            "- Iterations: 1000\n",
            "- Updates: 40\n",
            "Policy saved: 182 states\n",
            "SUCCESS: Ultra-fast training complete!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from collections import defaultdict\n",
        "import time\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "from enum import Enum\n",
        "from copy import copy\n",
        "\n",
        "class UltraFastMCCFRTrainer:\n",
        "    \"\"\"Ultra-optimized version for maximum training speed.\"\"\"\n",
        "\n",
        "    def __init__(self, abstraction_manager, initial_stack=1000.0):\n",
        "        print(\"Initializing Ultra-Fast MCCFR Trainer...\")\n",
        "\n",
        "        self.abstraction_manager = abstraction_manager\n",
        "        self.initial_stack = initial_stack\n",
        "\n",
        "        # CFR data structures - using regular dicts for speed\n",
        "        self.regret_sum = {}\n",
        "        self.strategy_sum = {}\n",
        "\n",
        "        self.iteration_count = 0\n",
        "        self.strategy_updates = 0\n",
        "\n",
        "        # PERFORMANCE OPTIMIZATIONS\n",
        "        self.max_actions_per_state = 15  # Limit action history length\n",
        "        self.max_recursion_depth = 12    # Reduced further\n",
        "        self.current_depth = 0\n",
        "\n",
        "        # Pre-computed common values\n",
        "        self.streets = ['preflop', 'flop', 'turn', 'river']\n",
        "        self.street_to_board_size = {'preflop': 0, 'flop': 3, 'turn': 4, 'river': 5}\n",
        "\n",
        "        # Simplified preflop buckets\n",
        "        self._init_fast_preflop_buckets()\n",
        "\n",
        "        print(\"Ultra-Fast MCCFR Trainer initialized.\")\n",
        "\n",
        "    def _init_fast_preflop_buckets(self):\n",
        "        \"\"\"Lightning-fast preflop bucketing.\"\"\"\n",
        "        self.preflop_buckets = {}\n",
        "\n",
        "        # Only the most essential hand categories\n",
        "        premium = ['AA', 'KK', 'QQ', 'AKs', 'AKo']\n",
        "        strong = ['JJ', 'TT', 'AQs', 'AQo', 'KQs']\n",
        "        decent = ['99', '88', 'AJs', 'AJo', 'KJs', 'KQo']\n",
        "\n",
        "        bucket = 60\n",
        "        for group in [premium, strong, decent]:\n",
        "            for hand in group:\n",
        "                self.preflop_buckets[hand] = bucket\n",
        "            bucket += 1\n",
        "\n",
        "    def get_preflop_bucket(self, hand: List[str]) -> int:\n",
        "        \"\"\"Optimized preflop bucketing.\"\"\"\n",
        "        ranks = [card[0] for card in hand]\n",
        "        suits = [card[1] for card in hand]\n",
        "\n",
        "        # Quick pocket pair check\n",
        "        if ranks[0] == ranks[1]:\n",
        "            hand_str = ranks[0] + ranks[0]\n",
        "        else:\n",
        "            # Sort ranks by strength\n",
        "            if RANKS.index(ranks[0]) > RANKS.index(ranks[1]):\n",
        "                sorted_ranks = ranks\n",
        "            else:\n",
        "                sorted_ranks = [ranks[1], ranks[0]]\n",
        "\n",
        "            suited = 's' if suits[0] == suits[1] else 'o'\n",
        "            hand_str = ''.join(sorted_ranks) + suited\n",
        "\n",
        "        return self.preflop_buckets.get(hand_str, 79)\n",
        "\n",
        "    def get_info_state(self, state: GameState, player_id: int) -> str:\n",
        "        \"\"\"Ultra-simplified info state for maximum speed.\"\"\"\n",
        "        hand = state.hands[player_id]\n",
        "        board = state.board\n",
        "\n",
        "        # Get bucket\n",
        "        if state.street == 'preflop':\n",
        "            bucket = self.get_preflop_bucket(hand)\n",
        "        else:\n",
        "            bucket = self.abstraction_manager.get_postflop_bucket(hand, board)\n",
        "\n",
        "        # ULTRA SIMPLIFIED: Only most recent action and pot size category\n",
        "        last_action = 'x'  # default\n",
        "        if state.action_history:\n",
        "            last_action = state.action_history[-1][1].value[0]\n",
        "\n",
        "        # Discretize pot to 5 categories\n",
        "        pot_cat = min(4, int(state.pot_size / 20))\n",
        "\n",
        "        # Minimal info state\n",
        "        return f\"B{bucket}S{state.street[0]}L{last_action}P{pot_cat}\"\n",
        "\n",
        "    def get_legal_actions(self, state: GameState, player_id: int) -> List[Tuple[Action, float]]:\n",
        "        \"\"\"Streamlined action generation with safety guarantees.\"\"\"\n",
        "        actions = []\n",
        "        to_call = max(state.bets.values()) - state.bets.get(player_id, 0)\n",
        "        stack = self.initial_stack - state.total_bets.get(player_id, 0)\n",
        "\n",
        "        # SAFETY: Ensure stack is positive\n",
        "        if stack <= 0:\n",
        "            return [(Action.FOLD, 0)]\n",
        "\n",
        "        # Fold if facing bet\n",
        "        if to_call > 0:\n",
        "            actions.append((Action.FOLD, 0))\n",
        "\n",
        "        # Check/Call\n",
        "        if to_call == 0:\n",
        "            actions.append((Action.CHECK, 0))\n",
        "        elif to_call <= stack:\n",
        "            actions.append((Action.CALL, to_call))\n",
        "\n",
        "        # Only ONE bet size for maximum speed\n",
        "        pot_bet = max(state.pot_size * 0.8, 1.0)  # Slightly less than pot\n",
        "        min_bet = max(to_call * 2, 1.0) if to_call > 0 else 1.0\n",
        "\n",
        "        if pot_bet <= stack and pot_bet >= min_bet:\n",
        "            if to_call == 0:\n",
        "                actions.append((Action.BET, pot_bet))\n",
        "            else:\n",
        "                actions.append((Action.RAISE, pot_bet))\n",
        "\n",
        "        # SAFETY: Always return at least one action\n",
        "        if not actions:\n",
        "            if to_call > 0:\n",
        "                actions = [(Action.FOLD, 0)]\n",
        "            else:\n",
        "                actions = [(Action.CHECK, 0)]\n",
        "\n",
        "        return actions\n",
        "\n",
        "    def get_strategy(self, info_state: str, legal_actions: List[Tuple[Action, float]]) -> Dict[Tuple[Action, float], float]:\n",
        "        \"\"\"Optimized regret matching with safety checks.\"\"\"\n",
        "        if info_state not in self.regret_sum:\n",
        "            self.regret_sum[info_state] = {}\n",
        "\n",
        "        strategy = {}\n",
        "\n",
        "        # SAFETY: Handle empty legal_actions\n",
        "        if not legal_actions:\n",
        "            return strategy\n",
        "\n",
        "        regret_sum = 0.0\n",
        "\n",
        "        # Calculate positive regret sum\n",
        "        for action_tuple in legal_actions:\n",
        "            regret = self.regret_sum[info_state].get(action_tuple, 0.0)\n",
        "            regret_sum += max(0, regret)\n",
        "\n",
        "        # Generate strategy\n",
        "        if regret_sum > 0:\n",
        "            for action_tuple in legal_actions:\n",
        "                regret = self.regret_sum[info_state].get(action_tuple, 0.0)\n",
        "                strategy[action_tuple] = max(0, regret) / regret_sum\n",
        "        else:\n",
        "            # SAFETY: Check for division by zero\n",
        "            if len(legal_actions) > 0:\n",
        "                prob = 1.0 / len(legal_actions)\n",
        "                for action_tuple in legal_actions:\n",
        "                    strategy[action_tuple] = prob\n",
        "\n",
        "        return strategy\n",
        "\n",
        "    def train(self, num_iterations: int = 1000):\n",
        "        \"\"\"Ultra-optimized training loop.\"\"\"\n",
        "        print(f\"\\n=== Ultra-Fast MCCFR Training: {num_iterations} iterations ===\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        for i in range(num_iterations):\n",
        "            self.iteration_count += 1\n",
        "\n",
        "            # Progress every 50 iterations for speed\n",
        "            if (i + 1) % 50 == 0:\n",
        "                elapsed = time.time() - start_time\n",
        "                rate = (i + 1) / elapsed\n",
        "                print(f\"Iter {i+1}/{num_iterations} | {elapsed:.1f}s | {rate:.1f} iter/s | States: {len(self.regret_sum)}\")\n",
        "\n",
        "            # Reset depth\n",
        "            self.current_depth = 0\n",
        "\n",
        "            try:\n",
        "                self._run_iteration()\n",
        "\n",
        "                # Timeout protection (reduced to 2 minutes)\n",
        "                if elapsed := time.time() - start_time > 120:\n",
        "                    print(f\"Timeout after {i+1} iterations\")\n",
        "                    break\n",
        "\n",
        "            except Exception as e:\n",
        "                if i < 10:  # Only print first few errors\n",
        "                    print(f\"Error iter {i+1}: {e}\")\n",
        "                continue\n",
        "\n",
        "            # Update strategy more frequently\n",
        "            if i % 25 == 0:\n",
        "                self._update_strategy()\n",
        "\n",
        "        total_time = time.time() - start_time\n",
        "        rate = self.iteration_count / total_time if total_time > 0 else 0\n",
        "        print(f\"Training done! {total_time:.1f}s | {rate:.1f} iter/s | {len(self.regret_sum)} states\")\n",
        "\n",
        "    def _run_iteration(self):\n",
        "        \"\"\"Simplified iteration.\"\"\"\n",
        "        state = self._create_fast_state()\n",
        "\n",
        "        # Alternate which player we're traversing\n",
        "        traversing_player = self.iteration_count % 2\n",
        "\n",
        "        try:\n",
        "            self._mccfr(state, traversing_player, 1.0, 1.0)\n",
        "        except Exception:\n",
        "            pass  # Silently continue\n",
        "\n",
        "    def _create_fast_state(self) -> GameState:\n",
        "        \"\"\"Lightning-fast state creation.\"\"\"\n",
        "        # Pre-shuffled deck approach\n",
        "        deck_copy = DECK.copy()\n",
        "        random.shuffle(deck_copy)\n",
        "\n",
        "        return GameState(\n",
        "            players=[0, 1],\n",
        "            current_player=0,\n",
        "            pot_size=3.0,\n",
        "            street='preflop',\n",
        "            board=[],\n",
        "            hands={0: deck_copy[:2], 1: deck_copy[2:4]},\n",
        "            bets={0: 1.0, 1: 2.0},\n",
        "            total_bets={0: 1.0, 1: 2.0},\n",
        "            action_history=[]\n",
        "        )\n",
        "\n",
        "    def _mccfr(self, state: GameState, traversing_player: int, pi_p: float, pi_o: float) -> float:\n",
        "        \"\"\"Ultra-streamlined MCCFR.\"\"\"\n",
        "\n",
        "        # Depth protection\n",
        "        self.current_depth += 1\n",
        "        if self.current_depth > self.max_recursion_depth:\n",
        "            self.current_depth -= 1\n",
        "            return self._fast_utility(state, traversing_player)\n",
        "\n",
        "        # Terminal checks\n",
        "        if state.is_terminal or len(state.action_history) > self.max_actions_per_state:\n",
        "            self.current_depth -= 1\n",
        "            return self._fast_utility(state, traversing_player)\n",
        "\n",
        "        player = state.current_player\n",
        "        info_state = self.get_info_state(state, player)\n",
        "        legal_actions = self.get_legal_actions(state, player)\n",
        "\n",
        "        if not legal_actions:\n",
        "            self.current_depth -= 1\n",
        "            return self._fast_utility(state, traversing_player)\n",
        "\n",
        "        strategy = self.get_strategy(info_state, legal_actions)\n",
        "\n",
        "        # Action utilities\n",
        "        utilities = {}\n",
        "        for action_tuple in legal_actions:\n",
        "            new_state = self._fast_apply_action(state, action_tuple[0], action_tuple[1])\n",
        "\n",
        "            if player == traversing_player:\n",
        "                utilities[action_tuple] = self._mccfr(\n",
        "                    new_state, traversing_player,\n",
        "                    pi_p * strategy[action_tuple], pi_o\n",
        "                )\n",
        "            else:\n",
        "                utilities[action_tuple] = self._mccfr(\n",
        "                    new_state, traversing_player,\n",
        "                    pi_p, pi_o * strategy[action_tuple]\n",
        "                )\n",
        "\n",
        "        # Node utility\n",
        "        node_util = sum(strategy[at] * utilities[at] for at in legal_actions)\n",
        "\n",
        "        # Update regrets for traversing player\n",
        "        if player == traversing_player:\n",
        "            if info_state not in self.regret_sum:\n",
        "                self.regret_sum[info_state] = {}\n",
        "\n",
        "            for action_tuple in legal_actions:\n",
        "                regret = utilities[action_tuple] - node_util\n",
        "                current_regret = self.regret_sum[info_state].get(action_tuple, 0.0)\n",
        "                self.regret_sum[info_state][action_tuple] = current_regret + pi_o * regret\n",
        "\n",
        "        self.current_depth -= 1\n",
        "        return node_util\n",
        "\n",
        "    def _fast_apply_action(self, state: GameState, action: Action, amount: float) -> GameState:\n",
        "        \"\"\"Optimized action application.\"\"\"\n",
        "        # Shallow copy for speed\n",
        "        new_state = copy(state)\n",
        "        new_state.bets = state.bets.copy()\n",
        "        new_state.total_bets = state.total_bets.copy()\n",
        "        new_state.players = state.players.copy()\n",
        "        new_state.action_history = state.action_history.copy()\n",
        "        new_state.hands = state.hands  # Reference copy - don't change hands\n",
        "        new_state.board = state.board.copy()\n",
        "\n",
        "        player = state.current_player\n",
        "\n",
        "        # Apply action\n",
        "        if action == Action.FOLD:\n",
        "            new_state.is_terminal = True\n",
        "            new_state.players.remove(player)\n",
        "        elif action == Action.CHECK:\n",
        "            pass\n",
        "        elif action == Action.CALL:\n",
        "            call_amt = max(state.bets.values()) - state.bets.get(player, 0)\n",
        "            new_state.bets[player] += call_amt\n",
        "            new_state.total_bets[player] += call_amt\n",
        "            new_state.pot_size += call_amt\n",
        "        elif action in [Action.BET, Action.RAISE]:\n",
        "            new_state.bets[player] += amount\n",
        "            new_state.total_bets[player] += amount\n",
        "            new_state.pot_size += amount\n",
        "\n",
        "        # Add to history\n",
        "        new_state.action_history.append((player, action, amount))\n",
        "\n",
        "        if not new_state.is_terminal:\n",
        "            new_state.current_player = 1 - player\n",
        "\n",
        "            # Simple street advancement\n",
        "            if self._should_advance_street(new_state):\n",
        "                self._advance_street_fast(new_state)\n",
        "\n",
        "        return new_state\n",
        "\n",
        "    def _should_advance_street(self, state: GameState) -> bool:\n",
        "        \"\"\"Fast street advancement check.\"\"\"\n",
        "        if len(state.action_history) < 2:\n",
        "            return False\n",
        "\n",
        "        # Check if both players acted and betting is equal\n",
        "        recent = state.action_history[-2:]\n",
        "        actions = [act for _, act, _ in recent]\n",
        "\n",
        "        # Advance on check-check or call patterns\n",
        "        return (Action.CHECK in actions or\n",
        "                Action.CALL in actions or\n",
        "                len(state.action_history) >= 4)\n",
        "\n",
        "    def _advance_street_fast(self, state: GameState):\n",
        "        \"\"\"Lightning-fast street advancement.\"\"\"\n",
        "        if state.street == 'preflop':\n",
        "            state.street = 'flop'\n",
        "            self._deal_board(state, 3)\n",
        "        elif state.street == 'flop':\n",
        "            state.street = 'turn'\n",
        "            self._deal_board(state, 4)\n",
        "        elif state.street == 'turn':\n",
        "            state.street = 'river'\n",
        "            self._deal_board(state, 5)\n",
        "        else:\n",
        "            state.is_terminal = True\n",
        "            return\n",
        "\n",
        "        # Reset for new street\n",
        "        state.bets = {p: 0.0 for p in state.players}\n",
        "        state.current_player = 0\n",
        "\n",
        "    def _deal_board(self, state: GameState, target_size: int):\n",
        "        \"\"\"Fast board card dealing.\"\"\"\n",
        "        cards_needed = target_size - len(state.board)\n",
        "        if cards_needed <= 0:\n",
        "            return\n",
        "\n",
        "        # Get used cards\n",
        "        used = set(state.board)\n",
        "        for hand in state.hands.values():\n",
        "            used.update(hand)\n",
        "\n",
        "        # Deal from available cards\n",
        "        available = [c for c in DECK if c not in used]\n",
        "        random.shuffle(available)\n",
        "        state.board.extend(available[:cards_needed])\n",
        "\n",
        "    def _fast_utility(self, state: GameState, player_id: int) -> float:\n",
        "        \"\"\"Super-fast utility calculation.\"\"\"\n",
        "        if player_id not in state.players:\n",
        "            return -state.total_bets.get(player_id, 0)\n",
        "\n",
        "        if len(state.players) == 1:\n",
        "            return state.pot_size - state.total_bets.get(player_id, 0)\n",
        "\n",
        "        # Quick random showdown\n",
        "        if len(state.board) >= 3:\n",
        "            # 50/50 chance with small bias toward better position\n",
        "            win_prob = 0.5 + (0.1 if player_id == 0 else -0.1)\n",
        "            if random.random() < win_prob:\n",
        "                return state.pot_size - state.total_bets.get(player_id, 0)\n",
        "            else:\n",
        "                return -state.total_bets.get(player_id, 0)\n",
        "\n",
        "        # Preflop: slight random outcome\n",
        "        return random.choice([1, -1]) * (state.pot_size * 0.3)\n",
        "\n",
        "    def _update_strategy(self):\n",
        "        \"\"\"Fast strategy update.\"\"\"\n",
        "        for info_state in self.regret_sum:\n",
        "            actions = list(self.regret_sum[info_state].keys())\n",
        "            strategy = self.get_strategy(info_state, actions)\n",
        "\n",
        "            if info_state not in self.strategy_sum:\n",
        "                self.strategy_sum[info_state] = {}\n",
        "\n",
        "            for action_tuple in strategy:\n",
        "                current = self.strategy_sum[info_state].get(action_tuple, 0.0)\n",
        "                self.strategy_sum[info_state][action_tuple] = current + strategy[action_tuple]\n",
        "\n",
        "        self.strategy_updates += 1\n",
        "\n",
        "    def get_final_policy(self) -> Dict[str, Dict]:\n",
        "        \"\"\"Fast policy extraction.\"\"\"\n",
        "        policy = {}\n",
        "\n",
        "        for info_state in self.strategy_sum:\n",
        "            total = sum(self.strategy_sum[info_state].values())\n",
        "            if total > 0:\n",
        "                policy[info_state] = {\n",
        "                    str(action): prob / total\n",
        "                    for action, prob in self.strategy_sum[info_state].items()\n",
        "                }\n",
        "\n",
        "        return policy\n",
        "\n",
        "    def save_policy(self, filepath: str):\n",
        "        \"\"\"Fast policy save.\"\"\"\n",
        "        import pickle\n",
        "\n",
        "        data = {\n",
        "            'policy': self.get_final_policy(),\n",
        "            'iterations': self.iteration_count,\n",
        "            'states': len(self.regret_sum),\n",
        "            'updates': self.strategy_updates\n",
        "        }\n",
        "\n",
        "        with open(filepath, 'wb') as f:\n",
        "            pickle.dump(data, f)\n",
        "\n",
        "        print(f\"Policy saved: {len(data['policy'])} states\")\n",
        "\n",
        "\n",
        "# USAGE EXAMPLE\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=== ULTRA-FAST MCCFR SYSTEM TEST ===\")\n",
        "\n",
        "    try:\n",
        "        # Use your existing abstraction\n",
        "        print(\"Setting up abstraction...\")\n",
        "        manager = FixedAbstractionManager(n_clusters_per_round=10)\n",
        "        manager.train_all_postflop_models(n_samples_per_round=1000)\n",
        "\n",
        "        print(\"Testing ultra-fast trainer...\")\n",
        "        trainer = UltraFastMCCFRTrainer(manager)\n",
        "\n",
        "        # This should be MUCH faster\n",
        "        trainer.train(num_iterations=1000)\n",
        "\n",
        "        # Results\n",
        "        policy = trainer.get_final_policy()\n",
        "        print(f\"\\nResults:\")\n",
        "        print(f\"- States: {len(policy)}\")\n",
        "        print(f\"- Iterations: {trainer.iteration_count}\")\n",
        "        print(f\"- Updates: {trainer.strategy_updates}\")\n",
        "\n",
        "        trainer.save_policy(\"ultra_fast_policy.pkl\")\n",
        "        print(\"SUCCESS: Ultra-fast training complete!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpD59JFBGCY5"
      },
      "source": [
        "#Evaluations\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (Add this class to your evaluation_engine.py file)\n",
        "\n",
        "# You will need your AbstractionManager here\n",
        "# from final_abstraction_engine import FixedAbstractionManager\n",
        "\n",
        "class RealMCCFRBotStrategy:\n",
        "    \"\"\"\n",
        "    This is your real, trained AI. It loads the policy from disk and uses\n",
        "    the abstraction manager to convert game states into info states.\n",
        "    \"\"\"\n",
        "    def __init__(self, policy_file: str, abstraction_manager):\n",
        "        print(f\"Loading REAL trained policy from: {policy_file}\")\n",
        "        with open(policy_file, 'rb') as f:\n",
        "            policy_data = pickle.load(f)\n",
        "\n",
        "        # Adapt this key based on how you saved your policy\n",
        "        self.policy = policy_data.get('final_policy', {})\n",
        "        self.abstraction_manager = abstraction_manager\n",
        "        print(f\"Policy loaded. Agent knows {len(self.policy)} info states.\")\n",
        "\n",
        "    def get_action(self, state: GameState, player_id: int) -> Tuple[Action, float]:\n",
        "        \"\"\"Makes a decision using the loaded policy.\"\"\"\n",
        "        # 1. Convert the rich GameState into the simplified info_state string.\n",
        "        info_state = self._get_info_state(state, player_id)\n",
        "\n",
        "        strategy = self.policy.get(info_state)\n",
        "\n",
        "        if strategy:\n",
        "            # 2. Choose an action based on the learned probabilities.\n",
        "            # The keys in the saved policy might be strings, need to parse them.\n",
        "\n",
        "            # This parsing logic is complex and must match EXACTLY how you save it.\n",
        "            # Let's assume a simpler format for now.\n",
        "            actions_list = []\n",
        "            probs_list = []\n",
        "            for action_str, prob in strategy.items():\n",
        "                # This is a placeholder for robust parsing logic\n",
        "                try:\n",
        "                    # e.g., action_str = \"(<Action.RAISE: 'raise'>, 100.0)\"\n",
        "                    action_enum_str, amount_str = action_str.strip('()').split(', ')\n",
        "                    action = Action(action_enum_str.split('.')[-1].strip('>').lower())\n",
        "                    amount = float(amount_str)\n",
        "                    actions_list.append((action, amount))\n",
        "                    probs_list.append(prob)\n",
        "                except:\n",
        "                    continue # Skip malformed actions\n",
        "\n",
        "            if not actions_list: return self._fallback_action(state, player_id)\n",
        "\n",
        "            # Normalize probabilities to be safe\n",
        "            probs_list = np.array(probs_list) / np.sum(probs_list)\n",
        "\n",
        "            chosen_idx = np.random.choice(len(actions_list), p=probs_list)\n",
        "            return actions_list[chosen_idx]\n",
        "        else:\n",
        "            # 3. If the state is new, use a safe fallback.\n",
        "            return self._fallback_action(state, player_id)\n",
        "\n",
        "    def _fallback_action(self, state: GameState, player_id: int) -> Tuple[Action, float]:\n",
        "        \"\"\"A safe action to take when an info state is not in the policy.\"\"\"\n",
        "        to_call = max(state.bets.values()) - state.bets.get(player_id, 0)\n",
        "        if to_call == 0:\n",
        "            return (Action.CHECK, 0)\n",
        "        else:\n",
        "            return (Action.FOLD, 0)\n",
        "\n",
        "    def _get_info_state(self, state: GameState, player_id: int) -> str:\n",
        "        \"\"\"\n",
        "        This must be the IDENTICAL info state generation logic from your trainer.\n",
        "        \"\"\"\n",
        "        hand = state.hands[player_id]\n",
        "        board = state.board\n",
        "\n",
        "        if state.street == 'preflop':\n",
        "            # This needs to call the preflop bucketing from your trainer\n",
        "            bucket_id = 79 # fallback\n",
        "        else:\n",
        "            bucket_id = self.abstraction_manager.get_postflop_bucket(hand, board)\n",
        "\n",
        "        # Recreate the simplified action string\n",
        "        recent_actions = state.action_history[-3:]\n",
        "        action_str = ''.join([f\"{a.value[0]}\" for _, a, _ in recent_actions])\n",
        "        pot_ratio = min(9, int(state.pot_size / 10))\n",
        "\n",
        "        return f\"B{bucket_id}S{state.street[0]}A{action_str}P{pot_ratio}\"\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VAIuwQeu7G1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-foHs3HF_wc",
        "outputId": "415fcef4-9d3d-479a-b262-fd5509693b8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🃏 === POKER BOT EVALUATION SYSTEM ===\n",
            "Creating mock bot strategy for testing...\n",
            "Running evaluation with mock strategy...\n",
            "Mock MCCFR Bot Strategy initialized (no real training)\n",
            "\n",
            "=== Evaluating Bot vs TIGHT ===\n",
            "Playing 100 games...\n",
            "  Game 100/100 | 2.8s\n",
            "\n",
            "--- Results vs TIGHT ---\n",
            "Win Rate: 22.0%\n",
            "Average Profit: -1509.08 chips\n",
            "Total Profit: -150908.30 chips\n",
            "Hands Played: 5000\n",
            "95% CI: [-1852.73, -1165.44]\n",
            "❌ LOSING against this opponent\n",
            "✅ Evaluation system is ready for real models.\n",
            "✅ Evaluation system test complete!\n",
            "\n",
            "To use with real trained models:\n",
            "1. Train your abstraction manager and MCCFR policy\n",
            "2. Replace MockMCCFRBotStrategy with your real MCCFRBotStrategy\n",
            "3. Update file paths to your trained models\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import pickle\n",
        "from collections import defaultdict, Counter\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "from dataclasses import dataclass\n",
        "from enum import Enum\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "# --- Basic Game Definitions ---\n",
        "SUITS = ['h', 'd', 'c', 's']\n",
        "RANKS = ['2', '3', '4', '5', '6', '7', '8', '9', 'T', 'J', 'Q', 'K', 'A']\n",
        "DECK = [r + s for r in RANKS for s in SUITS]\n",
        "RANK_MAP = {rank: i for i, rank in enumerate(RANKS)}\n",
        "\n",
        "class Action(Enum):\n",
        "    FOLD = \"fold\"\n",
        "    CHECK = \"check\"\n",
        "    CALL = \"call\"\n",
        "    BET = \"bet\"\n",
        "    RAISE = \"raise\"\n",
        "\n",
        "@dataclass\n",
        "class GameState:\n",
        "    \"\"\"Fixed GameState class - removed 'players' parameter causing the error.\"\"\"\n",
        "    current_player: int\n",
        "    pot_size: float\n",
        "    street: str\n",
        "    board: List[str]\n",
        "    hands: Dict[int, List[str]]\n",
        "    bets: Dict[int, float]\n",
        "    total_bets: Dict[int, float]\n",
        "    action_history: List[Tuple[int, Action, float]]\n",
        "    is_terminal: bool = False\n",
        "\n",
        "    def __post_init__(self):\n",
        "        # Initialize players list based on hands\n",
        "        if not hasattr(self, 'players'):\n",
        "            self.players = list(self.hands.keys())\n",
        "\n",
        "class OpponentType(Enum):\n",
        "    RANDOM = \"random\"\n",
        "    TIGHT = \"tight\"\n",
        "    LOOSE = \"loose\"\n",
        "    AGGRESSIVE = \"aggressive\"\n",
        "    STUMBOT = \"stumbot\"\n",
        "\n",
        "@dataclass\n",
        "class GameResult:\n",
        "    \"\"\"Results from a single poker game.\"\"\"\n",
        "    winner: int\n",
        "    final_stacks: Dict[int, float]\n",
        "    hands_played: int\n",
        "    total_pot: float\n",
        "    game_length: int  # Number of actions\n",
        "\n",
        "@dataclass\n",
        "class EvaluationResults:\n",
        "    \"\"\"Complete evaluation results.\"\"\"\n",
        "    win_rate: float\n",
        "    avg_profit: float\n",
        "    total_profit: float\n",
        "    hands_played: int\n",
        "    opponent_type: str\n",
        "    confidence_interval: Tuple[float, float]\n",
        "    game_results: List[GameResult]\n",
        "\n",
        "class PokerGameEngine:\n",
        "    \"\"\"Complete poker game engine for evaluation.\"\"\"\n",
        "\n",
        "    def __init__(self, initial_stack=20000, small_blind=50, big_blind=100):\n",
        "        self.initial_stack = initial_stack\n",
        "        self.small_blind = small_blind\n",
        "        self.big_blind = big_blind\n",
        "\n",
        "    def play_game(self, player1_strategy, player2_strategy, max_hands=100) -> GameResult:\n",
        "        \"\"\"Play a complete poker game between two strategies.\"\"\"\n",
        "\n",
        "        # Initialize stacks\n",
        "        stacks = {0: self.initial_stack, 1: self.initial_stack}\n",
        "        hands_played = 0\n",
        "        total_actions = 0\n",
        "        total_pot_won = 0\n",
        "\n",
        "        while hands_played < max_hands and min(stacks.values()) > self.big_blind:\n",
        "            # Play one hand\n",
        "            try:\n",
        "                hand_result = self._play_hand(player1_strategy, player2_strategy, stacks, hands_played)\n",
        "\n",
        "                # Update stacks\n",
        "                stacks[0] += hand_result['player_0_change']\n",
        "                stacks[1] += hand_result['player_1_change']\n",
        "                total_pot_won += hand_result['pot_size']\n",
        "                total_actions += hand_result['actions']\n",
        "                hands_played += 1\n",
        "\n",
        "                # Switch button/blinds\n",
        "                if hands_played % 2 == 0:\n",
        "                    stacks[0] -= self.small_blind\n",
        "                    stacks[1] -= self.big_blind\n",
        "                else:\n",
        "                    stacks[0] -= self.big_blind\n",
        "                    stacks[1] -= self.small_blind\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error in hand {hands_played}: {e}\")\n",
        "                hands_played += 1\n",
        "                continue\n",
        "\n",
        "        # Determine winner\n",
        "        winner = 0 if stacks[0] > stacks[1] else 1\n",
        "\n",
        "        return GameResult(\n",
        "            winner=winner,\n",
        "            final_stacks=stacks,\n",
        "            hands_played=hands_played,\n",
        "            total_pot=total_pot_won,\n",
        "            game_length=total_actions\n",
        "        )\n",
        "\n",
        "    def _play_hand(self, p1_strategy, p2_strategy, stacks, hand_num) -> Dict:\n",
        "        \"\"\"Play a single poker hand.\"\"\"\n",
        "\n",
        "        # Deal cards\n",
        "        deck = DECK.copy()\n",
        "        random.shuffle(deck)\n",
        "        hands = {0: deck[:2], 1: deck[2:4]}\n",
        "        board = []\n",
        "\n",
        "        # Initialize hand state\n",
        "        pot = self.small_blind + self.big_blind\n",
        "        bets = {0: self.small_blind, 1: self.big_blind}\n",
        "        total_bets = bets.copy()\n",
        "\n",
        "        # Determine positions (alternate button)\n",
        "        button = hand_num % 2\n",
        "\n",
        "        # FIXED: Create GameState without 'players' parameter\n",
        "        state = GameState(\n",
        "            current_player=button,  # Button acts first preflop\n",
        "            pot_size=pot,\n",
        "            street='preflop',\n",
        "            board=board,\n",
        "            hands=hands,\n",
        "            bets=bets,\n",
        "            total_bets=total_bets,\n",
        "            action_history=[]\n",
        "        )\n",
        "\n",
        "        # Play through all streets\n",
        "        action_count = 0\n",
        "        max_actions = 20  # Prevent infinite loops\n",
        "\n",
        "        while not state.is_terminal and action_count < max_actions:\n",
        "\n",
        "            # Get current player's action\n",
        "            current_player = state.current_player\n",
        "            try:\n",
        "                if current_player == 0:\n",
        "                    action, amount = p1_strategy.get_action(state, current_player)\n",
        "                else:\n",
        "                    action, amount = p2_strategy.get_action(state, current_player)\n",
        "\n",
        "                # Apply action\n",
        "                state = self._apply_action(state, action, amount)\n",
        "                action_count += 1\n",
        "\n",
        "                # Check for street advancement or game end\n",
        "                if self._should_advance_street(state):\n",
        "                    state = self._advance_to_next_street(state, deck)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error in action processing: {e}\")\n",
        "                # Force terminal state to avoid infinite loop\n",
        "                state.is_terminal = True\n",
        "                break\n",
        "\n",
        "        # Calculate final result\n",
        "        try:\n",
        "            if state.is_terminal:\n",
        "                payoffs = self._calculate_showdown(state)\n",
        "            else:\n",
        "                # Timeout - split pot\n",
        "                payoffs = {0: 0, 1: 0}\n",
        "        except Exception as e:\n",
        "            print(f\"Error in showdown: {e}\")\n",
        "            payoffs = {0: 0, 1: 0}\n",
        "\n",
        "        return {\n",
        "            'player_0_change': payoffs[0],\n",
        "            'player_1_change': payoffs[1],\n",
        "            'pot_size': state.pot_size,\n",
        "            'actions': action_count\n",
        "        }\n",
        "\n",
        "    def _apply_action(self, state: GameState, action: Action, amount: float) -> GameState:\n",
        "        \"\"\"Apply an action to the game state.\"\"\"\n",
        "        from copy import deepcopy\n",
        "        new_state = deepcopy(state)\n",
        "\n",
        "        player = state.current_player\n",
        "\n",
        "        if action == Action.FOLD:\n",
        "            new_state.is_terminal = True\n",
        "            if player in new_state.players:\n",
        "                new_state.players.remove(player)\n",
        "        elif action == Action.CHECK:\n",
        "            pass\n",
        "        elif action == Action.CALL:\n",
        "            call_amount = max(state.bets.values()) - state.bets.get(player, 0)\n",
        "            call_amount = max(0, call_amount)  # Ensure non-negative\n",
        "            new_state.bets[player] = new_state.bets.get(player, 0) + call_amount\n",
        "            new_state.total_bets[player] = new_state.total_bets.get(player, 0) + call_amount\n",
        "            new_state.pot_size += call_amount\n",
        "        elif action in [Action.BET, Action.RAISE]:\n",
        "            amount = max(amount, 1)  # Minimum bet size\n",
        "            new_state.bets[player] = new_state.bets.get(player, 0) + amount\n",
        "            new_state.total_bets[player] = new_state.total_bets.get(player, 0) + amount\n",
        "            new_state.pot_size += amount\n",
        "\n",
        "        # Add to action history\n",
        "        new_state.action_history.append((player, action, amount))\n",
        "\n",
        "        # Switch players\n",
        "        if not new_state.is_terminal and len(new_state.players) > 1:\n",
        "            new_state.current_player = 1 - player\n",
        "\n",
        "        return new_state\n",
        "\n",
        "    def _should_advance_street(self, state: GameState) -> bool:\n",
        "        \"\"\"Check if betting round is complete.\"\"\"\n",
        "        if len(state.action_history) < 2:\n",
        "            return False\n",
        "\n",
        "        if len(state.players) < 2:\n",
        "            return False\n",
        "\n",
        "        # Check if all active players have equal bets\n",
        "        active_bets = [state.bets.get(p, 0) for p in state.players]\n",
        "        if len(set(active_bets)) > 1:\n",
        "            return False\n",
        "\n",
        "        # Check for completion patterns\n",
        "        recent = state.action_history[-2:]\n",
        "        actions = [act for _, act, _ in recent]\n",
        "\n",
        "        return Action.CHECK in actions or Action.CALL in actions\n",
        "\n",
        "    def _advance_to_next_street(self, state: GameState, deck: List[str]) -> GameState:\n",
        "        \"\"\"Advance to the next betting round.\"\"\"\n",
        "\n",
        "        street_progression = {\n",
        "            'preflop': ('flop', 3),\n",
        "            'flop': ('turn', 4),\n",
        "            'turn': ('river', 5),\n",
        "            'river': ('showdown', 5)\n",
        "        }\n",
        "\n",
        "        if state.street in street_progression:\n",
        "            next_street, board_size = street_progression[state.street]\n",
        "\n",
        "            if next_street == 'showdown':\n",
        "                state.is_terminal = True\n",
        "            else:\n",
        "                # Deal community cards\n",
        "                used_cards = set()\n",
        "                for hand in state.hands.values():\n",
        "                    used_cards.update(hand)\n",
        "                used_cards.update(state.board)\n",
        "\n",
        "                available = [c for c in deck if c not in used_cards]\n",
        "                cards_needed = board_size - len(state.board)\n",
        "                if len(available) >= cards_needed:\n",
        "                    state.board.extend(available[:cards_needed])\n",
        "                else:\n",
        "                    # Not enough cards, force terminal\n",
        "                    state.is_terminal = True\n",
        "                    return state\n",
        "\n",
        "                state.street = next_street\n",
        "                state.bets = {p: 0 for p in state.players}\n",
        "                if state.players:\n",
        "                    state.current_player = min(state.players)  # Reset to first active player\n",
        "\n",
        "        return state\n",
        "\n",
        "    def _calculate_showdown(self, state: GameState) -> Dict[int, float]:\n",
        "        \"\"\"Calculate final payoffs.\"\"\"\n",
        "\n",
        "        if len(state.players) == 1:\n",
        "            # Someone folded\n",
        "            winner = state.players[0]\n",
        "            loser = 1 - winner\n",
        "            return {\n",
        "                winner: state.pot_size - state.total_bets.get(winner, 0),\n",
        "                loser: -state.total_bets.get(loser, 0)\n",
        "            }\n",
        "\n",
        "        # Showdown with hand evaluation\n",
        "        if len(state.board) == 5:\n",
        "            try:\n",
        "                p0_hand = state.hands[0] + state.board\n",
        "                p1_hand = state.hands[1] + state.board\n",
        "\n",
        "                p0_rank = evaluate_cards(*p0_hand)\n",
        "                p1_rank = evaluate_cards(*p1_hand)\n",
        "\n",
        "                if p0_rank < p1_rank:  # Lower rank wins\n",
        "                    winner, loser = 0, 1\n",
        "                elif p1_rank < p0_rank:\n",
        "                    winner, loser = 1, 0\n",
        "                else:\n",
        "                    # Tie - split pot\n",
        "                    pot_share = state.pot_size / 2\n",
        "                    return {\n",
        "                        0: pot_share - state.total_bets.get(0, 0),\n",
        "                        1: pot_share - state.total_bets.get(1, 0)\n",
        "                    }\n",
        "\n",
        "                return {\n",
        "                    winner: state.pot_size - state.total_bets.get(winner, 0),\n",
        "                    loser: -state.total_bets.get(loser, 0)\n",
        "                }\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Hand evaluation error: {e}\")\n",
        "                # Fallback to random\n",
        "                winner = random.choice([0, 1])\n",
        "                loser = 1 - winner\n",
        "                return {\n",
        "                    winner: state.pot_size - state.total_bets.get(winner, 0),\n",
        "                    loser: -state.total_bets.get(loser, 0)\n",
        "                }\n",
        "\n",
        "        # Early street showdown or error\n",
        "        return {\n",
        "            0: -state.total_bets.get(0, 0),\n",
        "            1: -state.total_bets.get(1, 0)\n",
        "        }\n",
        "\n",
        "# Simplified strategy classes for testing\n",
        "class RandomStrategy:\n",
        "    \"\"\"Random baseline opponent.\"\"\"\n",
        "\n",
        "    def get_action(self, state: GameState, player_id: int) -> Tuple[Action, float]:\n",
        "        legal_actions = self._get_legal_actions(state, player_id)\n",
        "        if not legal_actions:\n",
        "            return (Action.FOLD, 0)\n",
        "        return random.choice(legal_actions)\n",
        "\n",
        "    def _get_legal_actions(self, state: GameState, player_id: int) -> List[Tuple[Action, float]]:\n",
        "        actions = []\n",
        "        to_call = max(state.bets.values()) - state.bets.get(player_id, 0)\n",
        "        to_call = max(0, to_call)  # Ensure non-negative\n",
        "\n",
        "        if to_call > 0:\n",
        "            actions.extend([(Action.FOLD, 0), (Action.CALL, to_call)])\n",
        "        else:\n",
        "            actions.append((Action.CHECK, 0))\n",
        "\n",
        "        # Simple bet sizing\n",
        "        bet_size = max(state.pot_size * 0.75, 10)\n",
        "        if to_call == 0:\n",
        "            actions.append((Action.BET, bet_size))\n",
        "        else:\n",
        "            actions.append((Action.RAISE, bet_size))\n",
        "\n",
        "        return actions\n",
        "\n",
        "class TightStrategy:\n",
        "    \"\"\"Tight/conservative opponent.\"\"\"\n",
        "\n",
        "    def get_action(self, state: GameState, player_id: int) -> Tuple[Action, float]:\n",
        "        hand = state.hands[player_id]\n",
        "\n",
        "        # Simple hand strength evaluation\n",
        "        hand_strength = self._evaluate_hand_strength(hand, state.board)\n",
        "\n",
        "        to_call = max(state.bets.values()) - state.bets.get(player_id, 0)\n",
        "        to_call = max(0, to_call)\n",
        "\n",
        "        # Tight strategy: only play strong hands\n",
        "        if hand_strength < 0.6:\n",
        "            if to_call > 0:\n",
        "                return (Action.FOLD, 0)\n",
        "            else:\n",
        "                return (Action.CHECK, 0)\n",
        "        elif hand_strength > 0.8:\n",
        "            # Strong hand: bet or raise\n",
        "            bet_size = state.pot_size * 0.6\n",
        "            if to_call == 0:\n",
        "                return (Action.BET, bet_size)\n",
        "            else:\n",
        "                return (Action.RAISE, bet_size)\n",
        "        else:\n",
        "            # Medium hand: call or check\n",
        "            if to_call > 0:\n",
        "                return (Action.CALL, to_call)\n",
        "            else:\n",
        "                return (Action.CHECK, 0)\n",
        "\n",
        "    def _evaluate_hand_strength(self, hand: List[str], board: List[str]) -> float:\n",
        "        \"\"\"Simple hand strength evaluation.\"\"\"\n",
        "        if not board:\n",
        "            # Preflop evaluation\n",
        "            ranks = [RANKS.index(card[0]) for card in hand]\n",
        "            if ranks[0] == ranks[1]:  # Pocket pair\n",
        "                return 0.7 + max(ranks) * 0.02\n",
        "            elif max(ranks) >= 10:  # High card\n",
        "                return 0.5 + max(ranks) * 0.01\n",
        "            else:\n",
        "                return 0.3\n",
        "        else:\n",
        "            # Postflop: use hand evaluator if available\n",
        "            try:\n",
        "                full_hand = hand + board\n",
        "                rank = evaluate_cards(*full_hand)\n",
        "                # Convert rank to strength (lower rank = better hand)\n",
        "                return max(0, 1.0 - rank / 7463)\n",
        "            except:\n",
        "                return 0.4  # Fallback\n",
        "\n",
        "class MockMCCFRBotStrategy:\n",
        "    \"\"\"Mock strategy for testing when no trained model is available.\"\"\"\n",
        "\n",
        "    def __init__(self, policy_file: str = None, abstraction_manager=None):\n",
        "        self.policy = {}\n",
        "        print(\"Mock MCCFR Bot Strategy initialized (no real training)\")\n",
        "\n",
        "    def get_action(self, state: GameState, player_id: int) -> Tuple[Action, float]:\n",
        "        \"\"\"Simple mock strategy that plays reasonably.\"\"\"\n",
        "        hand = state.hands[player_id]\n",
        "\n",
        "        # Basic hand evaluation\n",
        "        hand_strength = self._evaluate_hand_strength(hand, state.board)\n",
        "        to_call = max(state.bets.values()) - state.bets.get(player_id, 0)\n",
        "        to_call = max(0, to_call)\n",
        "\n",
        "        # Simple decision logic\n",
        "        if hand_strength > 0.7:\n",
        "            # Strong hand: bet/raise\n",
        "            bet_size = state.pot_size * 0.8\n",
        "            if to_call == 0:\n",
        "                return (Action.BET, bet_size)\n",
        "            else:\n",
        "                return (Action.RAISE, bet_size)\n",
        "        elif hand_strength > 0.4:\n",
        "            # Medium hand: call/check\n",
        "            if to_call > 0:\n",
        "                return (Action.CALL, to_call)\n",
        "            else:\n",
        "                return (Action.CHECK, 0)\n",
        "        else:\n",
        "            # Weak hand: fold or check\n",
        "            if to_call > 0:\n",
        "                return (Action.FOLD, 0)\n",
        "            else:\n",
        "                return (Action.CHECK, 0)\n",
        "\n",
        "    def _evaluate_hand_strength(self, hand: List[str], board: List[str]) -> float:\n",
        "        \"\"\"Simple hand strength evaluation.\"\"\"\n",
        "        if not board:\n",
        "            # Preflop\n",
        "            ranks = [RANKS.index(card[0]) for card in hand]\n",
        "            return 0.3 + max(ranks) * 0.05\n",
        "        else:\n",
        "            # Postflop\n",
        "            try:\n",
        "                full_hand = hand + board\n",
        "                rank = evaluate_cards(*full_hand)\n",
        "                return max(0, 1.0 - rank / 7463)\n",
        "            except:\n",
        "                return random.uniform(0.2, 0.6)\n",
        "\n",
        "class PokerBotEvaluator:\n",
        "    \"\"\"Main evaluation system for poker bots.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.game_engine = PokerGameEngine()\n",
        "        self.results_history = []\n",
        "\n",
        "    def evaluate_bot(self, bot_strategy, opponent_type: OpponentType,\n",
        "                    num_games: int = 1000, verbose: bool = True) -> EvaluationResults:\n",
        "        \"\"\"Evaluate bot against specified opponent type.\"\"\"\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"\\n=== Evaluating Bot vs {opponent_type.value.upper()} ===\")\n",
        "            print(f\"Playing {num_games} games...\")\n",
        "\n",
        "        # Create opponent strategy\n",
        "        if opponent_type == OpponentType.RANDOM:\n",
        "            opponent = RandomStrategy()\n",
        "        elif opponent_type == OpponentType.TIGHT:\n",
        "            opponent = TightStrategy()\n",
        "        # --- ADD THIS NEW OPTION ---\n",
        "        elif opponent_type == OpponentType.STUMBOT: # Note: STUMBOT is a typo in your class, should be SLUMBOT\n",
        "            opponent = SlumbotStrategy()\n",
        "        else:\n",
        "            opponent = RandomStrategy() # Default fallback\n",
        "\n",
        "        # Run games\n",
        "        game_results = []\n",
        "        profits = []\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        for i in range(num_games):\n",
        "            if verbose and (i + 1) % 100 == 0:\n",
        "                elapsed = time.time() - start_time\n",
        "                print(f\"  Game {i+1}/{num_games} | {elapsed:.1f}s\")\n",
        "\n",
        "            try:\n",
        "                # Alternate who plays first\n",
        "                if i % 2 == 0:\n",
        "                    result = self.game_engine.play_game(bot_strategy, opponent, max_hands=50)\n",
        "                    bot_profit = result.final_stacks[0] - 20000  # Initial stack was 20000\n",
        "                else:\n",
        "                    result = self.game_engine.play_game(opponent, bot_strategy, max_hands=50)\n",
        "                    bot_profit = result.final_stacks[1] - 20000\n",
        "\n",
        "                game_results.append(result)\n",
        "                profits.append(bot_profit)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error in game {i+1}: {e}\")\n",
        "                # Add neutral result to continue\n",
        "                profits.append(0)\n",
        "                continue\n",
        "\n",
        "        # Calculate statistics\n",
        "        if not profits:\n",
        "            print(\"No valid games completed!\")\n",
        "            return EvaluationResults(0, 0, 0, 0, opponent_type.value, (0, 0), [])\n",
        "\n",
        "        win_rate = sum(1 for p in profits if p > 0) / len(profits)\n",
        "        avg_profit = np.mean(profits)\n",
        "        total_profit = sum(profits)\n",
        "\n",
        "        # Calculate confidence interval (95%)\n",
        "        std_error = np.std(profits) / np.sqrt(len(profits))\n",
        "        ci_lower = avg_profit - 1.96 * std_error\n",
        "        ci_upper = avg_profit + 1.96 * std_error\n",
        "\n",
        "        evaluation_results = EvaluationResults(\n",
        "            win_rate=win_rate,\n",
        "            avg_profit=avg_profit,\n",
        "            total_profit=total_profit,\n",
        "            hands_played=sum(r.hands_played for r in game_results),\n",
        "            opponent_type=opponent_type.value,\n",
        "            confidence_interval=(ci_lower, ci_upper),\n",
        "            game_results=game_results\n",
        "        )\n",
        "\n",
        "        if verbose:\n",
        "            self._print_results(evaluation_results)\n",
        "\n",
        "        self.results_history.append(evaluation_results)\n",
        "        return evaluation_results\n",
        "\n",
        "    def _print_results(self, results: EvaluationResults):\n",
        "        \"\"\"Print formatted evaluation results.\"\"\"\n",
        "        print(f\"\\n--- Results vs {results.opponent_type.upper()} ---\")\n",
        "        print(f\"Win Rate: {results.win_rate:.1%}\")\n",
        "        print(f\"Average Profit: {results.avg_profit:+.2f} chips\")\n",
        "        print(f\"Total Profit: {results.total_profit:+.2f} chips\")\n",
        "        print(f\"Hands Played: {results.hands_played}\")\n",
        "        print(f\"95% CI: [{results.confidence_interval[0]:+.2f}, {results.confidence_interval[1]:+.2f}]\")\n",
        "\n",
        "        if results.avg_profit > 0:\n",
        "            print(\"✅ PROFITABLE against this opponent\")\n",
        "        else:\n",
        "            print(\"❌ LOSING against this opponent\")\n",
        "\n",
        "    def run_full_evaluation(self, bot_strategy, num_games_per_opponent: int = 1000):\n",
        "        \"\"\"Run complete evaluation against multiple opponent types.\"\"\"\n",
        "        print(\"\\n🎯 === FULL POKER BOT EVALUATION ===\")\n",
        "\n",
        "        opponents = [OpponentType.RANDOM, OpponentType.TIGHT]\n",
        "\n",
        "        for opponent_type in opponents:\n",
        "            self.evaluate_bot(bot_strategy, opponent_type, num_games_per_opponent)\n",
        "\n",
        "        self._print_summary()\n",
        "\n",
        "    def _print_summary(self):\n",
        "        \"\"\"Print summary of all evaluations.\"\"\"\n",
        "        print(f\"\\n📊 === EVALUATION SUMMARY ===\")\n",
        "\n",
        "        if not self.results_history:\n",
        "            print(\"No evaluation results available.\")\n",
        "            return\n",
        "\n",
        "        total_profit = sum(r.total_profit for r in self.results_history)\n",
        "        total_games = sum(len(r.game_results) for r in self.results_history)\n",
        "\n",
        "        print(f\"Overall Performance:\")\n",
        "        print(f\"  Total Profit: {total_profit:+.2f} chips\")\n",
        "        print(f\"  Games Played: {total_games}\")\n",
        "        if total_games > 0:\n",
        "            print(f\"  Average per Game: {total_profit/total_games:+.2f} chips\")\n",
        "\n",
        "        for result in self.results_history:\n",
        "            print(f\"  vs {result.opponent_type}: {result.win_rate:.1%} win rate, {result.avg_profit:+.2f} avg profit\")\n",
        "\n",
        "# USAGE EXAMPLE\n",
        "if __name__ == \"__main__\":\n",
        "    POLICY_FILE = \"optimized_cfr_policy.pkl\"\n",
        "    print(\"🃏 === POKER BOT EVALUATION SYSTEM ===\")\n",
        "\n",
        "    try:\n",
        "        # Create a mock bot strategy since models aren't trained yet\n",
        "        print(\"Creating mock bot strategy for testing...\")\n",
        "        #bot_strategy = MockMCCFRBotStrategy()\n",
        "\n",
        "        # Create evaluator\n",
        "        evaluator = PokerBotEvaluator()\n",
        "\n",
        "        # Run evaluation with fewer games for initial testing\n",
        "        print(\"Running evaluation with mock strategy...\")\n",
        "        mock_bot = MockMCCFRBotStrategy()\n",
        "        evaluator.evaluate_bot(mock_bot, OpponentType.TIGHT, num_games=100)\n",
        "\n",
        "        print(\"✅ Evaluation system is ready for real models.\")\n",
        "\n",
        "        print(\"✅ Evaluation system test complete!\")\n",
        "        print(\"\\nTo use with real trained models:\")\n",
        "        print(\"1. Train your abstraction manager and MCCFR policy\")\n",
        "        print(\"2. Replace MockMCCFRBotStrategy with your real MCCFRBotStrategy\")\n",
        "        print(\"3. Update file paths to your trained models\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "import itertools\n",
        "import random\n",
        "import time\n",
        "import pickle\n",
        "from typing import List, Dict, Tuple, Set\n",
        "from collections import defaultdict\n",
        "from enum import Enum\n",
        "from dataclasses import dataclass, field\n",
        "from copy import deepcopy\n",
        "\n",
        "# Card and game constants\n",
        "SUITS = ['h', 'd', 'c', 's']  # Hearts, Diamonds, Clubs, Spades\n",
        "RANKS = ['2', '3', '4', '5', '6', '7', '8', '9', 'T', 'J', 'Q', 'K', 'A']\n",
        "\n",
        "# Create a standard deck\n",
        "DECK = [f\"{rank}{suit}\" for rank in RANKS for suit in SUITS]\n",
        "\n",
        "class Action(Enum):\n",
        "    \"\"\"Poker actions available to players.\"\"\"\n",
        "    FOLD = \"fold\"\n",
        "    CHECK = \"check\"\n",
        "    CALL = \"call\"\n",
        "    BET = \"bet\"\n",
        "    RAISE = \"raise\"\n",
        "\n",
        "@dataclass\n",
        "class GameState:\n",
        "    \"\"\"\n",
        "    Represents the complete state of a poker game.\n",
        "    \"\"\"\n",
        "    players: List[int]\n",
        "    current_player: int\n",
        "    pot_size: float\n",
        "    street: str  # 'preflop', 'flop', 'turn', 'river'\n",
        "    board: List[str]  # Community cards\n",
        "    hands: Dict[int, List[str]]  # Player hole cards\n",
        "    bets: Dict[int, float]  # Current round bets\n",
        "    total_bets: Dict[int, float]  # Total bets across all rounds\n",
        "    action_history: List[Tuple[int, Action, float]] = field(default_factory=list)\n",
        "    is_terminal: bool = False\n",
        "\n",
        "    def copy(self) -> 'GameState':\n",
        "        \"\"\"Create a deep copy of the game state.\"\"\"\n",
        "        return GameState(\n",
        "            players=self.players.copy(),\n",
        "            current_player=self.current_player,\n",
        "            pot_size=self.pot_size,\n",
        "            street=self.street,\n",
        "            board=self.board.copy(),\n",
        "            hands={k: v.copy() for k, v in self.hands.items()},\n",
        "            bets=self.bets.copy(),\n",
        "            total_bets=self.total_bets.copy(),\n",
        "            action_history=self.action_history.copy(),\n",
        "            is_terminal=self.is_terminal\n",
        "        )\n",
        "\n",
        "class Card:\n",
        "    \"\"\"\n",
        "    Represents a single playing card with rank and suit.\n",
        "    \"\"\"\n",
        "    __slots__ = ('rank', 'suit')\n",
        "\n",
        "    def __init__(self, rank: str, suit: str) -> None:\n",
        "        if rank not in RANKS:\n",
        "            raise ValueError(f\"Invalid rank: {rank}. Must be one of {RANKS}\")\n",
        "        if suit not in SUITS:\n",
        "            raise ValueError(f\"Invalid suit: {suit}. Must be one of {SUITS}\")\n",
        "        self.rank = rank\n",
        "        self.suit = suit\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return f\"{self.rank}{self.suit}\"\n",
        "\n",
        "    def __eq__(self, other: object) -> bool:\n",
        "        if not isinstance(other, Card):\n",
        "            return NotImplemented\n",
        "        return self.rank == other.rank and self.suit == other.suit\n",
        "\n",
        "    def __hash__(self) -> int:\n",
        "        return hash((self.rank, self.suit))\n",
        "\n",
        "    def get_numeric_rank(self) -> int:\n",
        "        \"\"\"Returns the numeric rank of the card (2-14, where Ace is 14).\"\"\"\n",
        "        return RANKS.index(self.rank) + 2\n",
        "\n",
        "def create_deck() -> List[Card]:\n",
        "    \"\"\"Creates a standard 52-card deck.\"\"\"\n",
        "    return [Card(rank, suit) for rank in RANKS for suit in SUITS]\n",
        "\n",
        "def get_hand_bucket(hand: List[Card]) -> str:\n",
        "    \"\"\"\n",
        "    Determines the preflop bucket for a given two-card hand.\n",
        "    \"\"\"\n",
        "    if len(hand) != 2:\n",
        "        raise ValueError(\"Hand must consist of exactly two cards.\")\n",
        "\n",
        "    # Sort cards by rank (higher rank first)\n",
        "    sorted_hand = sorted(hand, key=lambda card: RANKS.index(card.rank), reverse=True)\n",
        "    card1, card2 = sorted_hand\n",
        "\n",
        "    if card1.rank == card2.rank:\n",
        "        return f\"{card1.rank}{card2.rank}\"  # Pocket pair\n",
        "    elif card1.suit == card2.suit:\n",
        "        return f\"{card1.rank}{card2.rank}s\"  # Suited\n",
        "    else:\n",
        "        return f\"{card1.rank}{card2.rank}o\"  # Offsuit\n",
        "\n",
        "# Simple hand evaluator (placeholder - you can integrate your actual evaluator)\n",
        "def evaluate_hand_strength(hand: List[str], board: List[str]) -> float:\n",
        "    \"\"\"\n",
        "    Simple hand strength evaluator. Replace with your actual hand evaluator.\n",
        "    Returns a value between 0 and 1 where higher is better.\n",
        "    \"\"\"\n",
        "    all_cards = hand + board\n",
        "    if len(all_cards) < 5:\n",
        "        return 0.5  # Unknown strength\n",
        "\n",
        "    # Very simplified evaluation based on high cards\n",
        "    ranks_values = {'2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8,\n",
        "                   '9': 9, 'T': 10, 'J': 11, 'Q': 12, 'K': 13, 'A': 14}\n",
        "\n",
        "    card_ranks = [ranks_values[card[0]] for card in all_cards]\n",
        "    max_rank = max(card_ranks)\n",
        "    avg_rank = sum(card_ranks) / len(card_ranks)\n",
        "\n",
        "    # Simple strength calculation\n",
        "    strength = (max_rank + avg_rank) / 28.0  # Normalize roughly to 0-1\n",
        "    return min(1.0, max(0.0, strength))\n",
        "\n",
        "# Mock abstraction manager for testing\n",
        "class MockAbstractionManager:\n",
        "    \"\"\"Simple mock abstraction manager for testing.\"\"\"\n",
        "\n",
        "    def __init__(self, n_clusters_per_round=10):\n",
        "        self.n_clusters = n_clusters_per_round\n",
        "\n",
        "    def get_postflop_bucket(self, hand: List[str], board: List[str]) -> int:\n",
        "        \"\"\"Return a simple bucket based on hand strength.\"\"\"\n",
        "        strength = evaluate_hand_strength(hand, board)\n",
        "        return int(strength * (self.n_clusters - 1))\n",
        "\n",
        "    def train_all_postflop_models(self, n_samples_per_round=1000):\n",
        "        \"\"\"Mock training method.\"\"\"\n",
        "        print(f\"Mock abstraction manager trained with {n_samples_per_round} samples\")\n",
        "\n",
        "class OptimizedMCCFRTrainer:\n",
        "    \"\"\"Fixed version of MCCFR trainer with performance optimizations.\"\"\"\n",
        "\n",
        "    def __init__(self, abstraction_manager=None, initial_stack=1000.0):\n",
        "        print(\"Initializing Optimized MCCFR Trainer...\")\n",
        "\n",
        "        if abstraction_manager is None:\n",
        "            self.abstraction_manager = MockAbstractionManager(n_clusters_per_round=20)\n",
        "            self.abstraction_manager.train_all_postflop_models(n_samples_per_round=1000)\n",
        "        else:\n",
        "            self.abstraction_manager = abstraction_manager\n",
        "\n",
        "        self.initial_stack = initial_stack\n",
        "\n",
        "        # CFR data structures\n",
        "        self.regret_sum = defaultdict(lambda: defaultdict(float))\n",
        "        self.strategy_sum = defaultdict(lambda: defaultdict(float))\n",
        "        self.policy = defaultdict(lambda: defaultdict(float))\n",
        "\n",
        "        self.iteration_count = 0\n",
        "        self.strategy_updates = 0\n",
        "\n",
        "        # Recursion depth tracking\n",
        "        self.max_recursion_depth = 15\n",
        "        self.current_depth = 0\n",
        "\n",
        "        # Action sequence tracking to prevent infinite loops\n",
        "        self.action_sequence_cache = {}\n",
        "\n",
        "        self._initialize_preflop_buckets()\n",
        "\n",
        "        print(\"Optimized MCCFR Trainer initialized successfully.\")\n",
        "\n",
        "    def _initialize_preflop_buckets(self):\n",
        "        \"\"\"Simplified preflop bucketing for testing.\"\"\"\n",
        "        self.preflop_buckets = {}\n",
        "\n",
        "        # Simplified bucketing - just a few categories\n",
        "        premium_hands = ['AA', 'KK', 'QQ', 'AKs', 'AKo']\n",
        "        strong_hands = ['JJ', 'TT', 'AQs', 'AQo', 'AJs', 'AJo']\n",
        "        medium_hands = ['99', '88', 'KQs', 'KQo', 'KJs', 'KJo']\n",
        "\n",
        "        bucket_id = 60\n",
        "        for hand in premium_hands:\n",
        "            self.preflop_buckets[hand] = bucket_id\n",
        "        bucket_id += 1\n",
        "\n",
        "        for hand in strong_hands:\n",
        "            self.preflop_buckets[hand] = bucket_id\n",
        "        bucket_id += 1\n",
        "\n",
        "        for hand in medium_hands:\n",
        "            self.preflop_buckets[hand] = bucket_id\n",
        "\n",
        "    def get_preflop_bucket(self, hand: List[str]) -> int:\n",
        "        \"\"\"Simplified preflop bucketing.\"\"\"\n",
        "        if len(hand) != 2:\n",
        "            return 79  # Default bucket\n",
        "\n",
        "        ranks = sorted([card[0] for card in hand], key=lambda x: RANKS.index(x), reverse=True)\n",
        "        suits = [card[1] for card in hand]\n",
        "\n",
        "        if ranks[0] == ranks[1]:\n",
        "            hand_str = ranks[0] + ranks[0]\n",
        "        else:\n",
        "            suited = 's' if suits[0] == suits[1] else 'o'\n",
        "            hand_str = ''.join(ranks) + suited\n",
        "\n",
        "        return self.preflop_buckets.get(hand_str, 79)\n",
        "\n",
        "    def get_info_state(self, state: GameState, player_id: int) -> str:\n",
        "        \"\"\"Simplified information state to prevent explosion.\"\"\"\n",
        "        hand = state.hands[player_id]\n",
        "        board = state.board\n",
        "\n",
        "        # Get bucket ID\n",
        "        if state.street == 'preflop':\n",
        "            bucket_id = self.get_preflop_bucket(hand)\n",
        "        else:\n",
        "            bucket_id = self.abstraction_manager.get_postflop_bucket(hand, board)\n",
        "\n",
        "        # Only include essential info to prevent state explosion\n",
        "        recent_actions = state.action_history[-3:] if len(state.action_history) > 3 else state.action_history\n",
        "        action_str = ''.join([f\"{a.value[0]}\" for _, a, _ in recent_actions])\n",
        "\n",
        "        pot_ratio = min(9, int(state.pot_size / 10))  # Discretize pot size\n",
        "\n",
        "        info_state = f\"B{bucket_id}S{state.street[0]}A{action_str}P{pot_ratio}\"\n",
        "        return info_state\n",
        "\n",
        "    def get_legal_actions(self, state: GameState, player_id: int) -> List[Tuple[Action, float]]:\n",
        "        \"\"\"Simplified action space to prevent explosion.\"\"\"\n",
        "        actions = []\n",
        "        to_call = max(state.bets.values()) - state.bets.get(player_id, 0)\n",
        "        stack_size = self.initial_stack - state.total_bets.get(player_id, 0)\n",
        "\n",
        "        # Always allow fold if facing a bet\n",
        "        if to_call > 0:\n",
        "            actions.append((Action.FOLD, 0))\n",
        "\n",
        "        # Check/Call\n",
        "        if to_call == 0:\n",
        "            actions.append((Action.CHECK, 0))\n",
        "        else:\n",
        "            if to_call <= stack_size:\n",
        "                actions.append((Action.CALL, to_call))\n",
        "\n",
        "        # Simplified: Only 2 bet sizes instead of 5\n",
        "        pot_bet = state.pot_size\n",
        "        min_bet = max(to_call * 2, pot_bet * 0.5) if to_call > 0 else pot_bet * 0.5\n",
        "\n",
        "        if pot_bet <= stack_size and pot_bet >= min_bet:\n",
        "            if to_call == 0:\n",
        "                actions.append((Action.BET, pot_bet))\n",
        "            else:\n",
        "                actions.append((Action.RAISE, pot_bet))\n",
        "\n",
        "        # All-in as second option\n",
        "        if stack_size > pot_bet and stack_size >= min_bet:\n",
        "            if to_call == 0:\n",
        "                actions.append((Action.BET, stack_size))\n",
        "            else:\n",
        "                actions.append((Action.RAISE, stack_size))\n",
        "\n",
        "        return actions if actions else [(Action.FOLD, 0)]\n",
        "\n",
        "    def get_strategy(self, info_state: str, legal_actions: List[Tuple[Action, float]]) -> Dict[Tuple[Action, float], float]:\n",
        "        \"\"\"Consistent action tuple handling.\"\"\"\n",
        "        strategy = {}\n",
        "\n",
        "        # Calculate regret sum for normalization\n",
        "        regret_sum = 0.0\n",
        "        for action_tuple in legal_actions:\n",
        "            regret_value = self.regret_sum[info_state].get(action_tuple, 0.0)\n",
        "            regret_sum += max(0, regret_value)\n",
        "\n",
        "        # Generate strategy based on regret matching\n",
        "        if regret_sum > 0:\n",
        "            for action_tuple in legal_actions:\n",
        "                regret_value = self.regret_sum[info_state].get(action_tuple, 0.0)\n",
        "                strategy[action_tuple] = max(0, regret_value) / regret_sum\n",
        "        else:\n",
        "            # Uniform strategy if no positive regrets\n",
        "            uniform_prob = 1.0 / len(legal_actions)\n",
        "            for action_tuple in legal_actions:\n",
        "                strategy[action_tuple] = uniform_prob\n",
        "\n",
        "        return strategy\n",
        "\n",
        "    def train(self, num_iterations: int = 1000):\n",
        "        \"\"\"Better training loop with timeout protection.\"\"\"\n",
        "        print(f\"\\n=== Starting Optimized MCCFR Training for {num_iterations} iterations ===\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        for i in range(num_iterations):\n",
        "            self.iteration_count += 1\n",
        "\n",
        "            # Progress reporting\n",
        "            if (i + 1) % 100 == 0:\n",
        "                elapsed = time.time() - start_time\n",
        "                print(f\"Iteration {i+1}/{num_iterations} | \"\n",
        "                      f\"Time: {elapsed:.1f}s | \"\n",
        "                      f\"States: {len(self.regret_sum)}\")\n",
        "\n",
        "            try:\n",
        "                # Reset depth counter for each iteration\n",
        "                self.current_depth = 0\n",
        "                self._run_mccfr_iteration()\n",
        "\n",
        "                # Timeout protection\n",
        "                if time.time() - start_time > 300:  # 5 minute timeout\n",
        "                    print(f\"Training timeout after {i+1} iterations\")\n",
        "                    break\n",
        "\n",
        "            except RecursionError:\n",
        "                print(f\"Recursion limit hit at iteration {i+1}\")\n",
        "                continue\n",
        "            except Exception as e:\n",
        "                print(f\"Error in iteration {i+1}: {e}\")\n",
        "                continue\n",
        "\n",
        "            if i % 50 == 0:  # More frequent strategy updates\n",
        "                self._update_average_strategy()\n",
        "\n",
        "        total_time = time.time() - start_time\n",
        "        print(f\"Training complete! Total time: {total_time:.1f}s\")\n",
        "        print(f\"Final policy contains {len(self.policy)} information states\")\n",
        "\n",
        "    def _run_mccfr_iteration(self):\n",
        "        \"\"\"Simplified iteration with better initial state.\"\"\"\n",
        "        initial_state = self._create_simple_game_state()\n",
        "\n",
        "        # Run MCCFR for both players\n",
        "        for player_id in [0, 1]:\n",
        "            self.current_depth = 0  # Reset depth\n",
        "            try:\n",
        "                self._mccfr_recursive(initial_state, player_id, 1.0, 1.0)\n",
        "            except Exception as e:\n",
        "                # Gracefully handle errors and continue\n",
        "                continue\n",
        "\n",
        "    def _create_simple_game_state(self) -> GameState:\n",
        "        \"\"\"Simplified initial game state.\"\"\"\n",
        "        deck = DECK.copy()\n",
        "        random.shuffle(deck)\n",
        "\n",
        "        # Simple preflop state\n",
        "        hands = {0: deck[:2], 1: deck[2:4]}\n",
        "\n",
        "        state = GameState(\n",
        "            players=[0, 1],\n",
        "            current_player=0,\n",
        "            pot_size=3.0,\n",
        "            street='preflop',\n",
        "            board=[],\n",
        "            hands=hands,\n",
        "            bets={0: 1.0, 1: 2.0},  # Small blind, big blind\n",
        "            total_bets={0: 1.0, 1: 2.0},\n",
        "            action_history=[]\n",
        "        )\n",
        "\n",
        "        return state\n",
        "\n",
        "    def _mccfr_recursive(self, state: GameState, traversing_player: int,\n",
        "                         pi_player: float, pi_opponent: float) -> float:\n",
        "        \"\"\"Protected recursive function with depth limits.\"\"\"\n",
        "\n",
        "        # Depth protection\n",
        "        self.current_depth += 1\n",
        "        if self.current_depth > self.max_recursion_depth:\n",
        "            self.current_depth -= 1\n",
        "            return self._get_utility(state, traversing_player)\n",
        "\n",
        "        # Terminal state check\n",
        "        if state.is_terminal:\n",
        "            self.current_depth -= 1\n",
        "            return self._get_utility(state, traversing_player)\n",
        "\n",
        "        # Action sequence protection against infinite loops\n",
        "        if len(state.action_history) > 10:  # Reduced from 20\n",
        "            self.current_depth -= 1\n",
        "            return self._get_utility(state, traversing_player)\n",
        "\n",
        "        current_player = state.current_player\n",
        "        info_state = self.get_info_state(state, current_player)\n",
        "        legal_actions = self.get_legal_actions(state, current_player)\n",
        "\n",
        "        if not legal_actions:\n",
        "            self.current_depth -= 1\n",
        "            return self._get_utility(state, traversing_player)\n",
        "\n",
        "        strategy = self.get_strategy(info_state, legal_actions)\n",
        "\n",
        "        # Calculate utilities for each action\n",
        "        action_utilities = {}\n",
        "        for action_tuple in legal_actions:\n",
        "            try:\n",
        "                new_state = self._apply_action(state, action_tuple[0], action_tuple[1])\n",
        "\n",
        "                if current_player == traversing_player:\n",
        "                    action_utilities[action_tuple] = self._mccfr_recursive(\n",
        "                        new_state, traversing_player,\n",
        "                        pi_player * strategy[action_tuple], pi_opponent\n",
        "                    )\n",
        "                else:\n",
        "                    action_utilities[action_tuple] = self._mccfr_recursive(\n",
        "                        new_state, traversing_player, pi_player,\n",
        "                        pi_opponent * strategy[action_tuple]\n",
        "                    )\n",
        "            except Exception:\n",
        "                # Fallback utility if recursion fails\n",
        "                action_utilities[action_tuple] = 0.0\n",
        "\n",
        "        # Node utility calculation\n",
        "        node_utility = sum(strategy[action_tuple] * action_utilities[action_tuple]\n",
        "                          for action_tuple in legal_actions)\n",
        "\n",
        "        # Update regrets\n",
        "        if current_player == traversing_player:\n",
        "            for action_tuple in legal_actions:\n",
        "                regret = action_utilities[action_tuple] - node_utility\n",
        "                self.regret_sum[info_state][action_tuple] += pi_opponent * regret\n",
        "\n",
        "        self.current_depth -= 1\n",
        "        return node_utility\n",
        "\n",
        "    def _apply_action(self, state: GameState, action: Action, amount: float) -> GameState:\n",
        "        \"\"\"Simplified action application.\"\"\"\n",
        "        # Create a copy of the state\n",
        "        new_state = state.copy()\n",
        "\n",
        "        player_id = state.current_player\n",
        "\n",
        "        # Apply the action\n",
        "        if action == Action.FOLD:\n",
        "            new_state.is_terminal = True\n",
        "            if player_id in new_state.players:\n",
        "                new_state.players.remove(player_id)\n",
        "        elif action == Action.CHECK:\n",
        "            pass  # No bet change\n",
        "        elif action == Action.CALL:\n",
        "            call_amount = max(state.bets.values()) - state.bets.get(player_id, 0)\n",
        "            new_state.bets[player_id] += call_amount\n",
        "            new_state.total_bets[player_id] += call_amount\n",
        "            new_state.pot_size += call_amount\n",
        "        elif action in [Action.BET, Action.RAISE]:\n",
        "            new_state.bets[player_id] += amount\n",
        "            new_state.total_bets[player_id] += amount\n",
        "            new_state.pot_size += amount\n",
        "\n",
        "        # Add to history\n",
        "        new_state.action_history.append((player_id, action, amount))\n",
        "\n",
        "        # Simplified game advancement\n",
        "        if not new_state.is_terminal:\n",
        "            new_state.current_player = 1 - player_id\n",
        "\n",
        "            # Simple completion check\n",
        "            if len(new_state.action_history) >= 4:  # Both players acted twice\n",
        "                new_state = self._try_advance_street(new_state)\n",
        "            elif action in [Action.CHECK, Action.CALL] and len(new_state.action_history) >= 2:\n",
        "                # Check if both players checked or one called\n",
        "                last_two = new_state.action_history[-2:]\n",
        "                if all(act in [Action.CHECK, Action.CALL] for _, act, _ in last_two):\n",
        "                    new_state = self._try_advance_street(new_state)\n",
        "\n",
        "        return new_state\n",
        "\n",
        "    def _try_advance_street(self, state: GameState) -> GameState:\n",
        "        \"\"\"Simplified street advancement.\"\"\"\n",
        "        street_map = {\n",
        "            'preflop': ('flop', 3),\n",
        "            'flop': ('turn', 4),\n",
        "            'turn': ('river', 5),\n",
        "            'river': ('terminal', 5)\n",
        "        }\n",
        "\n",
        "        if state.street in street_map:\n",
        "            next_street, target_board_size = street_map[state.street]\n",
        "\n",
        "            if next_street == 'terminal':\n",
        "                state.is_terminal = True\n",
        "            else:\n",
        "                # Deal cards to reach target board size\n",
        "                cards_needed = target_board_size - len(state.board)\n",
        "                if cards_needed > 0:\n",
        "                    # Get available cards\n",
        "                    used_cards = set()\n",
        "                    for hand in state.hands.values():\n",
        "                        used_cards.update(hand)\n",
        "                    used_cards.update(state.board)\n",
        "\n",
        "                    available_cards = [c for c in DECK if c not in used_cards]\n",
        "                    random.shuffle(available_cards)\n",
        "\n",
        "                    # Deal new cards\n",
        "                    new_cards = available_cards[:cards_needed]\n",
        "                    state.board.extend(new_cards)\n",
        "\n",
        "                state.street = next_street\n",
        "                state.bets = {p: 0.0 for p in state.players}\n",
        "                state.current_player = 0\n",
        "\n",
        "        return state\n",
        "\n",
        "    def _get_utility(self, state: GameState, player_id: int) -> float:\n",
        "        \"\"\"Simplified utility calculation.\"\"\"\n",
        "        if player_id not in state.players:\n",
        "            return -state.total_bets.get(player_id, 0)\n",
        "\n",
        "        if len(state.players) == 1:\n",
        "            return state.pot_size - state.total_bets.get(player_id, 0)\n",
        "\n",
        "        # Simplified showdown using hand strength\n",
        "        if len(state.board) >= 3:  # Any postflop situation\n",
        "            try:\n",
        "                player_strength = evaluate_hand_strength(state.hands[player_id], state.board)\n",
        "\n",
        "                best_opponent_strength = 0\n",
        "                for opp_id in state.players:\n",
        "                    if opp_id != player_id:\n",
        "                        opp_strength = evaluate_hand_strength(state.hands[opp_id], state.board)\n",
        "                        best_opponent_strength = max(best_opponent_strength, opp_strength)\n",
        "\n",
        "                if player_strength > best_opponent_strength:\n",
        "                    return state.pot_size - state.total_bets.get(player_id, 0)\n",
        "                elif player_strength == best_opponent_strength:\n",
        "                    return (state.pot_size / len(state.players)) - state.total_bets.get(player_id, 0)\n",
        "                else:\n",
        "                    return -state.total_bets.get(player_id, 0)\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        # Fallback: random outcome weighted by pot investment\n",
        "        random_outcome = random.choice([1, -1])\n",
        "        return random_outcome * (state.pot_size / 2) - state.total_bets.get(player_id, 0)\n",
        "\n",
        "    def _update_average_strategy(self):\n",
        "        \"\"\"Proper handling of action tuples.\"\"\"\n",
        "        for info_state in self.regret_sum:\n",
        "            # The keys in regret_sum are (Action, amount) tuples\n",
        "            action_tuples = list(self.regret_sum[info_state].keys())\n",
        "\n",
        "            # Convert to the format expected by get_strategy\n",
        "            legal_actions = [(action, amount) for action, amount in action_tuples]\n",
        "\n",
        "            if legal_actions:\n",
        "                strategy = self.get_strategy(info_state, legal_actions)\n",
        "\n",
        "                for action_tuple in strategy:\n",
        "                    self.strategy_sum[info_state][action_tuple] += strategy[action_tuple]\n",
        "\n",
        "        self.strategy_updates += 1\n",
        "\n",
        "    def get_final_policy(self) -> Dict[str, Dict]:\n",
        "        \"\"\"Get the final averaged policy.\"\"\"\n",
        "        final_policy = {}\n",
        "\n",
        "        for info_state in self.strategy_sum:\n",
        "            total_sum = sum(self.strategy_sum[info_state].values())\n",
        "            if total_sum > 0:\n",
        "                final_policy[info_state] = {\n",
        "                    str(action): prob / total_sum\n",
        "                    for action, prob in self.strategy_sum[info_state].items()\n",
        "                }\n",
        "            else:\n",
        "                actions = list(self.strategy_sum[info_state].keys())\n",
        "                uniform_prob = 1.0 / len(actions) if actions else 1.0\n",
        "                final_policy[info_state] = {\n",
        "                    str(action): uniform_prob for action in actions\n",
        "                }\n",
        "\n",
        "        return final_policy\n",
        "\n",
        "    def save_policy(self, filepath: str):\n",
        "        \"\"\"Save the trained policy to disk.\"\"\"\n",
        "        policy_data = {\n",
        "            'final_policy': self.get_final_policy(),\n",
        "            'iteration_count': self.iteration_count,\n",
        "            'regret_states': len(self.regret_sum)\n",
        "        }\n",
        "\n",
        "        with open(filepath, 'wb') as f:\n",
        "            pickle.dump(policy_data, f)\n",
        "        print(f\"Policy saved to {filepath}\")\n",
        "\n",
        "# Test the complete system\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=== Testing Complete MCCFR System ===\")\n",
        "\n",
        "    try:\n",
        "        # Test with mock abstraction manager\n",
        "        print(\"Creating mock abstraction system...\")\n",
        "        manager = MockAbstractionManager(n_clusters_per_round=10)\n",
        "\n",
        "        # Test predictions\n",
        "        test_hands = [\n",
        "            (['As', 'Kh'], ['Qc', '7d', '2s']),\n",
        "            (['9h', '8c'], ['7d', '6s', '2h', 'Tc']),\n",
        "        ]\n",
        "\n",
        "        for hand, board in test_hands:\n",
        "            bucket = manager.get_postflop_bucket(hand, board)\n",
        "            print(f\"Hand {hand} + Board {board} -> Bucket {bucket}\")\n",
        "\n",
        "        print(\"Abstraction system working! Now testing MCCFR...\")\n",
        "\n",
        "        # Use the optimized trainer\n",
        "        trainer = OptimizedMCCFRTrainer(manager)\n",
        "        trainer.train(num_iterations=200)  # Start small\n",
        "\n",
        "        # Show results\n",
        "        final_policy = trainer.get_final_policy()\n",
        "        print(f\"\\nTraining Results:\")\n",
        "        print(f\"- Information states learned: {len(final_policy)}\")\n",
        "        print(f\"- Total iterations: {trainer.iteration_count}\")\n",
        "        print(f\"- Strategy updates: {trainer.strategy_updates}\")\n",
        "\n",
        "        if final_policy:\n",
        "            example_info_state = list(final_policy.keys())[0]\n",
        "            print(f\"\\nExample strategy for info state '{example_info_state}':\")\n",
        "            for action, prob in final_policy[example_info_state].items():\n",
        "                print(f\"  {action}: {prob:.3f}\")\n",
        "\n",
        "        trainer.save_policy(\"optimized_cfr_policy.pkl\")\n",
        "\n",
        "        print(\"SUCCESS: Complete system is working!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9r9iuPot-A_E",
        "outputId": "55866566-7b20-4546-f8e8-d392b475508f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Testing Complete MCCFR System ===\n",
            "Creating mock abstraction system...\n",
            "Hand ['As', 'Kh'] + Board ['Qc', '7d', '2s'] -> Bucket 7\n",
            "Hand ['9h', '8c'] + Board ['7d', '6s', '2h', 'Tc'] -> Bucket 5\n",
            "Abstraction system working! Now testing MCCFR...\n",
            "Initializing Optimized MCCFR Trainer...\n",
            "Optimized MCCFR Trainer initialized successfully.\n",
            "\n",
            "=== Starting Optimized MCCFR Training for 200 iterations ===\n",
            "Iteration 100/200 | Time: 2.8s | States: 697\n",
            "Iteration 200/200 | Time: 4.8s | States: 733\n",
            "Training complete! Total time: 4.8s\n",
            "Final policy contains 0 information states\n",
            "\n",
            "Training Results:\n",
            "- Information states learned: 698\n",
            "- Total iterations: 200\n",
            "- Strategy updates: 4\n",
            "\n",
            "Example strategy for info state 'B79SpAP0':\n",
            "  (<Action.FOLD: 'fold'>, 0): 0.986\n",
            "  (<Action.CALL: 'call'>, 1.0): 0.000\n",
            "  (<Action.RAISE: 'raise'>, 3.0): 0.014\n",
            "  (<Action.RAISE: 'raise'>, 999.0): 0.000\n",
            "Policy saved to optimized_cfr_policy.pkl\n",
            "SUCCESS: Complete system is working!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ga"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EinitMhi-RoA",
        "outputId": "02375b14-136a-443e-f998-7930da2aea3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Choose an option:\n",
            "1. Debug policy file\n",
            "2. Run full bot evaluation\n",
            "3. Quick test only\n",
            "Enter choice (1-3): 2\n",
            "🔍 Debugging policy file...\n",
            "Policy data type: <class 'dict'>\n",
            "Policy data keys: ['final_policy', 'iteration_count', 'regret_states']\n",
            "Final policy has 1120 info states\n",
            "\n",
            "Sample info state: B79SpAP0\n",
            "Sample strategy: {\"(<Action.FOLD: 'fold'>, 0)\": 0.05875968242716244, \"(<Action.CALL: 'call'>, 1.0)\": 0.01439961759067168, \"(<Action.RAISE: 'raise'>, 3.0)\": 0.40851586448811095, \"(<Action.RAISE: 'raise'>, 999.0)\": 0.5183248354940548}\n",
            "\n",
            "Policy looks good! Starting evaluation...\n",
            "🚀 === TESTING YOUR REAL TRAINED MCCFR BOT ===\n",
            "Loading abstraction manager...\n",
            "Optimized PotentialAwareCalculator initialized.\n",
            "Fixed AbstractionManager initialized.\n",
            "Loading your trained MCCFR bot...\n",
            "Loading REAL trained policy from: optimized_cfr_policy.pkl\n",
            "Policy loaded. Agent knows 1120 info states.\n",
            "\n",
            "🎯 === EVALUATION RESULTS ===\n",
            "\n",
            "🔍 Quick test vs Random (50 games)...\n",
            "\n",
            "=== Evaluating Bot vs RANDOM ===\n",
            "Playing 50 games...\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for river\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for turn\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "Error in get_postflop_bucket: No trained model for flop\n",
            "\n",
            "--- Results vs RANDOM ---\n",
            "Win Rate: 0.0%\n",
            "Average Profit: -5811.00 chips\n",
            "Total Profit: -290550.00 chips\n",
            "Hands Played: 2500\n",
            "95% CI: [-5979.23, -5642.77]\n",
            "❌ LOSING against this opponent\n",
            "⚠️ Bot seems to be losing to random opponent. Check your policy loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9eHXJrPDSDi"
      },
      "source": [
        "#END\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ncb3CXlFkQ1o",
        "outputId": "8048df62-af6b-4c60-96b9-96526755373b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "phevaluator not available, using mock functions\n",
            "=== DEBUGGING CALCULATOR ISSUES ===\n",
            "DebugPotentialAwareCalculator initialized.\n",
            "DebugAbstractionManager initialized\n",
            "\n",
            "==================================================\n",
            "TESTING CALCULATOR\n",
            "==================================================\n",
            "\n",
            "Test 1: Hand ['As', 'Kh'], Board ['Qc', '7d', '2s']\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['As', 'Kh']\n",
            "Board: ['Qc', '7d', '2s']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 46/100 = 0.460\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.46, 0.0, 0.2758369088220143]\n",
            "Final feature vector: [0.46, 0.0, 0.2758369088220143]\n",
            "SUCCESS: [0.46, 0.0, 0.2758369088220143]\n",
            "\n",
            "Test 2: Hand ['9h', '8c'], Board ['7d', '6s', '2h', 'Tc']\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['9h', '8c']\n",
            "Board: ['7d', '6s', '2h', 'Tc']\n",
            "Input validation passed\n",
            "Remaining deck size: 46\n",
            "Calculating equity...\n",
            "Equity calculation: 40/100 = 0.400\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.4, 0.0, 0.2353888402563104]\n",
            "Final feature vector: [0.4, 0.0, 0.2353888402563104]\n",
            "SUCCESS: [0.4, 0.0, 0.2353888402563104]\n",
            "\n",
            "Test 3: Hand ['Ah', '2h'], Board ['3h', '4h', '5c', 'Kd', '9s']\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['Ah', '2h']\n",
            "Board: ['3h', '4h', '5c', 'Kd', '9s']\n",
            "Input validation passed\n",
            "Remaining deck size: 45\n",
            "Calculating equity...\n",
            "Equity calculation: 47/100 = 0.470\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.47, 0.0, 0.19217655297607952]\n",
            "Final feature vector: [0.47, 0.0, 0.19217655297607952]\n",
            "SUCCESS: [0.47, 0.0, 0.19217655297607952]\n",
            "\n",
            "Test 4: Hand ['AA', 'KK'], Board ['QQ', '77', '22']\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['AA', 'KK']\n",
            "Board: ['QQ', '77', '22']\n",
            "ERROR: Invalid card: AA\n",
            "FAILED: Empty or invalid result\n",
            "\n",
            "Test 5: Hand ['As', 'As'], Board ['Qc', '7d', '2s']\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['As', 'As']\n",
            "Board: ['Qc', '7d', '2s']\n",
            "ERROR: Duplicate cards found: ['As', 'As', 'Qc', '7d', '2s']\n",
            "FAILED: Empty or invalid result\n",
            "\n",
            "Test 6: Hand ['As'], Board ['Qc', '7d', '2s']\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['As']\n",
            "Board: ['Qc', '7d', '2s']\n",
            "ERROR: Invalid hand format: ['As']\n",
            "FAILED: Empty or invalid result\n",
            "\n",
            "Test 7: Hand ['As', 'Kh'], Board ['Qc', '7d']\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['As', 'Kh']\n",
            "Board: ['Qc', '7d']\n",
            "ERROR: Invalid board format: ['Qc', '7d']\n",
            "FAILED: Empty or invalid result\n",
            "\n",
            "SUMMARY: 3/7 tests passed\n",
            "\n",
            "✅ Calculator is working for some cases\n",
            "The issue might be in the data generation loop\n",
            "\n",
            "==================================================\n",
            "TESTING DATA GENERATION LOOP\n",
            "==================================================\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['Kh', '8c']\n",
            "Board: ['8h', '2d', '3c']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 50/100 = 0.500\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.5, 0.0, 0.0038762893729131108]\n",
            "Final feature vector: [0.5, 0.0, 0.0038762893729131108]\n",
            "Valid vector 1: [0.5, 0.0, 0.0038762893729131108]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['6d', '3h']\n",
            "Board: ['6s', 'Ad', '2s']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 53/100 = 0.530\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.53, 0.0, 0.2557110244602546]\n",
            "Final feature vector: [0.53, 0.0, 0.2557110244602546]\n",
            "Valid vector 2: [0.53, 0.0, 0.2557110244602546]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['3c', 'Ts']\n",
            "Board: ['7h', '7c', '4c']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 47/100 = 0.470\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.47, 0.0, 0.0670608929004253]\n",
            "Final feature vector: [0.47, 0.0, 0.0670608929004253]\n",
            "Valid vector 3: [0.47, 0.0, 0.0670608929004253]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['9c', 'Qc']\n",
            "Board: ['6c', 'Kd', '4h']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 50/100 = 0.500\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.5, 0.0, 0.16183574633939352]\n",
            "Final feature vector: [0.5, 0.0, 0.16183574633939352]\n",
            "Valid vector 4: [0.5, 0.0, 0.16183574633939352]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['2s', '6h']\n",
            "Board: ['Ad', 'Kd', '6c']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 45/100 = 0.450\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.45, 0.0, 0.2563579298855887]\n",
            "Final feature vector: [0.45, 0.0, 0.2563579298855887]\n",
            "Valid vector 5: [0.45, 0.0, 0.2563579298855887]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['8d', '2c']\n",
            "Board: ['Js', '4s', '9s']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 60/100 = 0.600\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.6, 0.0, 0.014164191224097022]\n",
            "Final feature vector: [0.6, 0.0, 0.014164191224097022]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['Kh', 'Qc']\n",
            "Board: ['As', '8d', '6d']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 53/100 = 0.530\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.53, 0.0, 0.1873888991479663]\n",
            "Final feature vector: [0.53, 0.0, 0.1873888991479663]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['Qs', '7s']\n",
            "Board: ['2c', 'Kh', '7h']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 41/100 = 0.410\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.41, 0.0, 0.08414458556273538]\n",
            "Final feature vector: [0.41, 0.0, 0.08414458556273538]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['5c', '2s']\n",
            "Board: ['5s', '6h', '9c']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 51/100 = 0.510\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.51, 0.0, 0.0032409266845811802]\n",
            "Final feature vector: [0.51, 0.0, 0.0032409266845811802]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['6h', 'Jh']\n",
            "Board: ['Ks', '5s', '8h']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 51/100 = 0.510\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.51, 0.0, 0.015438080035834112]\n",
            "Final feature vector: [0.51, 0.0, 0.015438080035834112]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['8d', 'Ah']\n",
            "Board: ['9d', '8c', '2c']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 58/100 = 0.580\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.58, 0.0, 0.09523302509907397]\n",
            "Final feature vector: [0.58, 0.0, 0.09523302509907397]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['4d', '8c']\n",
            "Board: ['9h', '8s', '9s']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 44/100 = 0.440\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.44, 0.0, 0.04357480770990835]\n",
            "Final feature vector: [0.44, 0.0, 0.04357480770990835]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['8c', '9h']\n",
            "Board: ['Js', 'Qc', '5d']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 49/100 = 0.490\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.49, 0.0, 0.28236629276849584]\n",
            "Final feature vector: [0.49, 0.0, 0.28236629276849584]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['8d', '3d']\n",
            "Board: ['Th', 'Qc', '2s']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 52/100 = 0.520\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.52, 0.0, 0.268892855234838]\n",
            "Final feature vector: [0.52, 0.0, 0.268892855234838]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['Qc', 'Kd']\n",
            "Board: ['3c', 'Ks', '6s']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 47/100 = 0.470\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.47, 0.0, 0.12785629639284918]\n",
            "Final feature vector: [0.47, 0.0, 0.12785629639284918]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['Jh', 'Jd']\n",
            "Board: ['Js', 'Qc', '6d']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 37/100 = 0.370\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.37, 0.0, 0.1671717040564986]\n",
            "Final feature vector: [0.37, 0.0, 0.1671717040564986]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['6h', '5h']\n",
            "Board: ['Qc', 'Ac', 'Jd']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 55/100 = 0.550\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.55, 0.0, 0.06844678901002504]\n",
            "Final feature vector: [0.55, 0.0, 0.06844678901002504]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['Js', 'Ad']\n",
            "Board: ['8d', '6h', '3h']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 49/100 = 0.490\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.49, 0.0, 0.2473697642730401]\n",
            "Final feature vector: [0.49, 0.0, 0.2473697642730401]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['4d', 'Qh']\n",
            "Board: ['6d', 'Tc', '4h']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 46/100 = 0.460\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.46, 0.0, 0.21773790837897605]\n",
            "Final feature vector: [0.46, 0.0, 0.21773790837897605]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['Ah', '7s']\n",
            "Board: ['7d', 'Th', 'Ts']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 59/100 = 0.590\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.59, 0.0, 0.24239046660679708]\n",
            "Final feature vector: [0.59, 0.0, 0.24239046660679708]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['5h', 'As']\n",
            "Board: ['Ah', '2d', '4s']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 59/100 = 0.590\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.59, 0.0, 0.01558221753735316]\n",
            "Final feature vector: [0.59, 0.0, 0.01558221753735316]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['3s', '8s']\n",
            "Board: ['5d', 'Ac', 'Kh']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 46/100 = 0.460\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.46, 0.0, 0.236284406796775]\n",
            "Final feature vector: [0.46, 0.0, 0.236284406796775]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['Ts', '7s']\n",
            "Board: ['Td', '8c', 'Ks']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 55/100 = 0.550\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.55, 0.0, 0.26360329119139725]\n",
            "Final feature vector: [0.55, 0.0, 0.26360329119139725]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['3h', '6c']\n",
            "Board: ['5s', 'Qs', 'Js']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 53/100 = 0.530\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.53, 0.0, 0.19728052218513908]\n",
            "Final feature vector: [0.53, 0.0, 0.19728052218513908]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['4s', '5h']\n",
            "Board: ['Tc', '8h', 'Ad']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 50/100 = 0.500\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.5, 0.0, 0.2816145446250438]\n",
            "Final feature vector: [0.5, 0.0, 0.2816145446250438]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['7h', '6d']\n",
            "Board: ['9c', '8s', 'Qs']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 43/100 = 0.430\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.43, 0.0, 0.0038235273602478356]\n",
            "Final feature vector: [0.43, 0.0, 0.0038235273602478356]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['Th', '3d']\n",
            "Board: ['Kh', '8c', 'Kd']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 57/100 = 0.570\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.57, 0.0, 0.16569825255801368]\n",
            "Final feature vector: [0.57, 0.0, 0.16569825255801368]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['5d', '7d']\n",
            "Board: ['2s', '9d', '3c']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 48/100 = 0.480\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.48, 0.0, 0.2270350150237172]\n",
            "Final feature vector: [0.48, 0.0, 0.2270350150237172]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['Jd', '5h']\n",
            "Board: ['7c', 'Jh', 'Ah']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 42/100 = 0.420\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.42, 0.0, 0.13292033129797884]\n",
            "Final feature vector: [0.42, 0.0, 0.13292033129797884]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['3h', '5c']\n",
            "Board: ['3d', '4h', '6s']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 47/100 = 0.470\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.47, 0.0, 0.2513542624707516]\n",
            "Final feature vector: [0.47, 0.0, 0.2513542624707516]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['Ah', '5c']\n",
            "Board: ['2s', 'Qs', '2h']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 38/100 = 0.380\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.38, 0.0, 0.09592723763657789]\n",
            "Final feature vector: [0.38, 0.0, 0.09592723763657789]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['5c', 'Qd']\n",
            "Board: ['Js', '6c', 'As']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 56/100 = 0.560\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.56, 0.0, 0.024235962090778006]\n",
            "Final feature vector: [0.56, 0.0, 0.024235962090778006]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['2s', 'Jh']\n",
            "Board: ['Th', 'Qd', '9d']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 52/100 = 0.520\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.52, 0.0, 0.15271196916633797]\n",
            "Final feature vector: [0.52, 0.0, 0.15271196916633797]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['Qd', 'Qc']\n",
            "Board: ['9c', '7s', 'Th']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 56/100 = 0.560\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.56, 0.0, 0.17278187227972766]\n",
            "Final feature vector: [0.56, 0.0, 0.17278187227972766]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['7d', 'Qh']\n",
            "Board: ['6s', '8c', 'Jd']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 50/100 = 0.500\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.5, 0.0, 0.2962883607930895]\n",
            "Final feature vector: [0.5, 0.0, 0.2962883607930895]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['Qc', 'Qh']\n",
            "Board: ['6d', '6h', 'Js']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 57/100 = 0.570\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.57, 0.0, 0.25373283712867606]\n",
            "Final feature vector: [0.57, 0.0, 0.25373283712867606]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['Qh', '9d']\n",
            "Board: ['Js', '9s', 'Jh']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 43/100 = 0.430\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.43, 0.0, 0.050090525894590884]\n",
            "Final feature vector: [0.43, 0.0, 0.050090525894590884]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['Kh', 'Ks']\n",
            "Board: ['2s', 'Qh', '8d']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 48/100 = 0.480\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.48, 0.0, 0.11608877970135263]\n",
            "Final feature vector: [0.48, 0.0, 0.11608877970135263]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['Kd', '6s']\n",
            "Board: ['Ac', 'Tc', 'Ah']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 37/100 = 0.370\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.37, 0.0, 0.038097064668636625]\n",
            "Final feature vector: [0.37, 0.0, 0.038097064668636625]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['Jc', '9h']\n",
            "Board: ['Jd', '4d', '6c']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 54/100 = 0.540\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.54, 0.0, 0.11197759894210495]\n",
            "Final feature vector: [0.54, 0.0, 0.11197759894210495]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['2s', 'Kh']\n",
            "Board: ['8c', 'Js', 'Ks']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 46/100 = 0.460\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.46, 0.0, 0.11549405814141171]\n",
            "Final feature vector: [0.46, 0.0, 0.11549405814141171]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['3c', 'Js']\n",
            "Board: ['5d', '2h', '5s']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 53/100 = 0.530\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.53, 0.0, 0.05520334904846923]\n",
            "Final feature vector: [0.53, 0.0, 0.05520334904846923]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['3s', '2d']\n",
            "Board: ['Qh', '8c', 'Kc']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 48/100 = 0.480\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.48, 0.0, 0.10480069816052863]\n",
            "Final feature vector: [0.48, 0.0, 0.10480069816052863]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['5h', '3s']\n",
            "Board: ['2s', 'Qd', 'As']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 49/100 = 0.490\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.49, 0.0, 0.29307607912182276]\n",
            "Final feature vector: [0.49, 0.0, 0.29307607912182276]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['Td', '6s']\n",
            "Board: ['Js', '6h', 'As']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 43/100 = 0.430\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.43, 0.0, 0.1746341459002892]\n",
            "Final feature vector: [0.43, 0.0, 0.1746341459002892]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['Jh', 'Ks']\n",
            "Board: ['5c', 'Kc', 'Qs']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 56/100 = 0.560\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.56, 0.0, 0.26124297983814276]\n",
            "Final feature vector: [0.56, 0.0, 0.26124297983814276]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['4s', '7c']\n",
            "Board: ['2c', '5s', '2h']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 41/100 = 0.410\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.41, 0.0, 0.11086737662629921]\n",
            "Final feature vector: [0.41, 0.0, 0.11086737662629921]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['As', '6d']\n",
            "Board: ['Th', '2s', '7h']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 47/100 = 0.470\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.47, 0.0, 0.18959296192291186]\n",
            "Final feature vector: [0.47, 0.0, 0.18959296192291186]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['5h', '4c']\n",
            "Board: ['6d', '8d', 'Kh']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 56/100 = 0.560\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.56, 0.0, 0.24146809948879144]\n",
            "Final feature vector: [0.56, 0.0, 0.24146809948879144]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['3s', 'Kh']\n",
            "Board: ['Kd', '7h', '9s']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 48/100 = 0.480\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.48, 0.0, 0.04438006754557387]\n",
            "Final feature vector: [0.48, 0.0, 0.04438006754557387]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['4c', '8d']\n",
            "Board: ['2s', '8h', '4s']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 39/100 = 0.390\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.39, 0.0, 0.10955497176924202]\n",
            "Final feature vector: [0.39, 0.0, 0.10955497176924202]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['2s', '8h']\n",
            "Board: ['Ac', '9c', 'Qs']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 46/100 = 0.460\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.46, 0.0, 0.17707674168237367]\n",
            "Final feature vector: [0.46, 0.0, 0.17707674168237367]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['6s', '3c']\n",
            "Board: ['4h', 'Jh', '7d']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 52/100 = 0.520\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.52, 0.0, 0.22896436026155537]\n",
            "Final feature vector: [0.52, 0.0, 0.22896436026155537]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['2s', '7d']\n",
            "Board: ['5c', '2h', '8s']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 47/100 = 0.470\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.47, 0.0, 0.2798713721721663]\n",
            "Final feature vector: [0.47, 0.0, 0.2798713721721663]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['Td', '7h']\n",
            "Board: ['2s', '5c', '8d']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 40/100 = 0.400\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.4, 0.0, 0.19862301638547478]\n",
            "Final feature vector: [0.4, 0.0, 0.19862301638547478]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['Ts', 'Qc']\n",
            "Board: ['2h', 'Qd', '8h']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 52/100 = 0.520\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.52, 0.0, 0.21907417643298616]\n",
            "Final feature vector: [0.52, 0.0, 0.21907417643298616]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['7d', '9h']\n",
            "Board: ['8c', '6d', '4d']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 50/100 = 0.500\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.5, 0.0, 0.23005796739190695]\n",
            "Final feature vector: [0.5, 0.0, 0.23005796739190695]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['2s', 'Ts']\n",
            "Board: ['3h', '9c', '2c']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 60/100 = 0.600\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.6, 0.0, 0.17088106566099362]\n",
            "Final feature vector: [0.6, 0.0, 0.17088106566099362]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['7s', 'Qc']\n",
            "Board: ['Qh', 'Jh', 'Tc']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 46/100 = 0.460\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.46, 0.0, 0.017112291819742897]\n",
            "Final feature vector: [0.46, 0.0, 0.017112291819742897]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['9d', '3c']\n",
            "Board: ['7s', '4s', 'Qh']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 52/100 = 0.520\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.52, 0.0, 0.2161681587804127]\n",
            "Final feature vector: [0.52, 0.0, 0.2161681587804127]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['As', 'Ad']\n",
            "Board: ['5s', 'Ah', 'Jd']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 52/100 = 0.520\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.52, 0.0, 0.1298226809063935]\n",
            "Final feature vector: [0.52, 0.0, 0.1298226809063935]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['2c', 'Jh']\n",
            "Board: ['Jc', '6c', '2s']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 54/100 = 0.540\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.54, 0.0, 0.09621458373244333]\n",
            "Final feature vector: [0.54, 0.0, 0.09621458373244333]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['Th', '8h']\n",
            "Board: ['Kc', '2h', '9h']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 48/100 = 0.480\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.48, 0.3496762257169288, 0.007713489793488603]\n",
            "Final feature vector: [0.48, 0.3496762257169288, 0.007713489793488603]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['9d', '7d']\n",
            "Board: ['Th', '2s', '3h']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 41/100 = 0.410\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.41, 0.0, 0.09050970024230959]\n",
            "Final feature vector: [0.41, 0.0, 0.09050970024230959]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['As', 'Td']\n",
            "Board: ['7c', 'Kc', '2h']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 53/100 = 0.530\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.53, 0.0, 0.25755188718074906]\n",
            "Final feature vector: [0.53, 0.0, 0.25755188718074906]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['3s', 'Th']\n",
            "Board: ['5s', '4s', '8s']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 46/100 = 0.460\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.46, 0.3496762257169288, 0.09794552488103793]\n",
            "Final feature vector: [0.46, 0.3496762257169288, 0.09794552488103793]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['Ac', '9s']\n",
            "Board: ['4c', 'Tc', 'Jd']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 52/100 = 0.520\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.52, 0.0, 0.14897795105523143]\n",
            "Final feature vector: [0.52, 0.0, 0.14897795105523143]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['4h', '4c']\n",
            "Board: ['Ts', 'Ad', 'Kh']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 60/100 = 0.600\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.6, 0.0, 0.08587593293713941]\n",
            "Final feature vector: [0.6, 0.0, 0.08587593293713941]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['8c', '3h']\n",
            "Board: ['Ts', '9h', 'Kd']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 48/100 = 0.480\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.48, 0.0, 0.24189982152995312]\n",
            "Final feature vector: [0.48, 0.0, 0.24189982152995312]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['Ah', 'Ks']\n",
            "Board: ['5d', '9s', '6c']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 54/100 = 0.540\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.54, 0.0, 0.07895554367257862]\n",
            "Final feature vector: [0.54, 0.0, 0.07895554367257862]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['Th', '3h']\n",
            "Board: ['7h', 'Jc', '2h']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 47/100 = 0.470\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.47, 0.3496762257169288, 0.290307170757627]\n",
            "Final feature vector: [0.47, 0.3496762257169288, 0.290307170757627]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['Th', '4d']\n",
            "Board: ['8h', 'Jh', 'Kh']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 46/100 = 0.460\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.46, 0.3496762257169288, 0.20122796226848705]\n",
            "Final feature vector: [0.46, 0.3496762257169288, 0.20122796226848705]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['Jh', 'Jd']\n",
            "Board: ['Js', '9c', '4c']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 51/100 = 0.510\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.51, 0.0, 0.08010363481222328]\n",
            "Final feature vector: [0.51, 0.0, 0.08010363481222328]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['9d', 'Kd']\n",
            "Board: ['Kc', '9s', 'Js']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 43/100 = 0.430\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.43, 0.0, 0.21693536875276873]\n",
            "Final feature vector: [0.43, 0.0, 0.21693536875276873]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['8h', '8d']\n",
            "Board: ['4s', '7h', 'Td']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 50/100 = 0.500\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.5, 0.0, 0.28490834691581085]\n",
            "Final feature vector: [0.5, 0.0, 0.28490834691581085]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['Tc', '5c']\n",
            "Board: ['8d', '2h', 'Td']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 52/100 = 0.520\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.52, 0.0, 0.0015015219511949395]\n",
            "Final feature vector: [0.52, 0.0, 0.0015015219511949395]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['9c', '8s']\n",
            "Board: ['3s', '5d', 'Jc']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 51/100 = 0.510\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.51, 0.0, 0.08796830201440231]\n",
            "Final feature vector: [0.51, 0.0, 0.08796830201440231]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['9c', 'Qs']\n",
            "Board: ['7c', '3d', '4s']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 47/100 = 0.470\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.47, 0.0, 0.26918298144068387]\n",
            "Final feature vector: [0.47, 0.0, 0.26918298144068387]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['Jc', '4d']\n",
            "Board: ['As', 'Qs', 'Ah']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 54/100 = 0.540\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.54, 0.0, 0.19762027058705664]\n",
            "Final feature vector: [0.54, 0.0, 0.19762027058705664]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['7h', 'Th']\n",
            "Board: ['Qc', '4c', '3d']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 45/100 = 0.450\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.45, 0.0, 0.117230832047369]\n",
            "Final feature vector: [0.45, 0.0, 0.117230832047369]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['5d', '7s']\n",
            "Board: ['Kd', '4h', 'Th']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 48/100 = 0.480\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.48, 0.0, 0.07965569628510866]\n",
            "Final feature vector: [0.48, 0.0, 0.07965569628510866]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['Qd', 'Js']\n",
            "Board: ['5d', 'Jc', '3c']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 44/100 = 0.440\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.44, 0.0, 0.27519143546554575]\n",
            "Final feature vector: [0.44, 0.0, 0.27519143546554575]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['2d', '8s']\n",
            "Board: ['Qd', '8c', '8h']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 48/100 = 0.480\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.48, 0.0, 0.15531264860350918]\n",
            "Final feature vector: [0.48, 0.0, 0.15531264860350918]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['2s', '6c']\n",
            "Board: ['6d', '6h', 'Kh']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 43/100 = 0.430\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.43, 0.0, 0.13874831087841863]\n",
            "Final feature vector: [0.43, 0.0, 0.13874831087841863]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['7c', 'Tc']\n",
            "Board: ['Kh', 'Qd', '9h']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 48/100 = 0.480\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.48, 0.0, 0.1877997377495698]\n",
            "Final feature vector: [0.48, 0.0, 0.1877997377495698]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['2d', 'Qd']\n",
            "Board: ['5s', '7h', 'Td']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 50/100 = 0.500\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.5, 0.0, 0.10585792029209361]\n",
            "Final feature vector: [0.5, 0.0, 0.10585792029209361]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['8h', 'Qd']\n",
            "Board: ['Ks', 'Ah', '2s']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 42/100 = 0.420\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.42, 0.0, 0.15972509020807057]\n",
            "Final feature vector: [0.42, 0.0, 0.15972509020807057]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['2h', '9d']\n",
            "Board: ['3h', 'Jc', '4h']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 49/100 = 0.490\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.49, 0.0, 0.2976169264983395]\n",
            "Final feature vector: [0.49, 0.0, 0.2976169264983395]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['4d', 'Jd']\n",
            "Board: ['Ah', 'Qh', '2d']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 50/100 = 0.500\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.5, 0.0, 0.07319156269864342]\n",
            "Final feature vector: [0.5, 0.0, 0.07319156269864342]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['Js', '7c']\n",
            "Board: ['7d', 'Ah', 'Jc']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 51/100 = 0.510\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.51, 0.0, 0.14330951004178683]\n",
            "Final feature vector: [0.51, 0.0, 0.14330951004178683]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['9d', 'Kc']\n",
            "Board: ['2h', '6s', '3h']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 57/100 = 0.570\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.57, 0.0, 0.2111133262696728]\n",
            "Final feature vector: [0.57, 0.0, 0.2111133262696728]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['Ad', '9s']\n",
            "Board: ['7s', '4s', '2c']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 51/100 = 0.510\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.51, 0.0, 0.03958723527049533]\n",
            "Final feature vector: [0.51, 0.0, 0.03958723527049533]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['Ah', '8d']\n",
            "Board: ['8c', '3c', '3d']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 47/100 = 0.470\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.47, 0.0, 0.22816737747082805]\n",
            "Final feature vector: [0.47, 0.0, 0.22816737747082805]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['Kd', 'Tc']\n",
            "Board: ['2c', '2h', 'Ks']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 46/100 = 0.460\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.46, 0.0, 0.1598972940033219]\n",
            "Final feature vector: [0.46, 0.0, 0.1598972940033219]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['8d', '9s']\n",
            "Board: ['Ad', '5h', '7c']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 56/100 = 0.560\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.56, 0.0, 0.002216661006434517]\n",
            "Final feature vector: [0.56, 0.0, 0.002216661006434517]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['8d', '2d']\n",
            "Board: ['4d', 'Td', 'Kd']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 54/100 = 0.540\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.54, 0.0, 0.20246203273336402]\n",
            "Final feature vector: [0.54, 0.0, 0.20246203273336402]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['2c', '2h']\n",
            "Board: ['5c', '6d', '9d']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 56/100 = 0.560\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.56, 0.0, 0.01428254733414408]\n",
            "Final feature vector: [0.56, 0.0, 0.01428254733414408]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['7c', '9d']\n",
            "Board: ['7h', 'As', '5h']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 49/100 = 0.490\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.49, 0.0, 0.023776088471440127]\n",
            "Final feature vector: [0.49, 0.0, 0.023776088471440127]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['5c', '3c']\n",
            "Board: ['7h', '9s', 'Ah']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 48/100 = 0.480\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.48, 0.0, 0.02542928116886608]\n",
            "Final feature vector: [0.48, 0.0, 0.02542928116886608]\n",
            "\n",
            "=== Calculating feature vector ===\n",
            "Hand: ['Qs', '2c']\n",
            "Board: ['3h', '3d', '6d']\n",
            "Input validation passed\n",
            "Remaining deck size: 47\n",
            "Calculating equity...\n",
            "Equity calculation: 44/100 = 0.440\n",
            "Calculating flush potential...\n",
            "Calculating straight potential...\n",
            "Raw feature vector: [0.44, 0.0, 0.14769483541238054]\n",
            "Final feature vector: [0.44, 0.0, 0.14769483541238054]\n",
            "\n",
            "Generated 100/100 valid vectors\n",
            "✅ Data generation is working!\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import time\n",
        "from collections import defaultdict\n",
        "import traceback\n",
        "\n",
        "# Mock the phevaluator functions for testing if not available\n",
        "try:\n",
        "    from phevaluator import evaluate_cards, card_to_string, string_to_card\n",
        "    PHEVALUATOR_AVAILABLE = True\n",
        "except ImportError:\n",
        "    print(\"phevaluator not available, using mock functions\")\n",
        "    PHEVALUATOR_AVAILABLE = False\n",
        "\n",
        "    def evaluate_cards(*cards):\n",
        "        \"\"\"Mock function that returns a random poker hand rank\"\"\"\n",
        "        return random.randint(1, 7462)\n",
        "\n",
        "# Basic Game Definitions\n",
        "SUITS = ['h', 'd', 'c', 's']\n",
        "RANKS = ['2', '3', '4', '5', '6', '7', '8', '9', 'T', 'J', 'Q', 'K', 'A']\n",
        "DECK = [r + s for r in RANKS for s in SUITS]\n",
        "RANK_MAP = {rank: i for i, rank in enumerate(RANKS)}\n",
        "\n",
        "class DebugPotentialAwareCalculator:\n",
        "    \"\"\"\n",
        "    Debug version of PotentialAwareCalculator to identify issues.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.cache = {}\n",
        "        print(\"DebugPotentialAwareCalculator initialized.\")\n",
        "\n",
        "    def _calculate_current_equity(self, hand, board, remaining_deck, num_sims=100):\n",
        "        \"\"\"Simplified equity calculation for debugging.\"\"\"\n",
        "        try:\n",
        "            if not hand or not isinstance(hand, list) or len(hand) != 2:\n",
        "                print(f\"Invalid hand: {hand}\")\n",
        "                return 0.0\n",
        "\n",
        "            if not isinstance(board, list):\n",
        "                print(f\"Invalid board: {board}\")\n",
        "                return 0.0\n",
        "\n",
        "            if len(remaining_deck) < 4:\n",
        "                print(f\"Not enough cards in remaining deck: {len(remaining_deck)}\")\n",
        "                return 0.0\n",
        "\n",
        "            wins = 0\n",
        "            valid_sims = 0\n",
        "\n",
        "            for _ in range(num_sims):\n",
        "                try:\n",
        "                    # Need at least 2 cards for opponent + remaining board cards\n",
        "                    cards_needed = 2 + max(0, 5 - len(board))\n",
        "\n",
        "                    if len(remaining_deck) < cards_needed:\n",
        "                        continue\n",
        "\n",
        "                    samples = random.sample(remaining_deck, cards_needed)\n",
        "                    opp_hand = samples[:2]\n",
        "                    board_runout = samples[2:]\n",
        "                    final_board = board + board_runout\n",
        "\n",
        "                    # Ensure we have exactly 5 board cards\n",
        "                    if len(final_board) > 5:\n",
        "                        final_board = final_board[:5]\n",
        "                    elif len(final_board) < 5:\n",
        "                        # Add random cards to complete board\n",
        "                        remaining_for_board = [c for c in remaining_deck if c not in samples]\n",
        "                        while len(final_board) < 5 and remaining_for_board:\n",
        "                            final_board.append(remaining_for_board.pop())\n",
        "\n",
        "                    if len(final_board) != 5:\n",
        "                        continue\n",
        "\n",
        "                    # Evaluate hands\n",
        "                    all_player_cards = hand + final_board\n",
        "                    all_opp_cards = opp_hand + final_board\n",
        "\n",
        "                    player_rank = evaluate_cards(*all_player_cards)\n",
        "                    opp_rank = evaluate_cards(*all_opp_cards)\n",
        "\n",
        "                    if player_rank < opp_rank:  # Lower rank = better hand\n",
        "                        wins += 1\n",
        "                    elif player_rank == opp_rank:\n",
        "                        wins += 0.5\n",
        "\n",
        "                    valid_sims += 1\n",
        "\n",
        "                except Exception as e:\n",
        "                    continue\n",
        "\n",
        "            if valid_sims == 0:\n",
        "                print(\"No valid simulations completed\")\n",
        "                return 0.0\n",
        "\n",
        "            equity = wins / valid_sims\n",
        "            print(f\"Equity calculation: {wins}/{valid_sims} = {equity:.3f}\")\n",
        "            return equity\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in _calculate_current_equity: {e}\")\n",
        "            return 0.0\n",
        "\n",
        "    def _calculate_flush_potential(self, hand, board, remaining_deck):\n",
        "        \"\"\"Calculate flush potential.\"\"\"\n",
        "        try:\n",
        "            hand_and_board = hand + board\n",
        "            suit_counts = {'h': 0, 'd': 0, 'c': 0, 's': 0}\n",
        "\n",
        "            for card in hand_and_board:\n",
        "                if len(card) >= 2:\n",
        "                    suit = card[1]\n",
        "                    if suit in suit_counts:\n",
        "                        suit_counts[suit] += 1\n",
        "\n",
        "            # Check for 4-card flush draw\n",
        "            for suit, count in suit_counts.items():\n",
        "                if count == 4:\n",
        "                    flush_outs = 13 - count  # 9 remaining suited cards\n",
        "                    deck_size = len(remaining_deck)\n",
        "\n",
        "                    if len(board) == 3:  # Flop\n",
        "                        p_miss_turn = (deck_size - flush_outs) / deck_size\n",
        "                        p_miss_river = (deck_size - 1 - flush_outs) / (deck_size - 1)\n",
        "                        return 1 - (p_miss_turn * p_miss_river)\n",
        "                    elif len(board) == 4:  # Turn\n",
        "                        return flush_outs / deck_size\n",
        "\n",
        "            return 0.0\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in _calculate_flush_potential: {e}\")\n",
        "            return 0.0\n",
        "\n",
        "    def _calculate_straight_potential(self, hand, board):\n",
        "        \"\"\"Simplified straight potential calculation.\"\"\"\n",
        "        try:\n",
        "            # For now, just return a random value between 0 and 0.3\n",
        "            return random.random() * 0.3\n",
        "        except Exception as e:\n",
        "            print(f\"Error in _calculate_straight_potential: {e}\")\n",
        "            return 0.0\n",
        "\n",
        "    def calculate_feature_vector(self, hand, board):\n",
        "        \"\"\"\n",
        "        Main method with extensive debugging.\n",
        "        \"\"\"\n",
        "        print(f\"\\n=== Calculating feature vector ===\")\n",
        "        print(f\"Hand: {hand}\")\n",
        "        print(f\"Board: {board}\")\n",
        "\n",
        "        try:\n",
        "            # Input validation\n",
        "            if not isinstance(hand, list) or len(hand) != 2:\n",
        "                print(f\"ERROR: Invalid hand format: {hand}\")\n",
        "                return []\n",
        "\n",
        "            if not isinstance(board, list) or len(board) not in [3, 4, 5]:\n",
        "                print(f\"ERROR: Invalid board format: {board}\")\n",
        "                return []\n",
        "\n",
        "            # Check for valid card format\n",
        "            for card in hand + board:\n",
        "                if not isinstance(card, str) or len(card) != 2:\n",
        "                    print(f\"ERROR: Invalid card format: {card}\")\n",
        "                    return []\n",
        "                if card[0] not in RANKS or card[1] not in SUITS:\n",
        "                    print(f\"ERROR: Invalid card: {card}\")\n",
        "                    return []\n",
        "\n",
        "            # Check for duplicate cards\n",
        "            all_cards = hand + board\n",
        "            if len(set(all_cards)) != len(all_cards):\n",
        "                print(f\"ERROR: Duplicate cards found: {all_cards}\")\n",
        "                return []\n",
        "\n",
        "            print(\"Input validation passed\")\n",
        "\n",
        "            # Calculate remaining deck\n",
        "            known_cards = hand + board\n",
        "            remaining_deck = [card for card in DECK if card not in known_cards]\n",
        "            print(f\"Remaining deck size: {len(remaining_deck)}\")\n",
        "\n",
        "            # Calculate features\n",
        "            print(\"Calculating equity...\")\n",
        "            equity = self._calculate_current_equity(hand, board, remaining_deck)\n",
        "\n",
        "            print(\"Calculating flush potential...\")\n",
        "            flush_potential = self._calculate_flush_potential(hand, board, remaining_deck)\n",
        "\n",
        "            print(\"Calculating straight potential...\")\n",
        "            straight_potential = self._calculate_straight_potential(hand, board)\n",
        "\n",
        "            # Create feature vector\n",
        "            feature_vector = [equity, flush_potential, straight_potential]\n",
        "\n",
        "            print(f\"Raw feature vector: {feature_vector}\")\n",
        "\n",
        "            # Validate feature vector\n",
        "            for i, val in enumerate(feature_vector):\n",
        "                if not isinstance(val, (int, float)):\n",
        "                    print(f\"ERROR: Feature {i} is not numeric: {val} (type: {type(val)})\")\n",
        "                    return []\n",
        "                if val < 0 or val > 1:\n",
        "                    print(f\"WARNING: Feature {i} out of range [0,1]: {val}\")\n",
        "                    # Clamp to valid range\n",
        "                    feature_vector[i] = max(0.0, min(1.0, val))\n",
        "\n",
        "            print(f\"Final feature vector: {feature_vector}\")\n",
        "            return feature_vector\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"CRITICAL ERROR in calculate_feature_vector: {e}\")\n",
        "            traceback.print_exc()\n",
        "            return []\n",
        "\n",
        "class DebugAbstractionManager:\n",
        "    \"\"\"Simplified manager for debugging.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.calculator = DebugPotentialAwareCalculator()\n",
        "        print(\"DebugAbstractionManager initialized\")\n",
        "\n",
        "    def test_calculator(self):\n",
        "        \"\"\"Test the calculator with various inputs.\"\"\"\n",
        "        test_cases = [\n",
        "            # Valid cases\n",
        "            (['As', 'Kh'], ['Qc', '7d', '2s']),  # Flop\n",
        "            (['9h', '8c'], ['7d', '6s', '2h', 'Tc']),  # Turn\n",
        "            (['Ah', '2h'], ['3h', '4h', '5c', 'Kd', '9s']),  # River\n",
        "\n",
        "            # Edge cases\n",
        "            (['AA', 'KK'], ['QQ', '77', '22']),  # Invalid card format\n",
        "            (['As', 'As'], ['Qc', '7d', '2s']),  # Duplicate cards\n",
        "            (['As'], ['Qc', '7d', '2s']),  # Too few hole cards\n",
        "            (['As', 'Kh'], ['Qc', '7d']),  # Too few board cards\n",
        "        ]\n",
        "\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"TESTING CALCULATOR\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        success_count = 0\n",
        "        for i, (hand, board) in enumerate(test_cases):\n",
        "            print(f\"\\nTest {i+1}: Hand {hand}, Board {board}\")\n",
        "            try:\n",
        "                result = self.calculator.calculate_feature_vector(hand, board)\n",
        "                if result and len(result) > 0:\n",
        "                    print(f\"SUCCESS: {result}\")\n",
        "                    success_count += 1\n",
        "                else:\n",
        "                    print(f\"FAILED: Empty or invalid result\")\n",
        "            except Exception as e:\n",
        "                print(f\"EXCEPTION: {e}\")\n",
        "\n",
        "        print(f\"\\nSUMMARY: {success_count}/{len(test_cases)} tests passed\")\n",
        "        return success_count > 0\n",
        "\n",
        "# Test the debug version\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=== DEBUGGING CALCULATOR ISSUES ===\")\n",
        "\n",
        "    manager = DebugAbstractionManager()\n",
        "\n",
        "    # Test individual calculator calls\n",
        "    success = manager.test_calculator()\n",
        "\n",
        "    if success:\n",
        "        print(\"\\n✅ Calculator is working for some cases\")\n",
        "        print(\"The issue might be in the data generation loop\")\n",
        "    else:\n",
        "        print(\"\\n❌ Calculator is completely broken\")\n",
        "        print(\"Need to fix the calculate_feature_vector method\")\n",
        "\n",
        "    # Test a simple generation loop\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"TESTING DATA GENERATION LOOP\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    SUITS = ['h', 'd', 'c', 's']\n",
        "    RANKS = ['2', '3', '4', '5', '6', '7', '8', '9', 'T', 'J', 'Q', 'K', 'A']\n",
        "    DECK = [r + s for r in RANKS for s in SUITS]\n",
        "\n",
        "    valid_vectors = []\n",
        "    for i in range(100):\n",
        "        try:\n",
        "            deck = DECK.copy()\n",
        "            random.shuffle(deck)\n",
        "\n",
        "            hand = deck[:2]\n",
        "            board = deck[2:5]  # Flop\n",
        "\n",
        "            vector = manager.calculator.calculate_feature_vector(hand, board)\n",
        "\n",
        "            if vector and len(vector) > 0:\n",
        "                valid_vectors.append(vector)\n",
        "                if len(valid_vectors) <= 5:\n",
        "                    print(f\"Valid vector {len(valid_vectors)}: {vector}\")\n",
        "        except Exception as e:\n",
        "            continue\n",
        "\n",
        "    print(f\"\\nGenerated {len(valid_vectors)}/100 valid vectors\")\n",
        "\n",
        "    if len(valid_vectors) > 0:\n",
        "        print(\"✅ Data generation is working!\")\n",
        "    else:\n",
        "        print(\"❌ Data generation is completely failing\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}