
Ce projet pr√©sente le d√©veloppement complet d'un agent de poker autonome, capable de d√©velopper une strat√©gie quasi-optimale pour le Texas Hold'em en un-contre-un (Heads-Up). L'approche adopt√©e est un syst√®me hybride combinant le Machine Learning pour la simplification de l'environnement de jeu et la Th√©orie des Jeux pour l'apprentissage de la strat√©gie.

![poker_ai_demo](https://github.com/user-attachments/assets/95d1e390-3ab7-428c-a4ed-3eca765b6554)

# üÉè Texas Hold'em Poker AI: Agent Adaptatif bas√© sur MCCFR

Une IA de poker avanc√©e qui combine la **Minimisation de Regret Contrefactuel Monte Carlo (MCCFR)** avec une abstraction intelligente du jeu pour jouer au Texas Hold'em √† un niveau comp√©titif. Ce projet rel√®ve le d√©fi fondamental des jeux √† information imparfaite, o√π l'espace d'√©tats massif (~10^160 √©tats de jeu possibles) rend les approches traditionnelles de r√©solution de jeux computationnellement impossibles.

---

## üéØ Vue d'ensemble du projet

Cet agent d'IA d√©montre comment l'apprentissage automatique moderne peut ma√Ætriser des environnements strat√©giques complexes gr√¢ce √† :
- **L'abstraction strat√©gique** r√©duisant des milliards de sc√©narios de poker en clusters g√©rables
- **L'apprentissage par renforcement auto-supervis√©** convergeant vers des strat√©gies d'√©quilibre de Nash
- **L'exploitation adaptative** des styles de jeu adverses (tight/loose, passif/agressif)
- **Le raisonnement bas√© sur les caract√©ristiques** plut√¥t que la m√©morisation

---

## üß† Architecture : Un Pipeline en Quatre √âtapes

```
Mains de Poker Brutes ‚Üí Extraction de Caract√©ristiques ‚Üí Clustering ‚Üí Entra√Ænement Auto-Supervis√© ‚Üí √âvaluation
                        (PotentialAware)                 (K-Means)    (MCCFR)                      (vs Slumbot)
```

### üî¨ √âtape 1 : Extraction de Caract√©ristiques (`PotentialAwareCalculator`)

Plut√¥t que de traiter chaque configuration de main unique s√©par√©ment, l'IA analyse des **caract√©ristiques strat√©giques** :

- **√âquit√© de la main** : Probabilit√© de gagner actuelle contre des mains adverses al√©atoires
- **Potentiel de Couleur** : Probabilit√© de compl√©ter un tirage couleur
- **Potentiel de Suite** : Probabilit√© de compl√©ter un tirage suite
- **Force de Main** : Classement brut de la main (carte haute ‚Üí quinte flush royale)
- **Texture du Board** : Analyse des interactions entre cartes communes

**Pourquoi c'est important** : A‚ô†K‚ô† et A‚ô•K‚ô• sont strat√©giquement identiques malgr√© des cartes diff√©rentes. L'extraction de caract√©ristiques fait converger ces variations, r√©duisant drastiquement la complexit√© de l'espace d'√©tats.

```python
# Exemple de vecteur de caract√©ristiques
{
    "equity": 0.72,
    "flush_potential": 0.18,
    "straight_potential": 0.12,
    "hand_strength": 0.85,
    "feature_vector": [0.72, 0.18, 0.12, 0.85, ...]
}
```

---

### üé® √âtape 2 : Abstraction & Bucketing (`FixedAbstractionManager` + K-Means)

**Le Probl√®me** : M√™me avec les caract√©ristiques, il y a encore trop de situations uniques pour l'entra√Ænement direct.

**La Solution** : Utiliser le **clustering K-Means** pour regrouper les mains strat√©giquement similaires en **20 buckets abstraits** :

1. G√©n√©rer des vecteurs de caract√©ristiques pour 100 000+ sc√©narios de poker
2. Appliquer K-Means pour les regrouper en 20 "types de mains" strat√©giques
3. Mapper chaque main de poker possible √† son centro√Øde de cluster le plus proche

**R√©sultat** : L'IA voit maintenant le poker comme ayant ~20 cat√©gories de mains distinctes au lieu de milliards de situations uniques.

```
Complexit√© Originale :  ~10^160 √©tats
Apr√®s Abstraction :     ~10^6 √©tats (traitable !)
```

---

### üöÄ √âtape 3 : Entra√Ænement par Auto-Confrontation (`OptimizedMCCFRTrainer`)

L'algorithme d'apprentissage central : **Minimisation de Regret Contrefactuel Monte Carlo**

**Comment fonctionne MCCFR** :
1. **Simulation auto-supervis√©e** : L'agent joue des millions de mains contre lui-m√™me
2. **Suivi du regret** : Pour chaque point de d√©cision, calculer le "regret" (combien de valeur a √©t√© perdue en ne choisissant pas d'actions alternatives)
3. **Mises √† jour de strat√©gie** : Ajuster les probabilit√©s d'action pour minimiser le regret cumul√©
4. **Convergence vers l'√©quilibre de Nash** : Approche de mani√®re prouv√©e des strat√©gies inexploitables

**Boucle d'Entra√Ænement** :
```
Pour 1 000 000+ it√©rations :
    ‚îú‚îÄ Simuler une main de poker avec la strat√©gie actuelle
    ‚îú‚îÄ √âchantillonner les actions bas√©es sur des probabilit√©s pond√©r√©es par le regret
    ‚îú‚îÄ Calculer le regret contrefactuel (et si j'avais choisi diff√©remment ?)
    ‚îú‚îÄ Mettre √† jour la strat√©gie pour favoriser les actions √† faible regret
    ‚îî‚îÄ R√©p√©ter jusqu'√† convergence
```

**Innovation Cl√©** : MCCFR utilise une **approximation bas√©e sur l'√©chantillonnage** au lieu d'un parcours exhaustif de l'arbre, atteignant une convergence 1000x plus rapide que CFR classique tout en maintenant les garanties th√©oriques.

---

---

## üõ†Ô∏è Stack Technique

- **Framework Principal** : OpenSpiel (framework RL de Google DeepMind)
- **Langage** : Python 3.8+
- **Algorithmes Cl√©s** : 
  - Monte Carlo CFR (minimisation de regret √† variance r√©duite)
  - Clustering K-Means (scikit-learn)
  - Calcul d'√©quit√© (simulation Monte Carlo personnalis√©e)
- **√âvaluation** : Int√©gration PyPokerEngine + API Slumbot

---

## üöß Limitations & Travaux Futurs

### Limitations Actuelles
1. **Taille de mise statique** : Utilise une abstraction de mise fixe au lieu d'un dimensionnement dynamique
2. **Contraintes computationnelles** : Entra√Æn√© avec 1M d'it√©rations (les agents de pointe utilisent des milliards)
3. **Mod√®les d'adversaires fixes** : L'exploitation n√©cessite un pr√©-entra√Ænement pour des styles de jeu sp√©cifiques

### Am√©liorations Pr√©vues
1. **Dimensionnement dynamique des mises** : Int√©grer plusieurs options de taille de mise (3-5 tailles par point de d√©cision) dans l'entra√Ænement MCCFR
2. **Adaptation en ligne** : Mod√©lisation de l'adversaire en temps r√©el pendant le jeu au lieu de politiques d'exploitation pr√©-entra√Æn√©es
3. **Deep CFR** : Remplacer le stockage tabulaire de strat√©gie par une approximation de fonction par r√©seau de neurones

---

## üéì Contexte Th√©orique

### Th√©orie des Jeux √† Information Imparfaite

Le poker appartient √† une classe de jeux o√π :
- **Information cach√©e** : Les cartes adverses sont inconnues
- **R√©sultats stochastiques** : Les tirages de cartes sont probabilistes
- **Strat√©gies mixtes** : L'optimalit√© n√©cessite de la randomisation (bluff)
- **√âquilibre de Nash** : Aucun joueur ne peut am√©liorer unilat√©ralement son r√©sultat

### Minimisation de Regret Contrefactuel

**Regret Contrefactuel** : La diff√©rence de valeur entre l'action choisie et la meilleure action alternative, pond√©r√©e par la probabilit√© d'atteindre cet √©tat de jeu.

**Propri√©t√© de Convergence** : Si tous les joueurs minimisent leur regret, leurs strat√©gies convergent vers un √©quilibre de Nash.

**Avantage Monte Carlo** : L'√©chantillonnage r√©duit la complexit√© de O(|√âtats|) √† O(‚àö|√âtats|) tout en pr√©servant les garanties de convergence.

---

## üìö R√©f√©rences & Recherche

Ce projet s'appuie sur des recherches de pointe en IA pour le poker :
- **Counterfactual Regret Minimization** (Zinkevich et al., 2007)
- **DeepStack** (Moravƒç√≠k et al., 2017) - Premier agent surhumain au poker heads-up
- **Libratus** (Brown & Sandholm, 2018) - Vainqueur contre des professionnels
- **Pluribus** (Brown & Sandholm, 2019) - Extension au poker multijoueur

---

## üí° Applications au-del√† du Poker

Les techniques d√©velopp√©es ici s'appliquent √† :
- **Finance** : Trading algorithmique avec information incompl√®te
- **Cybers√©curit√©** : Strat√©gies d√©fensives contre adversaires adaptatifs
- **N√©gociation** : Syst√®mes de d√©cision multi-agents
- **Syst√®mes Autonomes** : Planification sous incertitude

