
Ce projet pr√©sente le d√©veloppement complet d'un agent de poker autonome, capable de d√©velopper une strat√©gie quasi-optimale pour le Texas Hold'em en un-contre-un (Heads-Up). L'approche adopt√©e est un syst√®me hybride combinant le Machine Learning pour la simplification de l'environnement de jeu et la Th√©orie des Jeux pour l'apprentissage de la strat√©gie.

![poker_ai_demo](https://github.com/user-attachments/assets/95d1e390-3ab7-428c-a4ed-3eca765b6554)

üéØ Vue d'ensemble
Ce projet impl√©mente un "cerveau" d'IA sophistiqu√© capable de jouer au poker Texas Hold'em √† un niveau comp√©titif. Le d√©fi ? Le poker poss√®de environ 10^160 √©tats de jeu possibles - rendant impossible pour toute IA de m√©moriser toutes les situations. Notre solution combine l'abstraction intelligente du jeu avec la Minimisation de Regret Contrefactuel Monte Carlo (MCCFR) pour cr√©er un agent de poker puissant et adaptatif.
üß† L'Architecture
Le Probl√®me : L'Information Imparfaite
Le poker est fondamentalement diff√©rent de jeux comme les √©checs :

Information imparfaite : Vous ne voyez pas les cartes des adversaires
R√©sultats stochastiques : Les tirages de cartes sont probabilistes
Espace d'√©tats massif : Sc√©narios de jeu quasi-infinis
Complexit√© psychologique : Bluff, lecture des adversaires, th√©orie des jeux

Les approches traditionnelles de r√©solution de jeux √©chouent spectaculairement. Nous avons besoin de quelque chose de plus intelligent.
La Solution : Un Pipeline en Quatre √âtapes
Mains de Poker Brutes ‚Üí Extraction de Caract√©ristiques ‚Üí Clustering ‚Üí Entra√Ænement Auto-Supervis√© ‚Üí √âvaluation
                        (PotentialAware)                 (K-Means)    (MCCFR)                    (Tournoi)

üî¨ √âtape 1 : Extraction de Caract√©ristiques
PotentialAwareCalculator
L'IA ne m√©morise pas les mains individuelles - elle analyse des caract√©ristiques strat√©giques.
Ce qu'il calcule :

√âquit√© : Force actuelle de la main (probabilit√© de gagner)
Potentiel de Couleur : Probabilit√© de compl√©ter une couleur
Potentiel de Suite : Probabilit√© de compl√©ter une suite
Force de Main : Classement brut de la main
Texture du Board : Analyse des cartes communes

Pourquoi c'est important :
Au lieu de traiter A‚ô† K‚ô† et A‚ô• K‚ô• comme des mains diff√©rentes, l'IA reconna√Æt qu'elles sont strat√©giquement identiques (m√™me √©quit√©, m√™me potentiel de couleur). Cela r√©duit consid√©rablement la complexit√©.
python# Exemple de sortie
{
    "equity": 0.72,
    "flush_potential": 0.18,
    "straight_potential": 0.12,
    "hand_strength": 0.85,
    "feature_vector": [0.72, 0.18, 0.12, 0.85, ...]
}

üé® √âtape 2 : Abstraction & Bucketing
FixedAbstractionManager + Clustering K-Means
Une fois que nous avons des vecteurs de caract√©ristiques pour des milliers de mains, nous utilisons le clustering K-Means pour regrouper les mains similaires en buckets.
Le processus :

G√©n√©rer des vecteurs de caract√©ristiques pour 100 000+ situations de poker
Appliquer K-Means pour les regrouper en 20 buckets strat√©giques
Mapper chaque main de poker possible √† son bucket le plus proche

R√©sultat :
L'IA voit maintenant le poker comme un jeu avec seulement 20 "types de mains" distincts au lieu de milliards. C'est ce qui rend l'apprentissage r√©alisable.
Complexit√© originale : ~10^160 √©tats
Apr√®s abstraction :    ~10^6 √©tats (g√©rable !)

üöÄ √âtape 3 : Entra√Ænement par Auto-Confrontation
OptimizedMCCFRTrainer
Vient maintenant l'apprentissage proprement dit. Notre IA utilise la Minimisation de Regret Contrefactuel Monte Carlo - un algorithme de pointe qui :

Joue des millions de mains contre elle-m√™me √† vitesse fulgurante
Suit le "regret" pour chaque d√©cision (Combien ai-je perdu en ne choisissant pas l'action X ?)
Met √† jour sa strat√©gie pour minimiser le regret total
Converge vers l'√©quilibre de Nash - une strat√©gie prouv√©e comme inexploitable

La boucle d'entra√Ænement :
Pour 1 000 000+ it√©rations :
    ‚îú‚îÄ Simuler une main de poker
    ‚îú‚îÄ L'IA choisit une action bas√©e sur la strat√©gie actuelle
    ‚îú‚îÄ Calculer le regret contrefactuel (et si j'avais choisi diff√©remment ?)
    ‚îú‚îÄ Mettre √† jour la strat√©gie pour favoriser les actions √† faible regret
    ‚îî‚îÄ R√©p√©ter
Innovation cl√© :
MCCFR est une m√©thode bas√©e sur l'√©chantillonnage. Au lieu de calculer le regret pour chaque sc√©nario possible (impossible), elle √©chantillonne les arbres de jeu et converge tout aussi efficacement - mais 1000x plus rapidement.

